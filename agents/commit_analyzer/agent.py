"""
CommitAnalyzer Agent

Git Ïª§Î∞ãÏùÑ Î∂ÑÏÑùÌïòÍ≥† Neo4jÏóê Ï†ÅÏû¨ (Pydantic Ïä§ÌÇ§Îßà ÏÇ¨Ïö©, MERGEÎ°ú Î©±Îì±ÏÑ± Î≥¥Ïû•)
Repository Isolation ÏßÄÏõê: Í∞Å Git repository Îç∞Ïù¥ÌÑ∞Î•º Í≤©Î¶¨ÌïòÏó¨ Ï†ÄÏû•
"""

import logging
import asyncio
from pathlib import Path
from typing import Any, Optional

from pydriller import Repository

from shared.graph_db import GraphDBBackend, Neo4jBackend
from .schemas import CommitAnalyzerContext, CommitAnalyzerResponse
from .author_mapper import AuthorMapper

logger = logging.getLogger(__name__)


class CommitAnalyzerAgent:
    """
    Git Ïª§Î∞ãÏùÑ Î∂ÑÏÑùÌïòÍ≥† Neo4jÏóê Ï†ÅÏû¨ÌïòÎäî ÏÑúÎ∏åÏóêÏù¥Ï†ÑÌä∏

    Level 2 Î≥ëÎ†¨ Ï≤òÎ¶¨:
    - Ïª§Î∞ã ÎßàÏù¥Îãù (PyDriller)
    - Neo4j Ï†ÅÏû¨ (Î∞∞Ïπò Îã®ÏúÑ, MERGE ÏÇ¨Ïö©)

    Repository Isolation:
    - Í∞Å ÎÖ∏ÎìúÏóê Repo_{repo_id} ÎùºÎ≤® ÏûêÎèô Ï∂îÍ∞Ä
    - ÏøºÎ¶¨ Ïãú repo_idÎ°ú ÌïÑÌÑ∞ÎßÅÌïòÏó¨ Îã§Î•∏ repository Îç∞Ïù¥ÌÑ∞ÏôÄ Í≤©Î¶¨
    """

    def __init__(
        self,
        neo4j_uri: str,
        neo4j_user: str,
        neo4j_password: str,
    ):
        self.neo4j_uri = neo4j_uri
        self.neo4j_user = neo4j_user
        self.neo4j_password = neo4j_password
        self.backend: Optional[GraphDBBackend] = None
        self.author_mapper: Optional[AuthorMapper] = None

    async def run(self, context: CommitAnalyzerContext) -> CommitAnalyzerResponse:
        """
        Ïª§Î∞ã Î∂ÑÏÑù Î∞è Neo4j Ï†ÅÏû¨ Ïã§Ìñâ (Pydantic Ïä§ÌÇ§Îßà ÏÇ¨Ïö©)
        Repository Isolation Ï†ÅÏö©: repo_idÎ°ú Îç∞Ïù¥ÌÑ∞ Í≤©Î¶¨

        Args:
            context: CommitAnalyzerContext (Í≤ÄÏ¶ùÎêú ÏûÖÎ†•, git_url Ìè¨Ìï®)

        Returns:
            CommitAnalyzerResponse (ÌÉÄÏûÖ ÏïàÏ†Ñ Ï∂úÎ†•)
        """
        repo_path = context.repo_path
        target_user = context.target_user
        repo_id = context.repo_id  # Repository IsolationÏö© ID

        logger.info(f"üìä CommitAnalyzer: {repo_path} Î∂ÑÏÑù ÏãúÏûë (repo_id: {repo_id})")

        try:
            # GraphDBBackend Ï¥àÍ∏∞Ìôî (Neo4j)
            self.backend = Neo4jBackend()

            # AuthorMapper Ï¥àÍ∏∞Ìôî (Îß§Ìïë Í∑úÏπôÏù¥ ÏûàÎäî Í≤ΩÏö∞)
            if context.author_mapping_rules:
                mapping_dict = context.author_mapping_rules.to_dict()
                self.author_mapper = AuthorMapper(mapping_dict)
                stats = self.author_mapper.get_mapping_stats()
                logger.info(
                    f"‚úÖ AuthorMapper enabled: {stats['total_developers']} developers, "
                    f"{stats['total_aliases']} aliases"
                )
            else:
                self.author_mapper = None
                logger.info("‚ÑπÔ∏è AuthorMapper disabled: No mapping rules provided")

            # Neo4j Ï¥àÍ∏∞Ìôî (Ïù∏Îç±Ïä§, Ï†úÏïΩÏ°∞Í±¥) - RepositoryÎ≥ÑÎ°ú Í≤©Î¶¨
            await self._init_neo4j(repo_id)

            # Level 2-1: PyDrillerÎ°ú Ïª§Î∞ã ÎßàÏù¥Îãù
            commits_data = await self._mine_commits(repo_path, target_user)

            # Level 2-2: Neo4jÏóê Î∞∞Ïπò Ï†ÅÏû¨ (MERGE ÏÇ¨Ïö©, Repository Isolation Ï†ÅÏö©)
            stats = await self._load_to_neo4j(commits_data, repo_id)

            logger.info(
                f"‚úÖ CommitAnalyzer: {stats['total_commits']}Í∞ú Ïª§Î∞ã, "
                f"{stats['total_users']}Î™Ö Ïú†Ï†Ä Ï†ÅÏû¨ ÏôÑÎ£å (repo_id: {repo_id})"
            )

            return CommitAnalyzerResponse(
                status="success",
                total_commits=stats["total_commits"],
                total_users=stats["total_users"],
                total_files=stats["total_files"],
                error=None,
            )

        except Exception as e:
            logger.error(f"‚ùå CommitAnalyzer: {e}")
            return CommitAnalyzerResponse(
                status="failed",
                total_commits=0,
                total_users=0,
                total_files=0,
                error=str(e),
            )

        finally:
            if self.backend:
                await self.backend.close()

    async def _init_neo4j(self, repo_id: str):
        """
        Neo4j Ïù∏Îç±Ïä§ Î∞è Ï†úÏïΩÏ°∞Í±¥ ÏÉùÏÑ± (Repository Isolation Ï†ÅÏö©)

        Args:
            repo_id: Repository ID (Ïòà: github_user_repo)
        """
        # Repository ÎùºÎ≤® ÏÉùÏÑ±
        repo_label = self.backend.get_repo_label(repo_id)

        # Ï†úÏïΩÏ°∞Í±¥ ÏÉùÏÑ± ÏøºÎ¶¨ (RepositoryÎ≥ÑÎ°ú Í≤©Î¶¨)
        # Neo4j 5.xÏóêÏÑúÎäî Ïó¨Îü¨ ÎùºÎ≤®ÏùÑ ÏßÅÏ†ë ÏÇ¨Ïö©Ìï† Ïàò ÏóÜÏúºÎØÄÎ°ú,
        # Îã®Ïùº ÎùºÎ≤® + Î≥µÌï© ÌÇ§(repo_id ÏÜçÏÑ± Ìè¨Ìï®)Î°ú Ï†úÏïΩÏ°∞Í±¥ ÏÉùÏÑ±
        safe_repo_id = repo_id.replace('-', '_').replace('.', '_')
        constraints = [
            # User ÎÖ∏Îìú: (email, repo_id) Î≥µÌï© ÌÇ§Î°ú repositoryÎ≥Ñ uniqueness Î≥¥Ïû•
            f"CREATE CONSTRAINT user_email_{safe_repo_id} IF NOT EXISTS "
            f"FOR (u:User) REQUIRE (u.email, u.repo_id) IS UNIQUE",

            # Commit ÎÖ∏Îìú: (hash, repo_id) Î≥µÌï© ÌÇ§Î°ú repositoryÎ≥Ñ uniqueness Î≥¥Ïû•
            f"CREATE CONSTRAINT commit_hash_{safe_repo_id} IF NOT EXISTS "
            f"FOR (c:Commit) REQUIRE (c.hash, c.repo_id) IS UNIQUE",

            # File ÎÖ∏Îìú: (path, repo_id) Î≥µÌï© ÌÇ§Î°ú repositoryÎ≥Ñ uniqueness Î≥¥Ïû•
            f"CREATE CONSTRAINT file_path_{safe_repo_id} IF NOT EXISTS "
            f"FOR (f:File) REQUIRE (f.path, f.repo_id) IS UNIQUE",
        ]

        for constraint_query in constraints:
            try:
                await self.backend.execute_query(constraint_query, repo_id=repo_id)
            except Exception as e:
                # Ï†úÏïΩÏ°∞Í±¥Ïù¥ Ïù¥ÎØ∏ Ï°¥Ïû¨ÌïòÎäî Í≤ΩÏö∞ Î¨¥Ïãú
                if "already exists" not in str(e).lower():
                    logger.warning(f"‚ö†Ô∏è Ï†úÏïΩÏ°∞Í±¥ ÏÉùÏÑ± Ïã§Ìå®: {e}")

        logger.info(f"‚úÖ Neo4j Ïù∏Îç±Ïä§ Î∞è Ï†úÏïΩÏ°∞Í±¥ ÏÉùÏÑ± ÏôÑÎ£å (repo_id: {repo_id})")

    async def _mine_commits(
        self, repo_path: str, target_user: Optional[str]
    ) -> list[dict[str, Any]]:
        """
        PyDrillerÎ°ú Ïª§Î∞ã ÎßàÏù¥Îãù

        Args:
            repo_path: Git Î†àÌè¨ÏßÄÌÜ†Î¶¨ Í≤ΩÎ°ú
            target_user: ÌäπÏ†ï Ïú†Ï†Ä Ïù¥Î©îÏùº (NoneÏù¥Î©¥ Ï†ÑÏ≤¥)

        Returns:
            list of commit data dictionaries
        """
        commits_data = []

        # PyDrillerÎäî ÎèôÍ∏∞ APIÏù¥ÎØÄÎ°ú executorÏóêÏÑú Ïã§Ìñâ
        def _mine():
            repo = Repository(repo_path)

            for commit in repo.traverse_commits():
                # ÌäπÏ†ï Ïú†Ï†Ä ÌïÑÌÑ∞ÎßÅ (Ïù¥Î©îÏùº ÎòêÎäî Ïù¥Î¶ÑÏúºÎ°ú ÎπÑÍµê, ÎåÄÏÜåÎ¨∏Ïûê Î¨¥Ïãú)
                if target_user:
                    target_lower = target_user.lower()
                    author_email_lower = commit.author.email.lower() if commit.author.email else ""
                    author_name_lower = commit.author.name.lower() if commit.author.name else ""
                    
                    # Ïù¥Î©îÏùº ÎòêÎäî Ïù¥Î¶Ñ Ï§ë ÌïòÎÇòÎùºÎèÑ ÏùºÏπòÌïòÎ©¥ Ìè¨Ìï®
                    if (target_lower != author_email_lower and 
                        target_lower != author_name_lower):
                        continue

                # Ï†ÄÏûê Ï†ïÎ≥¥ Ï†ïÍ∑úÌôî (AuthorMapper ÏÇ¨Ïö©)
                original_author_name = commit.author.name
                original_author_email = commit.author.email

                if self.author_mapper:
                    normalized_name, normalized_email = self.author_mapper.normalize_author(
                        original_author_name, original_author_email
                    )
                else:
                    normalized_name = original_author_name
                    normalized_email = original_author_email

                commit_data = {
                    "hash": commit.hash,
                    "message": commit.msg,
                    "author_name": normalized_name,  # Ï†ïÍ∑úÌôîÎêú Ïù¥Î¶Ñ
                    "author_email": normalized_email,  # Ï†ïÍ∑úÌôîÎêú Ïù¥Î©îÏùº
                    "original_author_name": original_author_name,  # ÏõêÎ≥∏ Ïù¥Î¶Ñ (Ï∞∏Í≥†Ïö©)
                    "original_author_email": original_author_email,  # ÏõêÎ≥∏ Ïù¥Î©îÏùº (Ï∞∏Í≥†Ïö©)
                    "author_date": commit.author_date.isoformat(),
                    "committer_name": commit.committer.name,
                    "committer_email": commit.committer.email,
                    "committer_date": commit.committer_date.isoformat(),
                    "lines_added": commit.insertions,
                    "lines_deleted": commit.deletions,
                    "files_changed": commit.files,
                    "modifications": [],
                }

                # ÌååÏùº ÏàòÏ†ï ÎÇ¥Ïó≠
                for modification in commit.modified_files:
                    # NULL Í≤ΩÎ°ú ÌïÑÌÑ∞ÎßÅ (ÏÇ≠Ï†úÎêú ÌååÏùº Îì±)
                    file_path = modification.new_path or modification.old_path

                    if file_path is None:
                        logger.warning(
                            f"‚ö†Ô∏è Commit {commit.hash[:7]}: ÌååÏùº Í≤ΩÎ°úÍ∞Ä NoneÏù∏ ÏàòÏ†ïÏÇ¨Ìï≠ Ïä§ÌÇµ "
                            f"(change_type: {modification.change_type.name})"
                        )
                        continue

                    commit_data["modifications"].append({
                        "filename": modification.filename,
                        "old_path": modification.old_path,
                        "new_path": file_path,  # NULL ÎåÄÏã† Ïú†Ìö®Ìïú Í≤ΩÎ°ú ÏÇ¨Ïö©
                        "change_type": modification.change_type.name,
                        "added_lines": modification.added_lines,
                        "deleted_lines": modification.deleted_lines,
                        "complexity": modification.complexity if modification.complexity else 0,
                    })

                commits_data.append(commit_data)

            return commits_data

        # ÎèôÍ∏∞ Ìï®ÏàòÎ•º ÎπÑÎèôÍ∏∞Î°ú Ïã§Ìñâ
        loop = asyncio.get_event_loop()
        commits_data = await loop.run_in_executor(None, _mine)

        logger.info(f"üìä PyDriller: {len(commits_data)}Í∞ú Ïª§Î∞ã ÎßàÏù¥Îãù ÏôÑÎ£å")
        return commits_data

    async def _load_to_neo4j(
        self, commits_data: list[dict[str, Any]], repo_id: str
    ) -> dict[str, int]:
        """
        Ïª§Î∞ã Îç∞Ïù¥ÌÑ∞Î•º Neo4jÏóê Î∞∞Ïπò Ï†ÅÏû¨ (MERGE ÏÇ¨Ïö©ÌïòÏó¨ Î©±Îì±ÏÑ± Î≥¥Ïû•)
        Repository Isolation Ï†ÅÏö©: repo_idÎ°ú Îç∞Ïù¥ÌÑ∞ Í≤©Î¶¨

        Args:
            commits_data: Ïª§Î∞ã Îç∞Ïù¥ÌÑ∞ Î¶¨Ïä§Ìä∏
            repo_id: Repository ID (Ïòà: github_user_repo)

        Returns:
            {"total_commits": int, "total_users": int, "total_files": int}
        """
        # Repository ÎùºÎ≤® ÏÉùÏÑ±
        repo_label = self.backend.get_repo_label(repo_id)

        # Î∞∞Ïπò ÌÅ¨Í∏∞
        batch_size = 100
        total_commits = 0
        users_set = set()
        files_set = set()

        for i in range(0, len(commits_data), batch_size):
            batch = commits_data[i : i + batch_size]

            # Î∞∞Ïπò Ï≤òÎ¶¨ ÏøºÎ¶¨ (MERGE ÏÇ¨Ïö©, Repository Isolation Ï†ÅÏö©)
            # Ï†úÏïΩÏ°∞Í±¥Ïù¥ Î≥µÌï© ÌÇ§Ïù¥ÎØÄÎ°ú MERGEÎèÑ Î≥µÌï© ÌÇ§Î°ú Îß§Ïπ≠ÌïòÎêò, ÎùºÎ≤®ÏùÄ Ïó¨Ï†ÑÌûà Ï∂îÍ∞Ä
            query = f"""
            UNWIND $commits AS commit

            // User ÎÖ∏Îìú ÏÉùÏÑ±/Î≥ëÌï© (Î≥µÌï© ÌÇ§: email + repo_id, Repository ÎùºÎ≤® Ìè¨Ìï®)
            MERGE (u:{repo_label}:User {{email: commit.author_email, repo_id: $repo_id}})
            ON CREATE SET
                u.name = commit.author_name
            ON MATCH SET
                u.name = commit.author_name  // Ï†ïÍ∑úÌôîÎêú Ïù¥Î¶ÑÏúºÎ°ú ÏóÖÎç∞Ïù¥Ìä∏

            // Commit ÎÖ∏Îìú ÏÉùÏÑ±/Î≥ëÌï© (Î≥µÌï© ÌÇ§: hash + repo_id, Repository ÎùºÎ≤® Ìè¨Ìï®, Î©±Îì±ÏÑ± Î≥¥Ïû•)
            MERGE (c:{repo_label}:Commit {{hash: commit.hash, repo_id: $repo_id}})
            ON CREATE SET
                c.message = commit.message,
                c.author_date = datetime(commit.author_date),
                c.committer_date = datetime(commit.committer_date),
                c.lines_added = commit.lines_added,
                c.lines_deleted = commit.lines_deleted,
                c.files_changed = commit.files_changed
            ON MATCH SET
                c.message = commit.message,
                c.author_date = datetime(commit.author_date),
                c.committer_date = datetime(commit.committer_date),
                c.lines_added = commit.lines_added,
                c.lines_deleted = commit.lines_deleted,
                c.files_changed = commit.files_changed

            // User-Commit Í¥ÄÍ≥Ñ ÏÉùÏÑ±/Î≥ëÌï©
            MERGE (u)-[:COMMITTED]->(c)

            // File ÎÖ∏Îìú Î∞è Í¥ÄÍ≥Ñ
            WITH c, commit
            UNWIND commit.modifications AS mod

            // File ÎÖ∏Îìú ÏÉùÏÑ±/Î≥ëÌï© (Î≥µÌï© ÌÇ§: path + repo_id, Repository ÎùºÎ≤® Ìè¨Ìï®)
            MERGE (f:{repo_label}:File {{path: mod.new_path, repo_id: $repo_id}})
            ON CREATE SET
                f.filename = mod.filename,
                f.old_path = mod.old_path,
                f.new_path = mod.new_path

            // Commit-File Í¥ÄÍ≥Ñ ÏÉùÏÑ±/Î≥ëÌï© (Î©±Îì±ÏÑ± Î≥¥Ïû•)
            MERGE (c)-[r:MODIFIED]->(f)
            ON CREATE SET
                r.change_type = mod.change_type,
                r.added_lines = mod.added_lines,
                r.deleted_lines = mod.deleted_lines,
                r.complexity = mod.complexity
            ON MATCH SET
                r.change_type = mod.change_type,
                r.added_lines = mod.added_lines,
                r.deleted_lines = mod.deleted_lines,
                r.complexity = mod.complexity
            """

            await self.backend.execute_query(
                query, params={"commits": batch, "repo_id": repo_id}, repo_id=repo_id
            )

            total_commits += len(batch)

            # ÌÜµÍ≥Ñ ÏàòÏßë
            for commit in batch:
                users_set.add(commit["author_email"])
                for mod in commit["modifications"]:
                    files_set.add(mod["new_path"])

            logger.info(f"üìä Neo4j: {total_commits}/{len(commits_data)} Ïª§Î∞ã Ï†ÅÏû¨ Ï§ë...")

        return {
            "total_commits": total_commits,
            "total_users": len(users_set),
            "total_files": len(files_set),
        }
