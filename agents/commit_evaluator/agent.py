"""
CommitEvaluator Agent

ê°œë³„ ì»¤ë°‹ì„ LLMìœ¼ë¡œ í‰ê°€í•˜ëŠ” ì„œë¸Œì—ì´ì „íŠ¸ (Pydantic ìŠ¤í‚¤ë§ˆ ì‚¬ìš©)
"""

import logging
import asyncio
import json
from typing import Any, Optional
from langchain_aws import ChatBedrockConverse
from langchain_core.messages import SystemMessage, HumanMessage

# Pydantic ìŠ¤í‚¤ë§ˆ
from .schemas import (
    CommitEvaluatorContext,
    CommitEvaluatorResponse,
    CommitEvaluation,
)

# ê³µí†µ ìœ í‹¸ë¦¬í‹°
from shared.utils.prompt_loader import PromptLoader
from shared.utils.token_tracker import TokenTracker

# Tools (ê¸°ì¡´ ìœ ì§€)
from shared.tools.neo4j_tools import get_commit_details
from shared.tools.chromadb_tools import search_code

logger = logging.getLogger(__name__)


class CommitEvaluatorAgent:
    """
    ê°œë³„ ì»¤ë°‹ì„ í‰ê°€í•˜ëŠ” ì„œë¸Œì—ì´ì „íŠ¸

    Level 3 ë³‘ë ¬ ì²˜ë¦¬:
    - ì»¤ë°‹ ë©”íƒ€ë°ì´í„° ì¡°íšŒ (Neo4j)
    - ê´€ë ¨ ì½”ë“œ ê²€ìƒ‰ (ChromaDB)
    - LLM í‰ê°€
    """

    def __init__(self, llm: Optional[ChatBedrockConverse] = None):
        # í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹: YAML ëª¨ë¸ ìš°ì„ , ì™¸ë¶€ LLM ì „ë‹¬ ì‹œ ì˜¤ë²„ë¼ì´ë“œ
        if llm is None:
            # YAML ì„¤ì • ê¸°ë°˜ìœ¼ë¡œ LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            self.llm = PromptLoader.get_llm("commit_evaluator")
            model_id = PromptLoader.get_model("commit_evaluator")
            logger.info(f"âœ… CommitEvaluatorAgent: YAML ëª¨ë¸ ì‚¬ìš© - {model_id}")
        else:
            # ì™¸ë¶€ ì „ë‹¬ëœ LLM ì‚¬ìš© (ì˜¤ë²„ë¼ì´ë“œ)
            self.llm = llm
            logger.info(f"âœ… CommitEvaluatorAgent: ì™¸ë¶€ LLM ì‚¬ìš©")
        
        # í•˜ì´ë¸Œë¦¬ë“œ: ìŠ¤í‚¤ë§ˆ ìë™ ì£¼ì…
        self.prompts = PromptLoader.load_with_schema(
            "commit_evaluator",
            response_schema_class=CommitEvaluation
        )

    async def run(self, context: CommitEvaluatorContext) -> CommitEvaluatorResponse:
        """
        ì»¤ë°‹ í‰ê°€ ì‹¤í–‰ (Pydantic ìŠ¤í‚¤ë§ˆ ì‚¬ìš©)

        Args:
            context: CommitEvaluatorContext (ê²€ì¦ëœ ì…ë ¥)

        Returns:
            CommitEvaluatorResponse (íƒ€ì… ì•ˆì „ ì¶œë ¥)
        """
        commit_hash = context.commit_hash
        user = context.user
        task_uuid = context.task_uuid

        logger.info(f"ğŸ“ CommitEvaluator: {commit_hash[:8]} í‰ê°€ ì‹œì‘")

        try:
            # Repository ID ìƒì„± (ì œì•½ì¡°ê±´ì´ ë³µí•© í‚¤ì´ë¯€ë¡œ í•„ìˆ˜)
            repo_id = context.repo_id
            
            # Level 3-1: ë³‘ë ¬ ë°ì´í„° ìˆ˜ì§‘
            commit_info, code_contexts = await asyncio.gather(
                # Neo4jì—ì„œ ì»¤ë°‹ ìƒì„¸ ì •ë³´ (repo_id í•„ìˆ˜)
                get_commit_details.ainvoke(
                    {
                        "commit_hash": commit_hash,
                        "repo_id": repo_id,  # ì œì•½ì¡°ê±´ì´ ë³µí•© í‚¤ì´ë¯€ë¡œ í•„ìˆ˜
                        "neo4j_uri": context.neo4j_uri,
                        "neo4j_user": context.neo4j_user,
                        "neo4j_password": context.neo4j_password,
                    }
                ),
                # ChromaDBì—ì„œ ê´€ë ¨ ì½”ë“œ ê²€ìƒ‰
                self._search_related_code(commit_hash, task_uuid),
            )

            # Level 3-2: LLM í‰ê°€
            evaluation = await self._evaluate_with_llm(
                commit_info=commit_info,
                code_contexts=code_contexts,
                user=user,
            )

            # Pydantic ëª¨ë¸ë¡œ ë³€í™˜ (ìë™ ê²€ì¦)
            commit_eval = CommitEvaluation(**evaluation)

            logger.info(
                f"âœ… CommitEvaluator: {commit_hash[:8]} - ì ìˆ˜ {commit_eval.quality_score}"
            )

            return CommitEvaluatorResponse(
                status="success",
                commit_hash=commit_hash,
                quality_score=commit_eval.quality_score,
                technologies=commit_eval.technologies,
                complexity=commit_eval.complexity,
                evaluation=commit_eval.evaluation,
                error=None,
            )

        except Exception as e:
            logger.error(f"âŒ CommitEvaluator: {commit_hash[:8]} - {e}")
            return CommitEvaluatorResponse(
                status="failed",
                commit_hash=commit_hash,
                quality_score=0.0,
                technologies=[],
                complexity="unknown",
                evaluation="",
                error=str(e),
            )

    async def _search_related_code(
        self, commit_hash: str, task_uuid: str, n_results: int = 5
    ) -> list[dict[str, Any]]:
        """
        ChromaDBì—ì„œ ì»¤ë°‹ ê´€ë ¨ ì½”ë“œ ê²€ìƒ‰
        """
        try:
            collection_name = f"code_{task_uuid}"
            results = await search_code.ainvoke(
                {
                    "query": commit_hash,  # ì»¤ë°‹ í•´ì‹œë¡œ ê²€ìƒ‰
                    "collection_name": collection_name,
                    "n_results": n_results,
                }
            )
            return results
        except Exception as e:
            logger.warning(f"âš ï¸  ì½”ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    async def _evaluate_with_llm(
        self,
        commit_info: dict[str, Any],
        code_contexts: list[dict[str, Any]],
        user: str,
    ) -> dict[str, Any]:
        """
        LLMìœ¼ë¡œ ì»¤ë°‹ í‰ê°€ (YAML í”„ë¡¬í”„íŠ¸ ì‚¬ìš©)
        """
        # YAML í”„ë¡¬í”„íŠ¸ ì‚¬ìš© (json_schema ë³€ìˆ˜ ìë™ ì£¼ì…)
        system_prompt = PromptLoader.format(
            self.prompts["system_prompt"],
            json_schema=self.prompts.get("json_schema", "")
        )

        # í…œí”Œë¦¿ ë³€ìˆ˜ ì¹˜í™˜
        user_prompt = PromptLoader.format(
            self.prompts["user_template"],
            commit_hash=commit_info.get("hash", "unknown")[:8],
            user=user,
            commit_message=commit_info.get("message", "No message"),
            files_count=len(commit_info.get("files", [])),
            lines_added=commit_info.get("lines_added", 0),
            lines_deleted=commit_info.get("lines_deleted", 0),
            code_contexts=self._format_code_contexts(code_contexts[:3]),
        )

        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_prompt),
        ]

        # í† í° ì¶”ì  (ê° ì»¤ë°‹ í‰ê°€ë§ˆë‹¤)
        response = await self.llm.ainvoke(messages)
        TokenTracker.record_usage("commit_evaluator", response, model_id=PromptLoader.get_model("commit_evaluator"))
        content = response.content

        # JSON íŒŒì‹±
        try:
            if "```json" in content:
                json_str = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                json_str = content.split("```")[1].split("```")[0].strip()
            else:
                json_str = content.strip()

            evaluation_data = json.loads(json_str)
            return evaluation_data

        except Exception as e:
            logger.warning(f"âš ï¸  LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return {
                "quality_score": 5.0,
                "technologies": [],
                "complexity": "medium",
                "evaluation": "í‰ê°€ ì‹¤íŒ¨",
            }

    def _format_code_contexts(self, contexts: list[dict[str, Any]]) -> str:
        """
        ì½”ë“œ ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…
        """
        if not contexts:
            return "ê´€ë ¨ ì½”ë“œ ì—†ìŒ"

        formatted = []
        for ctx in contexts:
            formatted.append(
                f"- {ctx['file']} (ìœ ì‚¬ë„: {ctx['score']:.2f})\n  {ctx['code'][:100]}..."
            )
        return "\n".join(formatted)
