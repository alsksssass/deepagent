"""RepoSynthesizerAgent - ì—¬ëŸ¬ ë ˆí¬ì§€í† ë¦¬ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ëŠ” ì—ì´ì „íŠ¸"""

import logging
import asyncio
import json
from pathlib import Path
from typing import Any, Dict, List, Optional
from datetime import datetime

from langchain_core.messages import SystemMessage, HumanMessage

from shared.storage import ResultStore
from shared.utils.prompt_loader import PromptLoader
from shared.utils.token_tracker import TokenTracker
from .schemas import (
    RepoSynthesizerContext,
    RepoSynthesizerResponse,
    UserAnalysisResult,
    LanguageInfo,
    LLMAnalysisResult,
)

# Response í´ë˜ìŠ¤ import (load_resultì— í•„ìš”)
from agents.static_analyzer.schemas import StaticAnalyzerResponse
from agents.user_aggregator.schemas import UserAggregatorResponse
from agents.user_skill_profiler.schemas import UserSkillProfilerResponse

logger = logging.getLogger(__name__)


class RepoSynthesizerAgent:
    """
    ì—¬ëŸ¬ ë ˆí¬ì§€í† ë¦¬ ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ëŠ” ì—ì´ì „íŠ¸

    ì£¼ìš” ê¸°ëŠ¥:
    1. ê° ë ˆí¬ì§€í† ë¦¬ ê²°ê³¼ ë¡œë“œ ë° ê²€ì¦
    2. í†µê³„ ì§‘ê³„ (ì´ ì»¤ë°‹ ìˆ˜, ì´ íŒŒì¼ ìˆ˜ ë“±)
    3. ë ˆí¬ì§€í† ë¦¬ ê°„ ë¹„êµ ë¶„ì„
    4. LLMì„ ì´ìš©í•œ ì¢…í•© ë¶„ì„ ë° ê°œì„  ë°©í–¥ ì œì‹œ
    5. ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
    """

    def __init__(self):
        """ì—ì´ì „íŠ¸ ì´ˆê¸°í™”"""
        # PromptLoaderë¡œ LLM ë¡œë“œ
        self.llm = PromptLoader.get_llm("repo_synthesizer")
        model_id = PromptLoader.get_model("repo_synthesizer")
        
        # í•˜ì´ë¸Œë¦¬ë“œ: ìŠ¤í‚¤ë§ˆ ìë™ ì£¼ì…
        self.prompts = PromptLoader.load_with_schema(
            "repo_synthesizer",
            response_schema_class=LLMAnalysisResult
        )
        
        logger.info(f"âœ… RepoSynthesizer: LLM ì´ˆê¸°í™” ì™„ë£Œ - {model_id}")

    async def run(self, context: RepoSynthesizerContext) -> RepoSynthesizerResponse:
        """
        ì—¬ëŸ¬ ë ˆí¬ì§€í† ë¦¬ ê²°ê³¼ ì¢…í•©

        Args:
            context: RepoSynthesizerContext

        Returns:
            RepoSynthesizerResponse
        """
        logger.info(f"ğŸ”¬ RepoSynthesizer: {len(context.repo_results)}ê°œ ë ˆí¬ì§€í† ë¦¬ ì¢…í•© ì‹œì‘")

        try:
            # 1. ê° ë ˆí¬ ê²°ê³¼ ìš”ì•½ ì¶”ì¶œ
            repo_summaries = await self._extract_repo_summaries(context.repo_results)

            # 2. í†µê³„ ì§‘ê³„
            total_commits = sum(s.get("total_commits", 0) for s in repo_summaries)
            total_files = sum(s.get("total_files", 0) for s in repo_summaries)
            successful = sum(1 for s in repo_summaries if s.get("status") == "success")
            failed = len(repo_summaries) - successful

            logger.info(f"   ì´ ì»¤ë°‹: {total_commits}, ì´ íŒŒì¼: {total_files}")
            logger.info(f"   ì„±ê³µ: {successful}ê°œ, ì‹¤íŒ¨: {failed}ê°œ")

            # 3. target_userê°€ ì§€ì •ëœ ê²½ìš° UserAnalysisResult ìƒì„±
            user_analysis_result = None
            if context.target_user:
                user_analysis_result = await self._generate_user_analysis_result(
                    context.repo_results,
                    context.target_user,
                    context.main_task_uuid,
                    context.main_base_path,
                )

            # 4. LLM ì¢…í•© ë¶„ì„ ë° ê°œì„  ë°©í–¥ ì œì‹œ
            llm_analysis = await self._generate_llm_analysis(
                repo_summaries=repo_summaries,
                total_commits=total_commits,
                total_files=total_files,
                successful=successful,
                failed=failed,
                target_user=context.target_user,
                user_analysis_result=user_analysis_result,
            )

            # 5. ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
            report_content = self._generate_synthesis_report(
                repo_summaries=repo_summaries,
                total_commits=total_commits,
                total_files=total_files,
                successful=successful,
                failed=failed,
                target_user=context.target_user,
                user_analysis_result=user_analysis_result,
                llm_analysis=llm_analysis,
            )

            # 6. UserAnalysisResultì˜ markdown, level, tech_stack, ì–¸ì–´ë³„ ì •ë³´ ì—…ë°ì´íŠ¸
            if user_analysis_result:
                user_analysis_result.markdown = report_content
                
                # LLMì´ ìƒì„±í•œ level ì •ë³´ë¥¼ UserAnalysisResultì—ë„ ì‚½ì…
                if llm_analysis and llm_analysis.level:
                    user_analysis_result.level = llm_analysis.level
                    logger.info(f"   UserAnalysisResult.level ì—…ë°ì´íŠ¸ ì™„ë£Œ: level={llm_analysis.level.get('level', 0)}")
                
                # LLMì´ ìƒì„±í•œ tech_stackì„ UserAnalysisResultì—ë„ ì‚½ì…
                if llm_analysis and llm_analysis.tech_stack:
                    user_analysis_result.tech_stack = llm_analysis.tech_stack
                    logger.info(f"   UserAnalysisResult.tech_stack ì—…ë°ì´íŠ¸ ì™„ë£Œ: {len(llm_analysis.tech_stack)}ê°œ ê¸°ìˆ ")
                
                # LLMì´ ìƒì„±í•œ ì–¸ì–´ë³„ ì •ë³´ë¥¼ UserAnalysisResultì— ë™ì  í•„ë“œë¡œ ì‚½ì…
                if llm_analysis:
                    for attr_name in dir(llm_analysis):
                        if not attr_name.startswith('_') and attr_name not in [
                            'overall_assessment', 'strengths', 'improvement_recommendations',
                            'role_suitability', 'level', 'tech_stack', 'model_config',
                            'model_fields', 'model_computed_fields', 'model_dump', 'model_dump_json',
                            'model_validate', 'model_validate_json', 'model_copy', 'model_post_init',
                            'model_json_schema', 'model_parametrized_name', 'model_rebuild', 'model_fields_set'
                        ]:
                            attr_value = getattr(llm_analysis, attr_name, None)
                            # LanguageInfo íƒ€ì…ì¸ì§€ í™•ì¸ (dict with stack, level, exp)
                            if isinstance(attr_value, dict) and all(k in attr_value for k in ['stack', 'level', 'exp']):
                                lang_info = LanguageInfo(**attr_value)
                                setattr(user_analysis_result, attr_name, lang_info)
                                logger.info(f"   UserAnalysisResult.{attr_name} ì—…ë°ì´íŠ¸ ì™„ë£Œ")
                            elif isinstance(attr_value, LanguageInfo):
                                setattr(user_analysis_result, attr_name, attr_value)
                                logger.info(f"   UserAnalysisResult.{attr_name} ì—…ë°ì´íŠ¸ ì™„ë£Œ")
                
                logger.info("   UserAnalysisResult.markdownì— ì „ì²´ ë¦¬í¬íŠ¸ ë‚´ìš© ì—…ë°ì´íŠ¸ ì™„ë£Œ")

            # 7. ë¦¬í¬íŠ¸ ì €ì¥
            main_store = ResultStore(context.main_task_uuid, Path(context.main_base_path))
            report_path = main_store.save_report("synthesis_report.md", report_content)

            logger.info(f"âœ… RepoSynthesizer: ì¢…í•© ì™„ë£Œ")
            logger.info(f"   ë¦¬í¬íŠ¸: {report_path}")

            return RepoSynthesizerResponse(
                status="success",
                total_repos=len(repo_summaries),
                successful_repos=successful,
                failed_repos=failed,
                total_commits=total_commits,
                total_files=total_files,
                synthesis_report_path=str(report_path),
                synthesis_report_markdown=report_content,
                repo_summaries=repo_summaries,
                user_analysis_result=user_analysis_result,
                llm_analysis=llm_analysis,
            )

        except Exception as e:
            logger.error(f"âŒ RepoSynthesizer ì‹¤íŒ¨: {e}", exc_info=True)
            return RepoSynthesizerResponse(
                status="failed",
                error=str(e),
            )

    async def _extract_repo_summaries(
        self, repo_results: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """ê° ë ˆí¬ì§€í† ë¦¬ ê²°ê³¼ ìš”ì•½ ì¶”ì¶œ"""
        summaries = []

        for result in repo_results:
            try:
                # ì—ëŸ¬ ë°œìƒí•œ ë ˆí¬ ì²˜ë¦¬
                if result.get("error_message"):
                    summaries.append({
                        "git_url": result.get("git_url", "unknown"),
                        "task_uuid": result.get("task_uuid", ""),
                        "status": "failed",
                        "error": result.get("error_message"),
                        "total_commits": 0,
                        "total_files": 0,
                    })
                    continue

                # ì„±ê³µí•œ ë ˆí¬ ìš”ì•½
                task_uuid = result.get("task_uuid", "")
                base_path = result.get("base_path", "")

                # ResultStoreì—ì„œ ì¶”ê°€ ì •ë³´ ë¡œë“œ ì‹œë„
                try:
                    if task_uuid and base_path:
                        store = ResultStore(task_uuid, Path(base_path))
                        
                        # UserAggregator ê²°ê³¼ ë¡œë“œ (í’ˆì§ˆ ì ìˆ˜ ë“±)
                        user_agg_response = store.load_result("user_aggregator", UserAggregatorResponse)
                        user_agg = user_agg_response.model_dump() if user_agg_response else None
                        quality_score = None
                        if user_agg and user_agg.get("aggregate_stats"):
                            quality_stats = user_agg["aggregate_stats"].get("quality_stats", {})
                            quality_score = quality_stats.get("mean_score")

                        summaries.append({
                            "git_url": result.get("git_url", ""),
                            "task_uuid": task_uuid,
                            "base_path": base_path,
                            "status": "success",
                            "total_commits": result.get("total_commits", 0),
                            "total_files": result.get("total_files", 0),
                            "final_report_path": result.get("final_report_path"),
                            "quality_score": quality_score,
                        })
                    else:
                        summaries.append({
                            "git_url": result.get("git_url", ""),
                            "task_uuid": task_uuid,
                            "base_path": base_path,
                            "status": "success",
                            "total_commits": result.get("total_commits", 0),
                            "total_files": result.get("total_files", 0),
                        })
                except Exception as e:
                    logger.warning(f"âš ï¸ ResultStore ë¡œë“œ ì‹¤íŒ¨: {e}")
                    summaries.append({
                        "git_url": result.get("git_url", ""),
                        "task_uuid": task_uuid,
                        "base_path": base_path,
                        "status": "success",
                        "total_commits": result.get("total_commits", 0),
                        "total_files": result.get("total_files", 0),
                    })

            except Exception as e:
                logger.warning(f"âš ï¸ ë ˆí¬ ìš”ì•½ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                summaries.append({
                    "git_url": result.get("git_url", "unknown"),
                    "status": "failed",
                    "error": str(e),
                })

        return summaries


    async def _generate_llm_analysis(
        self,
        repo_summaries: List[Dict[str, Any]],
        total_commits: int,
        total_files: int,
        successful: int,
        failed: int,
        target_user: str | None,
        user_analysis_result: Optional[UserAnalysisResult],
    ) -> Optional[LLMAnalysisResult]:
        """
        LLMì„ ì´ìš©í•œ ì¢…í•© ë¶„ì„ ë° ê°œì„  ë°©í–¥ ì œì‹œ
        
        Returns:
            LLMAnalysisResult ë˜ëŠ” None
        """
        try:
            # ë ˆí¬ì§€í† ë¦¬ ìš”ì•½ í¬ë§·íŒ…
            repo_summaries_text = self._format_repo_summaries(repo_summaries)
            
            # ê° repoì˜ ìƒì„¸ JSON ë°ì´í„° ìˆ˜ì§‘
            repo_json_data = await self._collect_repo_json_data(repo_summaries)
            
            # ìœ ì € ë¶„ì„ ê²°ê³¼ í¬ë§·íŒ…
            user_analysis_text = ""
            if user_analysis_result:
                user_analysis_text = self._format_user_analysis_result(user_analysis_result)
            
            # í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜ ì¤€ë¹„
            prompt_variables = {
                "total_repos": len(repo_summaries),
                "successful_repos": successful,
                "failed_repos": failed,
                "total_commits": total_commits,
                "total_files": total_files,
                "target_user": target_user if target_user else "ì „ì²´ ìœ ì €",
                "repo_summaries": repo_summaries_text,
                "repo_json_data": repo_json_data,
                "user_analysis_result": user_analysis_text if user_analysis_text else "ì—†ìŒ",
            }
            
            # í”„ë¡¬í”„íŠ¸ ìƒì„± (json_schema ë³€ìˆ˜ ìë™ ì£¼ì…)
            system_prompt = PromptLoader.format(
                self.prompts["system_prompt"],
                json_schema=self.prompts.get("json_schema", "")
            )
            user_prompt = PromptLoader.format(
                self.prompts["user_template"],
                **prompt_variables
            )
            
            # LLM í˜¸ì¶œ
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt),
            ]
            
            logger.info("ğŸ¤– LLM ì¢…í•© ë¶„ì„ ì‹œì‘...")
            response = await self.llm.ainvoke(messages)
            TokenTracker.record_usage(
                "repo_synthesizer",
                response,
                model_id=PromptLoader.get_model("repo_synthesizer")
            )
            
            # JSON íŒŒì‹±
            content = response.content
            try:
                if "```json" in content:
                    json_str = content.split("```json")[1].split("```")[0].strip()
                elif "```" in content:
                    json_str = content.split("```")[1].split("```")[0].strip()
                else:
                    json_str = content.strip()
                
                analysis_data = json.loads(json_str)
                
                # ëˆ„ë½ëœ í•„ë“œ ë³´ì™„ (category í•„ë“œê°€ ì—†ëŠ” ê²½ìš°)
                if "improvement_recommendations" in analysis_data:
                    for rec in analysis_data["improvement_recommendations"]:
                        if "category" not in rec or not rec.get("category"):
                            # titleì—ì„œ ì¹´í…Œê³ ë¦¬ë¥¼ ì¶”ë¡ í•˜ê±°ë‚˜ ê¸°ë³¸ê°’ ì‚¬ìš©
                            rec["category"] = "ì¼ë°˜"
                
                # Pydantic ëª¨ë¸ë¡œ ë³€í™˜
                try:
                    llm_result = LLMAnalysisResult(**analysis_data)
                    logger.info("âœ… LLM ì¢…í•© ë¶„ì„ ì™„ë£Œ")
                    return llm_result
                except Exception as validation_error:
                    # Pydantic ê²€ì¦ ì‹¤íŒ¨ ì‹œ ë” ìì„¸í•œ ë¡œê¹…
                    logger.warning(f"âš ï¸ LLM ì‘ë‹µ ê²€ì¦ ì‹¤íŒ¨: {validation_error}")
                    logger.debug(f"ì‘ë‹µ ë°ì´í„°: {json.dumps(analysis_data, indent=2, ensure_ascii=False)[:1000]}")
                    # ê¸°ë³¸ê°’ìœ¼ë¡œ ì¬ì‹œë„
                    try:
                        # í•„ìˆ˜ í•„ë“œê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
                        if "overall_assessment" not in analysis_data:
                            analysis_data["overall_assessment"] = "ë¶„ì„ ê²°ê³¼ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                        if "strengths" not in analysis_data:
                            analysis_data["strengths"] = []
                        if "improvement_recommendations" not in analysis_data:
                            analysis_data["improvement_recommendations"] = []
                        
                        llm_result = LLMAnalysisResult(**analysis_data)
                        logger.info("âœ… LLM ì¢…í•© ë¶„ì„ ì™„ë£Œ (ê¸°ë³¸ê°’ ë³´ì™„)")
                        return llm_result
                    except Exception as e2:
                        logger.warning(f"âš ï¸ LLM ì‘ë‹µ ë³µêµ¬ ì‹¤íŒ¨: {e2}")
                        return None
                
            except json.JSONDecodeError as e:
                logger.warning(f"âš ï¸ LLM ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                logger.debug(f"ì‘ë‹µ ë‚´ìš©: {content[:500]}")
                return None
            except Exception as e:
                logger.warning(f"âš ï¸ LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
                logger.debug(f"ì‘ë‹µ ë‚´ìš©: {content[:500]}")
                return None
                
        except Exception as e:
            logger.error(f"âŒ LLM ë¶„ì„ ì‹¤íŒ¨: {e}", exc_info=True)
            return None

    async def _collect_repo_json_data(self, repo_summaries: List[Dict[str, Any]]) -> str:
        """
        ê° ë ˆí¬ì§€í† ë¦¬ì˜ ìƒì„¸ JSON ë°ì´í„° ìˆ˜ì§‘
        
        Returns:
            JSON í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…ëœ ë¬¸ìì—´
        """
        repo_json_list = []
        
        for summary in repo_summaries:
            if summary.get("status") != "success":
                continue
            
            task_uuid = summary.get("task_uuid", "")
            base_path = summary.get("base_path")
            git_url = summary.get("git_url", "")
            
            if not task_uuid or not base_path:
                continue
            
            try:
                store = ResultStore(task_uuid, Path(base_path))
                
                # ì£¼ìš” ë¶„ì„ ê²°ê³¼ ë¡œë“œ
                repo_data = {
                    "git_url": git_url,
                    "task_uuid": task_uuid,
                }
                
                # StaticAnalyzer ê²°ê³¼ (í•µì‹¬ ì •ë³´ë§Œ)
                try:
                    static_response = store.load_result("static_analyzer", StaticAnalyzerResponse)
                    if static_response:
                        static_dict = static_response.model_dump()
                        # í•µì‹¬ ì •ë³´ë§Œ ì¶”ì¶œ (ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í•„ë“œ)
                        repo_data["static_analysis"] = {
                            "loc_stats": static_dict.get("loc_stats", {}),
                            "complexity": static_dict.get("complexity", {}),
                            "type_check": static_dict.get("type_check", {}),
                        }
                except Exception as e:
                    logger.debug(f"Static analyzer ë¡œë“œ ì‹¤íŒ¨: {e}")
                
                # UserAggregator ê²°ê³¼ (ì „ì²´ í†µê³„)
                try:
                    user_agg_response = store.load_result("user_aggregator", UserAggregatorResponse)
                    if user_agg_response:
                        agg_dict = user_agg_response.model_dump()
                        # aggregate_stats ì „ì²´ í¬í•¨ (í’ˆì§ˆ, ê¸°ìˆ , ë³µì¡ë„ í†µê³„)
                        repo_data["user_aggregator"] = {
                            "aggregate_stats": agg_dict.get("aggregate_stats", {})
                        }
                except Exception as e:
                    logger.debug(f"User aggregator ë¡œë“œ ì‹¤íŒ¨: {e}")
                
                # UserSkillProfiler ê²°ê³¼ (ë¶„ì„ì— í•µì‹¬ì ì¸ í•„ë“œë§Œ)
                try:
                    skill_profile_response = store.load_result("user_skill_profiler", UserSkillProfilerResponse)
                    if skill_profile_response:
                        skill_dict = skill_profile_response.model_dump()
                        skill_profile_data = skill_dict.get("skill_profile", {})
                        
                        # í•µì‹¬ ì •ë³´ë§Œ ì¶”ì¶œ (ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í•„ë“œ)
                        repo_data["skill_profile"] = {
                            "total_skills": skill_profile_data.get("total_skills", 0),
                            "skills_by_level": skill_profile_data.get("skills_by_level", {}),
                            "skills_by_category": skill_profile_data.get("skills_by_category", {}),
                            "top_skills": skill_profile_data.get("top_skills", [])[:10],  # ìƒìœ„ 10ê°œë§Œ
                            "total_experience": skill_profile_data.get("total_experience", 0),
                            "level": skill_profile_data.get("level", {}),
                            "developer_type_coverage": skill_profile_data.get("developer_type_coverage", {}),
                            "developer_type_levels": skill_profile_data.get("developer_type_levels", {}),
                            "category_coverage": skill_profile_data.get("category_coverage", {}),
                            "total_coverage": skill_profile_data.get("total_coverage", 0),
                        }
                except Exception as e:
                    logger.debug(f"Skill profiler ë¡œë“œ ì‹¤íŒ¨: {e}")
                
                repo_json_list.append(repo_data)
                
            except Exception as e:
                logger.warning(f"âš ï¸ ë ˆí¬ì§€í† ë¦¬ {git_url} JSON ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                continue
        
        if not repo_json_list:
            logger.warning("   ë ˆí¬ì§€í† ë¦¬ JSON ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
            return "ë ˆí¬ì§€í† ë¦¬ JSON ë°ì´í„° ì—†ìŒ"
        
        logger.info(f"   ìˆ˜ì§‘ëœ JSON ë°ì´í„°: {len(repo_json_list)}ê°œ ë ˆí¬ì§€í† ë¦¬")
        
        # JSON í¬ë§·íŒ… (ê°€ë…ì„±ì„ ìœ„í•´ ë“¤ì—¬ì“°ê¸°)
        json_str = json.dumps(repo_json_list, indent=2, ensure_ascii=False)
        logger.info(f"   JSON ë°ì´í„° í¬ê¸°: {len(json_str):,} ë¬¸ì")
        
        return json_str

    def _format_repo_summaries(self, repo_summaries: List[Dict[str, Any]]) -> str:
        """ë ˆí¬ì§€í† ë¦¬ ìš”ì•½ í¬ë§·íŒ…"""
        formatted = []
        for i, summary in enumerate(repo_summaries, 1):
            status_emoji = "âœ…" if summary.get("status") == "success" else "âŒ"
            git_url = summary.get("git_url", "unknown")
            
            repo_text = f"\n{i}. {status_emoji} {git_url}\n"
            if summary.get("status") == "success":
                repo_text += f"   - ì»¤ë°‹ ìˆ˜: {summary.get('total_commits', 0):,}ê°œ\n"
                repo_text += f"   - íŒŒì¼ ìˆ˜: {summary.get('total_files', 0):,}ê°œ\n"
                if summary.get("quality_score") is not None:
                    repo_text += f"   - í’ˆì§ˆ ì ìˆ˜: {summary.get('quality_score'):.2f}/10\n"
            else:
                repo_text += f"   - ì—ëŸ¬: {summary.get('error', 'Unknown error')}\n"
            
            formatted.append(repo_text)
        
        return "\n".join(formatted)

    def _format_user_analysis_result(self, user_analysis_result: UserAnalysisResult) -> str:
        """ìœ ì € ë¶„ì„ ê²°ê³¼ í¬ë§·íŒ…"""
        formatted = []
        
        formatted.append(f"ì½”ë“œ í’ˆì§ˆ ì ìˆ˜: {user_analysis_result.clean_code:.2f}/10")
        
        if user_analysis_result.role:
            formatted.append(f"\nì—­í• ë³„ ê¸°ìˆ ìŠ¤íƒ ë³´ìœ ìœ¨:")
            for role, percentage in sorted(user_analysis_result.role.items(), key=lambda x: x[1], reverse=True):
                formatted.append(f"  - {role}: {percentage}%")
        
        if hasattr(user_analysis_result, 'python') and user_analysis_result.python:
            python = user_analysis_result.python
            formatted.append(f"\nPython ë¶„ì„:")
            formatted.append(f"  - ìˆ™ë ¨ë„ ë ˆë²¨: {python.level}")
            formatted.append(f"  - ê²½í—˜ì¹˜: {python.exp:,}")
            if python.stack:
                formatted.append(f"  - ê¸°ìˆ  ìŠ¤íƒ: {', '.join(python.stack)}")
        
        return "\n".join(formatted)

    async def _generate_user_analysis_result(
        self,
        repo_results: List[Dict[str, Any]],
        target_user: str,
        main_task_uuid: str,
        main_base_path: str,
    ) -> Optional[UserAnalysisResult]:
        """
        target_userì˜ ì¢…í•© ë¶„ì„ ê²°ê³¼ ìƒì„±
        
        Returns:
            UserAnalysisResult ë˜ëŠ” None
        """
        try:
            # ëª¨ë“  ë ˆí¬ì§€í† ë¦¬ì—ì„œ ë°ì´í„° ìˆ˜ì§‘
            all_quality_scores = []  # í’ˆì§ˆ ì ìˆ˜ ë¦¬ìŠ¤íŠ¸
            all_developer_type_coverage = {}  # ì—­í• ë³„ ì»¤ë²„ë¦¬ì§€
            
            for result in repo_results:
                if result.get("error_message"):
                    continue
                    
                task_uuid = result.get("task_uuid", "")
                base_path = result.get("base_path", "")
                
                if not task_uuid or not base_path:
                    continue
                
                try:
                    store = ResultStore(task_uuid, Path(base_path))
                    
                    # 1. UserAggregator ê²°ê³¼ì—ì„œ í’ˆì§ˆ ì ìˆ˜ ìˆ˜ì§‘
                    user_agg_response = store.load_result("user_aggregator", UserAggregatorResponse)
                    user_agg = user_agg_response.model_dump() if user_agg_response else None
                    if user_agg and user_agg.get("aggregate_stats"):
                        quality_stats = user_agg["aggregate_stats"].get("quality_stats", {})
                        avg_score = quality_stats.get("average_score")
                        if avg_score is not None:
                            all_quality_scores.append(avg_score)
                    
                    # 2. UserSkillProfiler ê²°ê³¼ì—ì„œ ì—­í• ë³„ ì»¤ë²„ë¦¬ì§€ ìˆ˜ì§‘
                    skill_profile_response = store.load_result("user_skill_profiler", UserSkillProfilerResponse)
                    skill_profile = skill_profile_response.model_dump() if skill_profile_response else None
                    
                    if skill_profile and skill_profile.get("skill_profile"):
                        dev_type_coverage = skill_profile["skill_profile"].get("developer_type_coverage", {})
                        for role, coverage_data in dev_type_coverage.items():
                            if role not in all_developer_type_coverage:
                                all_developer_type_coverage[role] = []
                            percentage = coverage_data.get("percentage", 0)
                            if percentage is not None:
                                all_developer_type_coverage[role].append(percentage)
                
                except Exception as e:
                    logger.warning(f"âš ï¸ ë ˆí¬ì§€í† ë¦¬ {task_uuid} ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                    continue
            
            # ë°ì´í„° ì§‘ê³„
            logger.info(f"   í’ˆì§ˆ ì ìˆ˜: {len(all_quality_scores)}ê°œ")
            logger.info(f"   ì—­í•  ì»¤ë²„ë¦¬ì§€: {list(all_developer_type_coverage.keys())}")
            
            # 1. clean_code ì ìˆ˜ ê³„ì‚° (í‰ê· )
            clean_code_score = 0.0
            if all_quality_scores:
                clean_code_score = sum(all_quality_scores) / len(all_quality_scores)
            
            # 2. role í¼ì„¼íŠ¸ ê³„ì‚° (ê° ì—­í• ë³„ í‰ê· )
            role_percentages = {}
            for role, percentages in all_developer_type_coverage.items():
                if percentages:
                    role_percentages[role] = int(sum(percentages) / len(percentages))
            
            # UserAnalysisResult ìƒì„± (ê¸°ë³¸ ì •ë³´ë§Œ, ì–¸ì–´ë³„ ì •ë³´ëŠ” LLMì´ ìƒì„±í•˜ì—¬ ë‚˜ì¤‘ì— ì‚½ì…)
            result = UserAnalysisResult(
                python=LanguageInfo(),  # ë¹ˆ ì´ˆê¸°ê°’, LLMì´ ì±„ì›€
                clean_code=round(clean_code_score, 2),
                role=role_percentages,
                markdown="",  # ë‚˜ì¤‘ì— ì „ì²´ ë¦¬í¬íŠ¸ë¡œ ì±„ì›€
            )
            
            logger.info(f"âœ… UserAnalysisResult ê¸°ë³¸ ìƒì„± ì™„ë£Œ (ì–¸ì–´ë³„ ì •ë³´ëŠ” LLMì´ ìƒì„± ì˜ˆì •)")
            return result
            
        except Exception as e:
            logger.error(f"âŒ UserAnalysisResult ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
            return None


    def _generate_synthesis_report(
        self,
        repo_summaries: List[Dict[str, Any]],
        total_commits: int,
        total_files: int,
        successful: int,
        failed: int,
        target_user: str | None,
        user_analysis_result: Optional[UserAnalysisResult] = None,
        llm_analysis: Optional[LLMAnalysisResult] = None,
    ) -> str:
        """ì¢…í•© ë¦¬í¬íŠ¸ ë§ˆí¬ë‹¤ìš´ ìƒì„±"""
        
        is_single = len(repo_summaries) == 1
        title = "Repository Analysis - Synthesis Report" if is_single else "Multi-Repository Analysis - Synthesis Report"
        
        report = f"""# {title}

**ìƒì„± ì‹œê°„**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
**ë¶„ì„ ëŒ€ìƒ ìœ ì €**: {target_user if target_user else "ì „ì²´ ìœ ì €"}

---

## ğŸ“Š Executive Summary

- **ì´ ë ˆí¬ì§€í† ë¦¬ ìˆ˜**: {len(repo_summaries)}ê°œ
- **ì„±ê³µ**: {successful}ê°œ
- **ì‹¤íŒ¨**: {failed}ê°œ
- **ì´ ë¶„ì„ ì»¤ë°‹ ìˆ˜**: {total_commits:,}ê°œ
- **ì´ ë¶„ì„ íŒŒì¼ ìˆ˜**: {total_files:,}ê°œ

---

"""

        # target_userê°€ ìˆê³  user_analysis_resultê°€ ìˆìœ¼ë©´ ì¶”ê°€
        if target_user and user_analysis_result:
            report += user_analysis_result.markdown
            report += "\n---\n\n"

        # LLM ë¶„ì„ ê²°ê³¼ ì¶”ê°€
        if llm_analysis:
            report += "## ğŸ¤– LLM ì¢…í•© ë¶„ì„ ë° ê°œì„  ë°©í–¥\n\n"
            
            # ë ˆë²¨ ì •ë³´ (ìµœìƒë‹¨ í‘œì‹œ)
            if llm_analysis.level:
                level_info = llm_analysis.level
                report += "### ğŸ¯ ê°œë°œì ë ˆë²¨\n\n"
                report += f"**ë ˆë²¨**: {level_info.get('level', 0)}\n"
                report += f"**ì´ ê²½í—˜ì¹˜**: {level_info.get('experience', 0):,}\n"
                report += f"**í˜„ì¬ ë ˆë²¨ ê²½í—˜ì¹˜**: {level_info.get('current_level_exp', 0):,} / {level_info.get('next_level_exp', 0):,}\n"
                report += f"**ì§„í–‰ë¥ **: {level_info.get('progress_percentage', 0):.1f}%\n\n"
            
            # ê¸°ìˆ  ìŠ¤íƒ (ë ˆë²¨ ë‹¤ìŒ í‘œì‹œ)
            if llm_analysis.tech_stack:
                report += "### ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ\n\n"
                # 5ê°œì”© ì¤„ë°”ê¿ˆí•˜ì—¬ í‘œì‹œ
                for i in range(0, len(llm_analysis.tech_stack), 5):
                    chunk = llm_analysis.tech_stack[i:i+5]
                    report += f"`{'` Â· `'.join(chunk)}`\n"
                report += "\n"
            
            report += f"### ì¢…í•© í‰ê°€\n\n{llm_analysis.overall_assessment}\n\n"
            
            if llm_analysis.strengths:
                report += "### ê°•ì  ë¶„ì„\n\n"
                for strength in llm_analysis.strengths:
                    report += f"- {strength}\n"
                report += "\n"
            
            if llm_analysis.improvement_recommendations:
                report += "### ê°œì„  ë°©í–¥\n\n"
                for rec in llm_analysis.improvement_recommendations:
                    report += f"#### {rec.priority} - {rec.title}\n\n"
                    report += f"**ì¹´í…Œê³ ë¦¬**: {rec.category}\n\n"
                    report += f"{rec.description}\n\n"
                    if rec.action_items:
                        report += "**ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜**:\n"
                        for action in rec.action_items:
                            report += f"- {action}\n"
                    report += "\n"
            
            if llm_analysis.role_suitability:
                report += "### ì—­í•  ì í•©ì„± í‰ê°€\n\n"
                for role, assessment in llm_analysis.role_suitability.items():
                    report += f"- **{role}**: {assessment}\n"
                report += "\n"

        # LLM ë¶„ì„ì´ ì—†ëŠ” ê²½ìš° ì•ˆë‚´ ë©”ì‹œì§€
        if not llm_analysis:
            report += "## ğŸ“ Notes\n\n"
            report += "LLM ë¶„ì„ì´ ì‹¤íŒ¨í•˜ì—¬ ìƒì„¸ í‰ê°€ì™€ ê°œì„  ë°©í–¥ì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"

        return report

