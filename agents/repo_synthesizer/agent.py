"""RepoSynthesizerAgent - ì—¬ëŸ¬ ë ˆí¬ì§€í† ë¦¬ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ëŠ” ì—ì´ì „íŠ¸"""

import logging
import asyncio
import json
import os
from pathlib import Path
from typing import Any, Dict, List, Optional
from datetime import datetime

from langchain_core.messages import SystemMessage, HumanMessage

from shared.storage import ResultStore
from shared.utils.prompt_loader import PromptLoader
from shared.utils.token_tracker import TokenTracker
from shared.utils.skill_level_calculator import SkillLevelCalculator
from .schemas import (
    RepoSynthesizerContext,
    RepoSynthesizerResponse,
    UserAnalysisResult,
    LanguageInfo,
    LLMAnalysisResult,
)

# Response í´ë˜ìŠ¤ import (load_resultì— í•„ìš”)
from agents.static_analyzer.schemas import StaticAnalyzerResponse
from agents.user_aggregator.schemas import UserAggregatorResponse
from agents.user_skill_profiler.schemas import UserSkillProfilerResponse
from agents.reporter.schemas import ReporterResponse

logger = logging.getLogger(__name__)


class RepoSynthesizerAgent:
    """
    ì—¬ëŸ¬ ë ˆí¬ì§€í† ë¦¬ ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ëŠ” ì—ì´ì „íŠ¸

    ì£¼ìš” ê¸°ëŠ¥:
    1. ê° ë ˆí¬ì§€í† ë¦¬ ê²°ê³¼ ë¡œë“œ ë° ê²€ì¦
    2. í†µê³„ ì§‘ê³„ (ì´ ì»¤ë°‹ ìˆ˜, ì´ íŒŒì¼ ìˆ˜ ë“±)
    3. ë ˆí¬ì§€í† ë¦¬ ê°„ ë¹„êµ ë¶„ì„
    4. LLMì„ ì´ìš©í•œ ì¢…í•© ë¶„ì„ ë° ê°œì„  ë°©í–¥ ì œì‹œ
    5. ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
    """

    def __init__(self):
        """ì—ì´ì „íŠ¸ ì´ˆê¸°í™”"""
        # PromptLoaderë¡œ LLM ë¡œë“œ
        self.llm = PromptLoader.get_llm("repo_synthesizer")
        model_id = PromptLoader.get_model("repo_synthesizer")
        
        # í•˜ì´ë¸Œë¦¬ë“œ: ìŠ¤í‚¤ë§ˆ ìë™ ì£¼ì…
        self.prompts = PromptLoader.load_with_schema(
            "repo_synthesizer",
            response_schema_class=LLMAnalysisResult
        )
        
        logger.info(f"âœ… RepoSynthesizer: LLM ì´ˆê¸°í™” ì™„ë£Œ - {model_id}")

    async def run(self, context: RepoSynthesizerContext) -> RepoSynthesizerResponse:
        """
        ì—¬ëŸ¬ ë ˆí¬ì§€í† ë¦¬ ê²°ê³¼ ì¢…í•©

        Args:
            context: RepoSynthesizerContext

        Returns:
            RepoSynthesizerResponse
        """
        logger.info(f"ğŸ”¬ RepoSynthesizer: {len(context.repo_results)}ê°œ ë ˆí¬ì§€í† ë¦¬ ì¢…í•© ì‹œì‘")

        try:
            # 1. ê° ë ˆí¬ ê²°ê³¼ ìš”ì•½ ì¶”ì¶œ
            repo_summaries = await self._extract_repo_summaries(context.repo_results)

            # 2. í†µê³„ ì§‘ê³„
            total_commits = sum(s.get("total_commits", 0) for s in repo_summaries)
            total_files = sum(s.get("total_files", 0) for s in repo_summaries)
            successful = sum(1 for s in repo_summaries if s.get("status") == "success")
            failed = len(repo_summaries) - successful

            logger.info(f"   ì´ ì»¤ë°‹: {total_commits}, ì´ íŒŒì¼: {total_files}")
            logger.info(f"   ì„±ê³µ: {successful}ê°œ, ì‹¤íŒ¨: {failed}ê°œ")

            # 3. UserAnalysisResult ìƒì„±
            user_analysis_result = await self._generate_user_analysis_result(
                context.repo_results,
                context.main_task_uuid,
                context.main_base_path,
            )
            context.user_analysis_result = user_analysis_result

            # 4. LLM ì¢…í•© ë¶„ì„ ë° ê°œì„  ë°©í–¥ ì œì‹œ
            llm_analysis = await self._generate_llm_analysis(
                repo_summaries=repo_summaries,
                total_commits=total_commits,
                total_files=total_files,
                successful=successful,
                failed=failed,
                target_user=context.target_user,
                user_analysis_result=user_analysis_result,
                context=context,  # ë””ë²„ê¹…ìš© context ì „ë‹¬
            )

            # 5. ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
            report_content = self._generate_synthesis_report(
                repo_summaries=repo_summaries,
                total_commits=total_commits,
                total_files=total_files,
                successful=successful,
                failed=failed,
                target_user=context.target_user,
                user_analysis_result=user_analysis_result,
                llm_analysis=llm_analysis,
            )

            # 6. UserAnalysisResultì˜ markdown, ì–¸ì–´ë³„ ì •ë³´ ì—…ë°ì´íŠ¸
            if user_analysis_result:
                user_analysis_result.markdown = report_content
                
                # LLMì´ ìƒì„±í•œ ì–¸ì–´ë³„ ì •ë³´ë¥¼ UserAnalysisResultì— ë™ì  í•„ë“œë¡œ ì‚½ì…
                if llm_analysis:
                    for attr_name in dir(llm_analysis):
                        if not attr_name.startswith('_') and attr_name not in [
                            'overall_assessment',
                            'strengths',
                            'improvement_recommendations',
                            'role_suitability',
                            'model_config',
                            'model_fields',
                            'model_computed_fields',
                            'model_dump',
                            'model_dump_json',
                            'model_validate',
                            'model_validate_json',
                            'model_copy',
                            'model_post_init',
                            'model_json_schema',
                            'model_parametrized_name',
                            'model_rebuild',
                            'model_fields_set'
                        ]:
                            attr_value = getattr(llm_analysis, attr_name, None)
                            # LanguageInfo íƒ€ì…ì¸ì§€ í™•ì¸
                            if isinstance(attr_value, dict) and all(
                                k in attr_value
                                for k in ['stack', 'level', 'exp']
                            ):
                                lang_info = LanguageInfo(**attr_value)
                                setattr(
                                    user_analysis_result,
                                    attr_name,
                                    lang_info
                                )
                                logger.info(
                                    f"   UserAnalysisResult.{attr_name} "
                                    f"ì—…ë°ì´íŠ¸ ì™„ë£Œ"
                                )
                            elif isinstance(attr_value, LanguageInfo):
                                setattr(
                                    user_analysis_result,
                                    attr_name,
                                    attr_value
                                )
                                logger.info(
                                    f"   UserAnalysisResult.{attr_name} "
                                    f"ì—…ë°ì´íŠ¸ ì™„ë£Œ"
                                )
                
                logger.info(
                    "   UserAnalysisResult.markdownì— "
                    "ì „ì²´ ë¦¬í¬íŠ¸ ë‚´ìš© ì—…ë°ì´íŠ¸ ì™„ë£Œ"
                )

            # 7. ë¦¬í¬íŠ¸ ì €ì¥
            main_store = ResultStore(context.main_task_uuid, Path(context.main_base_path))
            report_path = main_store.save_report("synthesis_report.md", report_content)

            logger.info(f"âœ… RepoSynthesizer: ì¢…í•© ì™„ë£Œ")
            logger.info(f"   ë¦¬í¬íŠ¸: {report_path}")

            return RepoSynthesizerResponse(
                status="success",
                total_repos=len(repo_summaries),
                successful_repos=successful,
                failed_repos=failed,
                total_commits=total_commits,
                total_files=total_files,
                synthesis_report_path=str(report_path),
                synthesis_report_markdown=report_content,
                repo_summaries=repo_summaries,
                user_analysis_result=user_analysis_result,
                llm_analysis=llm_analysis,
            )

        except Exception as e:
            logger.error(f"âŒ RepoSynthesizer ì‹¤íŒ¨: {e}", exc_info=True)
            import traceback
            logger.error(f"ìƒì„¸ Traceback:\n{traceback.format_exc()}")
            return RepoSynthesizerResponse(
                status="failed",
                error=str(e),
            )

    async def _extract_repo_summaries(
        self, repo_results: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """ê° ë ˆí¬ì§€í† ë¦¬ ê²°ê³¼ ìš”ì•½ ì¶”ì¶œ"""
        summaries = []

        for result in repo_results:
            try:
                # ì—ëŸ¬ ë°œìƒí•œ ë ˆí¬ ì²˜ë¦¬
                if result.get("error_message"):
                    summaries.append({
                        "git_url": result.get("git_url", "unknown"),
                        "task_uuid": result.get("task_uuid", ""),
                        "status": "failed",
                        "error": result.get("error_message"),
                        "total_commits": 0,
                        "total_files": 0,
                    })
                    continue

                # ì„±ê³µí•œ ë ˆí¬ ìš”ì•½
                task_uuid = result.get("task_uuid", "")
                base_path = result.get("base_path", "")

                # ResultStoreì—ì„œ ì¶”ê°€ ì •ë³´ ë¡œë“œ ì‹œë„
                try:
                    if task_uuid and base_path:
                        logger.info(f"ğŸ” ResultStore ì´ˆê¸°í™” (ìš”ì•½ ì¶”ì¶œ): task_uuid={task_uuid}, base_path={base_path}")
                        store = ResultStore(task_uuid, Path(base_path))
                        
                        # Reporter ê²°ê³¼ ë¡œë“œ (ë©”íƒ€ë°ì´í„°)
                        reporter_response = None
                        try:
                            reporter_response = store.load_result("reporter", ReporterResponse)
                        except Exception:
                            pass
                        
                        # UserAggregator ê²°ê³¼ ë¡œë“œ (í’ˆì§ˆ ì ìˆ˜ ë“±)
                        user_agg_response = store.load_result("user_aggregator", UserAggregatorResponse)
                        user_agg = user_agg_response.model_dump() if user_agg_response else None
                        quality_score = None
                        if user_agg and user_agg.get("aggregate_stats"):
                            quality_stats = user_agg["aggregate_stats"].get("quality_stats", {})
                            quality_score = quality_stats.get("mean_score")
                        
                        # Reporter ë©”íƒ€ë°ì´í„° ì¶”ê°€
                        reporter_meta = None
                        if reporter_response:
                            reporter_dict = reporter_response.model_dump()
                            reporter_meta = {
                                "total_commits": reporter_dict.get("total_commits", 0),
                                "total_files": reporter_dict.get("total_files", 0),
                                "report_path": reporter_dict.get("report_path", ""),
                                "status": reporter_dict.get("status", ""),
                            }

                        summaries.append({
                            "git_url": result.get("git_url", ""),
                            "task_uuid": task_uuid,
                            "base_path": base_path,
                            "status": "success",
                            "total_commits": result.get("total_commits", 0),
                            "total_files": result.get("total_files", 0),
                            "final_report_path": result.get("final_report_path"),
                            "quality_score": quality_score,
                            "reporter_meta": reporter_meta,  # Reporter ë©”íƒ€ë°ì´í„° ì¶”ê°€
                        })
                    else:
                        summaries.append({
                            "git_url": result.get("git_url", ""),
                            "task_uuid": task_uuid,
                            "base_path": base_path,
                            "status": "success",
                            "total_commits": result.get("total_commits", 0),
                            "total_files": result.get("total_files", 0),
                        })
                except Exception as e:
                    logger.warning(f"âš ï¸ ResultStore ë¡œë“œ ì‹¤íŒ¨: {e} (task_uuid={task_uuid}, base_path={base_path})")
                    summaries.append({
                        "git_url": result.get("git_url", ""),
                        "task_uuid": task_uuid,
                        "base_path": base_path,
                        "status": "success",
                        "total_commits": result.get("total_commits", 0),
                        "total_files": result.get("total_files", 0),
                    })

            except Exception as e:
                logger.warning(f"âš ï¸ ë ˆí¬ ìš”ì•½ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                summaries.append({
                    "git_url": result.get("git_url", "unknown"),
                    "status": "failed",
                    "error": str(e),
                })

        return summaries


    async def _generate_llm_analysis(
        self,
        repo_summaries: List[Dict[str, Any]],
        total_commits: int,
        total_files: int,
        successful: int,
        failed: int,
        target_user: str | None,
        user_analysis_result: Optional[UserAnalysisResult],
        context: Optional[Any] = None,  # RepoSynthesizerContext ì „ë‹¬ìš©
    ) -> Optional[LLMAnalysisResult]:
        """
        LLMì„ ì´ìš©í•œ ì¢…í•© ë¶„ì„ ë° ê°œì„  ë°©í–¥ ì œì‹œ
        
        Returns:
            LLMAnalysisResult ë˜ëŠ” None
        """
        try:
            # ë ˆí¬ì§€í† ë¦¬ ìš”ì•½ í¬ë§·íŒ…
            repo_summaries_text = self._format_repo_summaries(repo_summaries)
            
            # ê° repoì˜ ìƒì„¸ JSON ë°ì´í„° ìˆ˜ì§‘
            repo_json_data = await self._collect_repo_json_data(repo_summaries)
            
            # ìœ ì € ë¶„ì„ ê²°ê³¼ í¬ë§·íŒ…
            user_analysis_text = ""
            if user_analysis_result:
                user_analysis_text = self._format_user_analysis_result(user_analysis_result)
            
            # í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜ ì¤€ë¹„
            prompt_variables = {
                "total_repos": len(repo_summaries),
                "successful_repos": successful,
                "failed_repos": failed,
                "total_commits": total_commits,
                "total_files": total_files,
                "target_user": target_user if target_user else "ì „ì²´ ìœ ì €",
                "repo_summaries": repo_summaries_text,
                "repo_json_data": repo_json_data,
                "user_analysis_result": user_analysis_text if user_analysis_text else "ì—†ìŒ",
                
            }
            
            # í”„ë¡¬í”„íŠ¸ ìƒì„± (json_schema ë³€ìˆ˜ ìë™ ì£¼ì…)
            system_prompt = PromptLoader.format(
                self.prompts["system_prompt"],
                json_schema=self.prompts.get("json_schema", "")
            )
            user_prompt = PromptLoader.format(
                self.prompts["user_template"],
                **prompt_variables
            )
            
            # LLM í˜¸ì¶œ
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt),
            ]
            
            logger.info("ğŸ¤– LLM ì¢…í•© ë¶„ì„ ì‹œì‘...")
            
            # ë””ë²„ê¹…: LLM ì‘ë‹µ ì €ì¥ì„ ìœ„í•œ ê²½ë¡œ ì¤€ë¹„
            debug_store = None
            if context:
                from pathlib import Path
                from shared.storage import ResultStore
                try:
                    debug_store = ResultStore(context.main_task_uuid, Path(context.main_base_path))
                except Exception as e:
                    logger.debug(f"ë””ë²„ê¹… ì €ì¥ì†Œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            
            # LLM í˜¸ì¶œ ë° ì¬ì‹œë„ ë¡œì§
            max_retries = 2
            analysis_data = None
            last_error = None
            llm_response_content = None
            
            for attempt in range(max_retries + 1):
                try:
                    response = await self.llm.ainvoke(messages)
                    TokenTracker.record_usage(
                        "repo_synthesizer",
                        response,
                        model_id=PromptLoader.get_model("repo_synthesizer")
                    )
                    
                    # ì‘ë‹µ ê²€ì¦
                    content = response.content if hasattr(response, 'content') else str(response)
                    llm_response_content = content  # ë””ë²„ê¹…ìš© ì €ì¥
                    
                    if not content or not content.strip():
                        if attempt < max_retries:
                            logger.warning(f"âš ï¸ LLM ì‘ë‹µì´ ë¹„ì–´ìˆìŒ (ì‹œë„ {attempt + 1}/{max_retries + 1}), ì¬ì‹œë„...")
                            import asyncio
                            await asyncio.sleep(1)
                            continue
                        else:
                            logger.error("âŒ LLM ì‘ë‹µì´ ë¹„ì–´ìˆìŒ (ìµœì¢… ì‹¤íŒ¨)")
                            # ë””ë²„ê¹…: ë¹ˆ ì‘ë‹µ ì €ì¥
                            if debug_store:
                                try:
                                    debug_store.backend.save_debug_file("repo_synthesizer_llm_response_empty.txt", "")
                                except:
                                    pass
                            return None
                    
                    # JSON ì¶”ì¶œ ë° íŒŒì‹± (ì„¹ì…˜ë³„ íŒŒì‹± ì§€ì›)
                    analysis_data = self._parse_llm_response(content)
                    if not analysis_data:
                        if attempt < max_retries:
                            logger.warning(f"âš ï¸ LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries + 1}), ì¬ì‹œë„...")
                            logger.info(f"   LLM ì‘ë‹µ ë‚´ìš© (ì²˜ìŒ 500ì): {content[:500]}")
                            import asyncio
                            await asyncio.sleep(1)
                            continue
                        else:
                            logger.error("âŒ LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨ (ìµœì¢… ì‹¤íŒ¨)")
                            logger.error(f"   LLM ì‘ë‹µ ë‚´ìš© (ì²˜ìŒ 1000ì): {content[:1000]}")
                            # ë””ë²„ê¹…: JSON ì¶”ì¶œ ì‹¤íŒ¨ ì‘ë‹µ ì €ì¥
                            if debug_store:
                                try:
                                    debug_store.backend.save_debug_file("repo_synthesizer_llm_response_no_json.txt", content)
                                except:
                                    pass
                            return None
                    
                    # ë””ë²„ê¹…: ì„±ê³µí•œ JSON ì €ì¥
                    if debug_store:
                        try:
                            debug_store.backend.save_debug_file("repo_synthesizer_llm_response_raw.txt", content)
                            debug_store.backend.save_debug_file("repo_synthesizer_llm_response_parsed.json", json.dumps(analysis_data, indent=2, ensure_ascii=False))
                        except:
                            pass
                    
                    break  # ì„±ê³µ ì‹œ ë£¨í”„ ì¢…ë£Œ
                    
                except json.JSONDecodeError as e:
                    last_error = e
                    if attempt < max_retries:
                        logger.warning(f"âš ï¸ LLM ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries + 1}): {e}")
                        import asyncio
                        await asyncio.sleep(1)
                    else:
                        logger.warning(f"âš ï¸ LLM ì‘ë‹µ JSON íŒŒì‹± ìµœì¢… ì‹¤íŒ¨: {e}")
                        logger.error(f"   ì‘ë‹µ ë‚´ìš© (ì²˜ìŒ 1000ì): {content[:1000] if 'content' in locals() else 'N/A'}")
                        return None
                except Exception as e:
                    last_error = e
                    if attempt < max_retries:
                        logger.warning(f"âš ï¸ LLM í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries + 1}): {e}")
                        import asyncio
                        await asyncio.sleep(1)
                    else:
                        logger.error(f"âŒ LLM í˜¸ì¶œ ìµœì¢… ì‹¤íŒ¨: {e}")
                        return None
            
            # analysis_dataê°€ Noneì´ë©´ ì‹¤íŒ¨
            if analysis_data is None:
                logger.warning("âš ï¸ LLM ë¶„ì„: analysis_dataê°€ Noneì…ë‹ˆë‹¤")
                return None
            
            # ëˆ„ë½ëœ í•„ë“œ ë³´ì™„ (category í•„ë“œê°€ ì—†ëŠ” ê²½ìš°)
            if "improvement_recommendations" in analysis_data:
                for rec in analysis_data["improvement_recommendations"]:
                    if "category" not in rec or not rec.get("category"):
                        # titleì—ì„œ ì¹´í…Œê³ ë¦¬ë¥¼ ì¶”ë¡ í•˜ê±°ë‚˜ ê¸°ë³¸ê°’ ì‚¬ìš©
                        rec["category"] = "ì¼ë°˜"
            
            # Pydantic ëª¨ë¸ë¡œ ë³€í™˜
            try:
                llm_result = LLMAnalysisResult(**analysis_data)
                logger.info("âœ… LLM ì¢…í•© ë¶„ì„ ì™„ë£Œ")
                return llm_result
            except Exception as validation_error:
                    # Pydantic ê²€ì¦ ì‹¤íŒ¨ ì‹œ ë” ìì„¸í•œ ë¡œê¹…
                    from pydantic import ValidationError
                    if isinstance(validation_error, ValidationError):
                        error_count = len(validation_error.errors())
                        logger.warning(f"âš ï¸ LLM ì‘ë‹µ ê²€ì¦ ì‹¤íŒ¨: {error_count} validation errors for LLMAnalysisResult")
                        for err in validation_error.errors():
                            logger.warning(f"  - Field: {'.'.join(str(loc) for loc in err['loc'])}, Type: {err['type']}, Msg: {err['msg']}")
                    else:
                        logger.warning(f"âš ï¸ LLM ì‘ë‹µ ê²€ì¦ ì‹¤íŒ¨: {validation_error}")
                    
                    # ë””ë²„ê¹…: ê²€ì¦ ì‹¤íŒ¨í•œ ë°ì´í„° ì €ì¥
                    if debug_store:
                        try:
                            debug_store.backend.save_debug_file("repo_synthesizer_llm_response_validation_failed.json", json.dumps(analysis_data, indent=2, ensure_ascii=False))
                            if llm_response_content:
                                debug_store.backend.save_debug_file("repo_synthesizer_llm_response_raw_validation_failed.txt", llm_response_content)
                        except:
                            pass
                    
                    logger.info(f"   ê²€ì¦ ì‹¤íŒ¨í•œ ë°ì´í„° í‚¤: {list(analysis_data.keys()) if analysis_data else 'None'}")
                    logger.info(f"   ì‘ë‹µ ë°ì´í„° (ì²˜ìŒ 2000ì): {json.dumps(analysis_data, indent=2, ensure_ascii=False)[:2000]}")
                    # ê¸°ë³¸ê°’ìœ¼ë¡œ ì¬ì‹œë„
                    try:
                        # í•„ìˆ˜ í•„ë“œê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
                        if "overall_assessment" not in analysis_data:
                            analysis_data["overall_assessment"] = "ë¶„ì„ ê²°ê³¼ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                        if "strengths" not in analysis_data:
                            analysis_data["strengths"] = []
                        if "improvement_recommendations" not in analysis_data:
                            analysis_data["improvement_recommendations"] = []

                        # role_suitability í•„ìˆ˜ 5ê°œ ì—­í•  í™•ì¸
                        if "role_suitability" not in analysis_data:
                            analysis_data["role_suitability"] = {}
                        required_roles = ["Backend", "Frontend", "DevOps", "Data Science", "Fullstack"]
                        for role in required_roles:
                            if role not in analysis_data["role_suitability"]:
                                analysis_data["role_suitability"][role] = f"{role} (í‰ê°€ ë¶ˆê°€): ë°ì´í„° ë¶€ì¡±"

                        # hiring_decision í•„ìˆ˜ í•„ë“œ í™•ì¸
                        if "hiring_decision" not in analysis_data:
                            analysis_data["hiring_decision"] = {}
                        hiring = analysis_data["hiring_decision"]

                        if "immediate_readiness" not in hiring:
                            hiring["immediate_readiness"] = "í‰ê°€ ë¶ˆê°€"
                        if "onboarding_period" not in hiring:
                            hiring["onboarding_period"] = "ë¯¸ì •"
                        if "hiring_recommendation" not in hiring:
                            hiring["hiring_recommendation"] = "ì‹ ì¤‘ ê²€í† "
                        if "hiring_decision_reason" not in hiring:
                            hiring["hiring_decision_reason"] = "ë¶„ì„ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì•„ ì •í™•í•œ í‰ê°€ê°€ ì–´ë µìŠµë‹ˆë‹¤."
                        if "salary_recommendation" not in hiring:
                            hiring["salary_recommendation"] = "ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ í‰ê°€ ë¶ˆê°€"
                        if "estimated_salary_range" not in hiring:
                            hiring["estimated_salary_range"] = "í‰ê°€ ë¶ˆê°€"
                        if "technical_risks" not in hiring:
                            hiring["technical_risks"] = []
                        if "expected_contributions" not in hiring:
                            hiring["expected_contributions"] = []

                        llm_result = LLMAnalysisResult(**analysis_data)
                        logger.info("âœ… LLM ì¢…í•© ë¶„ì„ ì™„ë£Œ (ê¸°ë³¸ê°’ ë³´ì™„)")
                        return llm_result
                    except Exception as e2:
                        logger.warning(f"âš ï¸ LLM ì‘ë‹µ ë³µêµ¬ ì‹¤íŒ¨: {e2}")
                        return None
                
                
        except Exception as e:
            logger.error(f"âŒ LLM ë¶„ì„ ì‹¤íŒ¨: {e}", exc_info=True)
            return None

    def _extract_json_from_response(self, content: str) -> Optional[str]:
        """
        LLM ì‘ë‹µì—ì„œ JSON ë¬¸ìì—´ ì¶”ì¶œ (JSONExtractor ì‚¬ìš©)
        
        Args:
            content: LLM ì‘ë‹µ ë‚´ìš©
            
        Returns:
            ì¶”ì¶œëœ JSON ë¬¸ìì—´ ë˜ëŠ” None
        """
        from shared.utils.json_extractor import JSONExtractor
        return JSONExtractor.extract(content)
    
    def _parse_llm_response(self, content: str) -> Optional[Dict[str, Any]]:
        """
        LLM ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ LLMAnalysisResult í˜•ì‹ì˜ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        
        LLMì´ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì„¹ì…˜ë³„ë¡œ ë‚˜ëˆ„ì–´ ë°˜í™˜í•˜ëŠ” ê²½ìš°ë¥¼ ì²˜ë¦¬:
        - ### 1ï¸âƒ£ overall_assessment: ì½”ë“œ ë¸”ë¡ ì•ˆì˜ ë¬¸ìì—´
        - ### 2ï¸âƒ£ strengths: JSON ë°°ì—´
        - ### 3ï¸âƒ£ improvement_recommendations: JSON ë°°ì—´
        - ### 4ï¸âƒ£ role_suitability: JSON ê°ì²´
        - ### 5ï¸âƒ£ hiring_decision: JSON ê°ì²´
        - ### 6ï¸âƒ£ ì–¸ì–´ë³„ ì •ë³´: JSON ê°ì²´
        
        Args:
            content: LLM ì‘ë‹µ ë‚´ìš©
            
        Returns:
            íŒŒì‹±ëœ ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” None
        """
        import re
        import json
        
        result = {}
        
        try:
            # 1. overall_assessment ì¶”ì¶œ (ì½”ë“œ ë¸”ë¡ ì•ˆì˜ ë¬¸ìì—´)
            # íŒ¨í„´: ### 1ï¸âƒ£ overall_assessment ë‹¤ìŒì— ```ë¡œ ì‹œì‘í•˜ëŠ” ì½”ë“œ ë¸”ë¡ (ì–¸ì–´ ì‹ë³„ì í—ˆìš©)
            overall_match = re.search(r"###\s*1[ï¸âƒ£1]\s*overall_assessment\s*\n```(?:markdown)?\s*\n(.*?)\n```", content, re.DOTALL | re.IGNORECASE)
            if overall_match:
                result["overall_assessment"] = overall_match.group(1).strip()
            else:
                # ëŒ€ì²´ íŒ¨í„´: ``` ì—†ì´ ì§ì ‘ í…ìŠ¤íŠ¸ ë˜ëŠ” ```ê°€ í¬í•¨ëœ í…ìŠ¤íŠ¸
                overall_match = re.search(r"###\s*1[ï¸âƒ£1]\s*overall_assessment\s*\n(.*?)(?=###|\Z)", content, re.DOTALL)
                if overall_match:
                    text = overall_match.group(1).strip()
                    # ë§Œì•½ í…ìŠ¤íŠ¸ê°€ ```ë¡œ ê°ì‹¸ì ¸ ìˆë‹¤ë©´ ì œê±°
                    if text.startswith("```") and text.endswith("```"):
                        # ì²« ì¤„(```markdown ë“±)ê³¼ ë§ˆì§€ë§‰ ì¤„(```) ì œê±°
                        lines = text.split('\n')
                        if len(lines) >= 2:
                            result["overall_assessment"] = '\n'.join(lines[1:-1]).strip()
                        else:
                            result["overall_assessment"] = text.strip('`').strip()
                    else:
                        result["overall_assessment"] = text
            
            # 2. strengths ì¶”ì¶œ (JSON ë°°ì—´)
            # íŒ¨í„´: ### 2ï¸âƒ£ strengths ë‹¤ìŒì— ```jsonìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ì½”ë“œ ë¸”ë¡
            strengths_match = re.search(r"###\s*2[ï¸âƒ£2]\s*strengths\s*\n```json\s*\n(\[.*?\])\s*\n```", content, re.DOTALL)
            if strengths_match:
                try:
                    strengths_json = json.loads(strengths_match.group(1))
                    # strengthsëŠ” List[str]ì´ë¯€ë¡œ ê° í•­ëª©ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
                    result["strengths"] = [
                        f"âœ… {item.get('title', '')}: {item.get('description', '')}" 
                        if isinstance(item, dict) else str(item)
                        for item in strengths_json
                    ]
                except json.JSONDecodeError:
                    logger.warning("âš ï¸ strengths JSON íŒŒì‹± ì‹¤íŒ¨")
            
            # 3. improvement_recommendations ì¶”ì¶œ (JSON ë°°ì—´)
            improvements_match = re.search(r"###\s*3[ï¸âƒ£3]\s*improvement_recommendations\s*\n```json\s*\n(\[.*?\])\s*\n```", content, re.DOTALL)
            if improvements_match:
                try:
                    result["improvement_recommendations"] = json.loads(improvements_match.group(1))
                except json.JSONDecodeError:
                    logger.warning("âš ï¸ improvement_recommendations JSON íŒŒì‹± ì‹¤íŒ¨")
            
            # 4. role_suitability ì¶”ì¶œ (JSON ê°ì²´)
            # ì¤‘ê´„í˜¸ ë§¤ì¹­ìœ¼ë¡œ ì™„ì „í•œ JSON ê°ì²´ ì¶”ì¶œ
            role_section = re.search(r"###\s*4[ï¸âƒ£4]\s*role_suitability\s*\n```json\s*\n(\{.*)", content, re.DOTALL)
            if role_section:
                brace_start = content.find("{", role_section.start())
                if brace_start != -1:
                    brace_count = 0
                    for i in range(brace_start, len(content)):
                        if content[i] == "{":
                            brace_count += 1
                        elif content[i] == "}":
                            brace_count -= 1
                            if brace_count == 0:
                                json_str = content[brace_start:i+1]
                                try:
                                    result["role_suitability"] = json.loads(json_str)
                                except json.JSONDecodeError:
                                    logger.warning("âš ï¸ role_suitability JSON íŒŒì‹± ì‹¤íŒ¨")
                                break
            
            # 5. hiring_decision ì¶”ì¶œ (JSON ê°ì²´)
            # ì¤‘ê´„í˜¸ ë§¤ì¹­ìœ¼ë¡œ ì™„ì „í•œ JSON ê°ì²´ ì¶”ì¶œ
            hiring_section = re.search(r"###\s*5[ï¸âƒ£5]\s*hiring_decision\s*\n```json\s*\n(\{.*)", content, re.DOTALL)
            if hiring_section:
                brace_start = content.find("{", hiring_section.start())
                if brace_start != -1:
                    brace_count = 0
                    for i in range(brace_start, len(content)):
                        if content[i] == "{":
                            brace_count += 1
                        elif content[i] == "}":
                            brace_count -= 1
                            if brace_count == 0:
                                json_str = content[brace_start:i+1]
                                try:
                                    result["hiring_decision"] = json.loads(json_str)
                                except json.JSONDecodeError:
                                    logger.warning("âš ï¸ hiring_decision JSON íŒŒì‹± ì‹¤íŒ¨")
                                break
            
            # 6. ì–¸ì–´ë³„ ì •ë³´ ì¶”ì¶œ (JSON ê°ì²´)
            lang_section = re.search(r"###\s*6[ï¸âƒ£6]\s*ì–¸ì–´ë³„\s*ìƒì„¸\s*ì •ë³´\s*\n```json\s*\n(\{.*)", content, re.DOTALL)
            if lang_section:
                brace_start = content.find("{", lang_section.start())
                if brace_start != -1:
                    brace_count = 0
                    for i in range(brace_start, len(content)):
                        if content[i] == "{":
                            brace_count += 1
                        elif content[i] == "}":
                            brace_count -= 1
                            if brace_count == 0:
                                json_str = content[brace_start:i+1]
                                try:
                                    lang_data = json.loads(json_str)
                                    # ë™ì  í•„ë“œë¡œ ì¶”ê°€
                                    for lang, info in lang_data.items():
                                        result[lang] = info
                                except json.JSONDecodeError:
                                    logger.warning("âš ï¸ ì–¸ì–´ë³„ ì •ë³´ JSON íŒŒì‹± ì‹¤íŒ¨")
                                break
            
            # ì „ì²´ JSON ê°ì²´ê°€ ìˆëŠ” ê²½ìš° (ì„¹ì…˜ë³„ íŒŒì‹± ì‹¤íŒ¨ ì‹œ ëŒ€ì²´)
            if not result:
                json_str = self._extract_json_from_response(content)
                if json_str:
                    try:
                        result = json.loads(json_str)
                    except json.JSONDecodeError:
                        pass
            
            # í•„ìˆ˜ í•„ë“œê°€ ëª¨ë‘ ìˆëŠ”ì§€ í™•ì¸
            if "overall_assessment" in result and "role_suitability" in result and "hiring_decision" in result:
                logger.debug("âœ… LLM ì‘ë‹µ ì„¹ì…˜ë³„ íŒŒì‹± ì„±ê³µ")
                return result
            else:
                logger.warning(f"âš ï¸ LLM ì‘ë‹µ íŒŒì‹±: í•„ìˆ˜ í•„ë“œ ëˆ„ë½. íŒŒì‹±ëœ í‚¤: {list(result.keys())}")
                return result if result else None
                
        except json.JSONDecodeError as e:
            logger.warning(f"âš ï¸ LLM ì‘ë‹µ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            return None
        except Exception as e:
            logger.warning(f"âš ï¸ LLM ì‘ë‹µ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
            return None

    async def _collect_repo_json_data(self, repo_summaries: List[Dict[str, Any]]) -> str:
        """
        ê° ë ˆí¬ì§€í† ë¦¬ì˜ ìƒì„¸ JSON ë°ì´í„° ìˆ˜ì§‘
        
        Returns:
            JSON í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…ëœ ë¬¸ìì—´
        """
        repo_json_list = []
        
        for summary in repo_summaries:
            if summary.get("status") != "success":
                continue
            
            task_uuid = summary.get("task_uuid", "")
            base_path = summary.get("base_path")
            git_url = summary.get("git_url", "")
            
            if not task_uuid or not base_path:
                continue
            
            try:
                logger.info(f"ğŸ” ResultStore ì´ˆê¸°í™” (JSON ìˆ˜ì§‘): task_uuid={task_uuid}, base_path={base_path}")
                store = ResultStore(task_uuid, Path(base_path))
                
                # ì£¼ìš” ë¶„ì„ ê²°ê³¼ ë¡œë“œ
                repo_data = {
                    "git_url": git_url,
                    "task_uuid": task_uuid,
                }
                
                # Reporter ê²°ê³¼ (ë©”íƒ€ë°ì´í„°)
                try:
                    reporter_response = store.load_result("reporter", ReporterResponse)
                    if reporter_response:
                        reporter_dict = reporter_response.model_dump()
                        # ë¦¬í¬íŠ¸ ë©”íƒ€ë°ì´í„° í¬í•¨
                        repo_data["reporter"] = {
                            "total_commits": reporter_dict.get("total_commits", 0),
                            "total_files": reporter_dict.get("total_files", 0),
                            "report_path": reporter_dict.get("report_path", ""),
                            "status": reporter_dict.get("status", ""),
                        }
                except Exception as e:
                    logger.debug(f"Reporter ë¡œë“œ ì‹¤íŒ¨: {e}")
                
                # StaticAnalyzer ê²°ê³¼ (í•µì‹¬ ì •ë³´ë§Œ)
                try:
                    static_response = store.load_result("static_analyzer", StaticAnalyzerResponse)
                    if static_response:
                        static_dict = static_response.model_dump()
                        # í•µì‹¬ ì •ë³´ë§Œ ì¶”ì¶œ (ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í•„ë“œ)
                        repo_data["static_analysis"] = {
                            "loc_stats": static_dict.get("loc_stats", {}),
                            "complexity": static_dict.get("complexity", {}),
                            "type_check": static_dict.get("type_check", {}),
                        }
                except Exception as e:
                    logger.debug(f"Static analyzer ë¡œë“œ ì‹¤íŒ¨: {e}")
                
                # UserAggregator ê²°ê³¼ (ì „ì²´ í†µê³„)
                try:
                    user_agg_response = store.load_result("user_aggregator", UserAggregatorResponse)
                    if user_agg_response:
                        agg_dict = user_agg_response.model_dump()
                        # aggregate_stats ì „ì²´ í¬í•¨ (í’ˆì§ˆ, ê¸°ìˆ , ë³µì¡ë„ í†µê³„)
                        repo_data["user_aggregator"] = {
                            "aggregate_stats": agg_dict.get("aggregate_stats", {})
                        }
                except Exception as e:
                    logger.debug(f"User aggregator ë¡œë“œ ì‹¤íŒ¨: {e}")
                
                # UserSkillProfiler ê²°ê³¼ (ë¶„ì„ì— í•µì‹¬ì ì¸ í•„ë“œë§Œ)
                try:
                    skill_profile_response = store.load_result("user_skill_profiler", UserSkillProfilerResponse)
                    if skill_profile_response:
                        skill_dict = skill_profile_response.model_dump()
                        skill_profile_data = skill_dict.get("skill_profile", {})
                        
                        # í•µì‹¬ ì •ë³´ë§Œ ì¶”ì¶œ (ì‹¤ì œ ì¡´ì¬í•˜ëŠ” í•„ë“œ)
                        repo_data["skill_profile"] = {
                            "total_skills": skill_profile_data.get("total_skills", 0),
                            "skills_by_level": skill_profile_data.get("skills_by_level", {}),
                            "skills_by_category": skill_profile_data.get("skills_by_category", {}),
                            "top_skills": skill_profile_data.get("top_skills", [])[:10],  # ìƒìœ„ 10ê°œë§Œ
                            "total_experience": skill_profile_data.get("total_experience", 0),
                            "level": skill_profile_data.get("level", {}),
                            "developer_type_coverage": skill_profile_data.get("developer_type_coverage", {}),
                            "developer_type_levels": skill_profile_data.get("developer_type_levels", {}),
                            "category_coverage": skill_profile_data.get("category_coverage", {}),
                            "total_coverage": skill_profile_data.get("total_coverage", 0),
                        }
                except Exception as e:
                    logger.debug(f"Skill profiler ë¡œë“œ ì‹¤íŒ¨: {e}")
                
                repo_json_list.append(repo_data)
                
            except Exception as e:
                logger.warning(f"âš ï¸ ë ˆí¬ì§€í† ë¦¬ {git_url} JSON ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                continue
        
        if not repo_json_list:
            logger.warning("   ë ˆí¬ì§€í† ë¦¬ JSON ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
            return "ë ˆí¬ì§€í† ë¦¬ JSON ë°ì´í„° ì—†ìŒ"
        
        logger.info(f"   ìˆ˜ì§‘ëœ JSON ë°ì´í„°: {len(repo_json_list)}ê°œ ë ˆí¬ì§€í† ë¦¬")
        
        # JSON í¬ë§·íŒ… (ê°€ë…ì„±ì„ ìœ„í•´ ë“¤ì—¬ì“°ê¸°)
        json_str = json.dumps(repo_json_list, indent=2, ensure_ascii=False)
        logger.info(f"   JSON ë°ì´í„° í¬ê¸°: {len(json_str):,} ë¬¸ì")
        
        return json_str

    def _format_repo_summaries(self, repo_summaries: List[Dict[str, Any]]) -> str:
        """ë ˆí¬ì§€í† ë¦¬ ìš”ì•½ í¬ë§·íŒ…"""
        formatted = []
        for i, summary in enumerate(repo_summaries, 1):
            status_emoji = "âœ…" if summary.get("status") == "success" else "âŒ"
            git_url = summary.get("git_url", "unknown")
            
            repo_text = f"\n{i}. {status_emoji} {git_url}\n"
            if summary.get("status") == "success":
                repo_text += f"   - ì»¤ë°‹ ìˆ˜: {summary.get('total_commits', 0):,}ê°œ\n"
                repo_text += f"   - íŒŒì¼ ìˆ˜: {summary.get('total_files', 0):,}ê°œ\n"
                if summary.get("quality_score") is not None:
                    repo_text += f"   - í’ˆì§ˆ ì ìˆ˜: {summary.get('quality_score'):.2f}/10\n"
            else:
                repo_text += f"   - ì—ëŸ¬: {summary.get('error', 'Unknown error')}\n"
            
            formatted.append(repo_text)
        
        return "\n".join(formatted)

    def _format_user_analysis_result(self, user_analysis_result: UserAnalysisResult) -> str:
        """ìœ ì € ë¶„ì„ ê²°ê³¼ í¬ë§·íŒ…"""
        formatted = []

        formatted.append(f"ì½”ë“œ í’ˆì§ˆ ì ìˆ˜: {user_analysis_result.clean_code:.2f}/10")

        if user_analysis_result.role:
            formatted.append(f"\nğŸš¨ ì—­í• ë³„ ê¸°ìˆ ìŠ¤íƒ ë³´ìœ ìœ¨ (ì •í™•í•œ ìˆ˜ì¹˜ - role_suitabilityì—ì„œ ë°˜ë“œì‹œ ì´ ê°’ì„ ì‚¬ìš©):")
            for role, percentage in sorted(user_analysis_result.role.items(), key=lambda x: x[1], reverse=True):
                formatted.append(f"  - {role}: {percentage:.1f}% â† role_suitabilityì—ì„œ ì´ ì •í™•í•œ í¼ì„¼íŠ¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”!")

            formatted.append(f"\nâš ï¸ ì¤‘ìš”: role_suitability ì‘ì„± ì‹œ ìœ„ì˜ í¼ì„¼íŠ¸ ê°’ì„ ì •í™•íˆ ë³µì‚¬í•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”.")
            formatted.append(f"ì˜ˆì‹œ: \"Backend ({user_analysis_result.role.get('Backend', 0.0):.1f}%): [í‰ê°€ ë‚´ìš©]\"")

        if hasattr(user_analysis_result, 'python') and user_analysis_result.python:
            python = user_analysis_result.python
            formatted.append(f"\nPython ë¶„ì„:")
            formatted.append(f"  - ìˆ™ë ¨ë„ ë ˆë²¨: {python.level}")
            formatted.append(f"  - ê²½í—˜ì¹˜: {python.exp:,}")
            if python.stack:
                formatted.append(f"  - ê¸°ìˆ  ìŠ¤íƒ: {', '.join(python.stack)}")

        return "\n".join(formatted)

    async def _generate_user_analysis_result(
        self,
        repo_results: List[Dict[str, Any]],
        main_task_uuid: str,
        main_base_path: str,
    ) -> Optional[UserAnalysisResult]:
        """
        target_userì˜ ì¢…í•© ë¶„ì„ ê²°ê³¼ ìƒì„±
        
        Returns:
            UserAnalysisResult ë˜ëŠ” None
        """
        try:
            # ëª¨ë“  ë ˆí¬ì§€í† ë¦¬ì—ì„œ ë°ì´í„° ìˆ˜ì§‘
            all_quality_scores = []  # í’ˆì§ˆ ì ìˆ˜ ë¦¬ìŠ¤íŠ¸
            all_skills = []  # ëª¨ë“  ë ˆí¬ì˜ ìŠ¤í‚¬ ë°ì´í„° (ì¤‘ë³µ í¬í•¨)
            all_tech_stack = set()  # ì „ì²´ ê¸°ìˆ  ìŠ¤íƒ (ì¤‘ë³µ ì œê±°ìš©)
            
            for result in repo_results:
                if result.get("error_message"):
                    continue
                    
                task_uuid = result.get("task_uuid", "")
                base_path = result.get("base_path", "")
                
                if not task_uuid or not base_path:
                    continue
                
                try:
                    store = ResultStore(task_uuid, Path(base_path))
                    logger.info(f"ğŸ“‚ RepoSynthesizer ë°ì´í„° ë¡œë“œ ì‹œì‘: task_uuid={task_uuid}")
                    logger.info(f"   base_path: {base_path}")
                    logger.info(f"   ResultStore results_dir: {store.results_dir}")
                    
                    # total_skill.json ë¡œë“œ (ì¼ë°˜ JSON íŒŒì¼)
                    try:
                        import json
                        logger.info(f"   ğŸ“¥ total_skill.json ë¡œë“œ ì‹œë„: {base_path}/total_skill.json")
                        total_skill_content = store.load_debug_file("total_skill.json")
                        total_skill_data = json.loads(total_skill_content)
                        if isinstance(total_skill_data, list):
                            all_skills += total_skill_data
                            logger.info(f"   âœ… total_skill.json ë¡œë“œ ì„±ê³µ: {len(total_skill_data)}ê°œ ìŠ¤í‚¬")
                        else:
                            logger.debug(f"total_skill.jsonì´ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì´ ì•„ë‹˜: {type(total_skill_data)}")
                    except FileNotFoundError:
                        logger.warning(f"   âš ï¸ total_skill.json íŒŒì¼ ì—†ìŒ: task_uuid={task_uuid}, base_path={base_path}")
                    except Exception as e:
                        logger.warning(f"   âš ï¸ total_skill.json ë¡œë“œ ì‹¤íŒ¨: {e}, base_path={base_path}")
                    
                    
                    # 1. UserAggregator ê²°ê³¼ì—ì„œ í’ˆì§ˆ ì ìˆ˜ ìˆ˜ì§‘
                    try:
                        logger.info(f"   ğŸ“¥ user_aggregator.json ë¡œë“œ ì‹œë„: {store.results_dir}/user_aggregator.json")
                        user_agg_response = store.load_result("user_aggregator", UserAggregatorResponse)
                        user_agg = user_agg_response.model_dump() if user_agg_response else None
                        if user_agg and user_agg.get("aggregate_stats"):
                            quality_stats = user_agg["aggregate_stats"].get("quality_stats", {})
                            avg_score = quality_stats.get("average_score")
                            if avg_score is not None:
                                all_quality_scores.append(avg_score)
                                logger.info(f"   âœ… user_aggregator.json ë¡œë“œ ì„±ê³µ: í’ˆì§ˆ ì ìˆ˜={avg_score}")
                        else:
                            logger.warning(f"   âš ï¸ user_aggregator ê²°ê³¼ì— aggregate_stats ì—†ìŒ")
                    except Exception as e:
                        logger.warning(f"   âš ï¸ user_aggregator.json ë¡œë“œ ì‹¤íŒ¨: {e}")
                    
                    # 2. UserSkillProfiler ê²°ê³¼ì—ì„œ ìŠ¤í‚¬ ë°ì´í„° ìˆ˜ì§‘
                    try:
                        logger.info(f"   ğŸ“¥ user_skill_profiler.json ë¡œë“œ ì‹œë„: {store.results_dir}/user_skill_profiler.json")
                        skill_profile_response = store.load_result("user_skill_profiler", UserSkillProfilerResponse)
                        skill_profile = skill_profile_response.model_dump() if skill_profile_response else None
                        if skill_profile:
                            logger.info(f"   âœ… user_skill_profiler.json ë¡œë“œ ì„±ê³µ")
                        else:
                            logger.warning(f"   âš ï¸ user_skill_profiler ê²°ê³¼ê°€ None")
                    except Exception as e:
                        logger.warning(f"   âš ï¸ user_skill_profiler.json ë¡œë“œ ì‹¤íŒ¨: {e}")
                        skill_profile = None
                    
                    if skill_profile and skill_profile.get("skill_profile"):
                        # top_skillsì—ì„œ ìŠ¤í‚¬ ì •ë³´ ì¶”ì¶œ
                        top_skills = skill_profile["skill_profile"].get("top_skills", [])
                        logger.info(f"   ğŸ“Š top_skills ìˆ˜ì§‘: {len(top_skills)}ê°œ")
                        for skill in top_skills:
                            # all_skillsì— ì¶”ê°€ (ë ˆë²¨ ê³„ì‚°ìš©)
                            # top_skillsëŠ” ì´ë¯¸ base_scoreë¥¼ í¬í•¨í•œ ìŠ¤í‚¬ ê°ì²´
                            all_skills.append(skill)
                            
                            # ê¸°ìˆ  ìŠ¤íƒ ì¶”ê°€ (ì¤‘ë³µ ì œê±°)
                            skill_category = skill.get("category", "")
                            if skill_category:
                                all_tech_stack.add(skill_category)
                        logger.info(f"   âœ… top_skillsë¥¼ all_skillsì— ì¶”ê°€ ì™„ë£Œ: {len(top_skills)}ê°œ")
                
                except Exception as e:
                    logger.warning(f"âš ï¸ ë ˆí¬ì§€í† ë¦¬ {task_uuid} ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                    continue
            
            # ë°ì´í„° ì§‘ê³„
            logger.info(f"   í’ˆì§ˆ ì ìˆ˜: {len(all_quality_scores)}ê°œ")
            logger.info(f"   ìˆ˜ì§‘ëœ ìŠ¤í‚¬: {len(all_skills)}ê°œ (ì¤‘ë³µ í¬í•¨)")
            logger.info(f"   ê³ ìœ  ê¸°ìˆ  ìŠ¤íƒ: {len(all_tech_stack)}ê°œ")
            
            # 1. clean_code ì ìˆ˜ ê³„ì‚° (í‰ê· )
            clean_code_score = 0.0
            if all_quality_scores:
                clean_code_score = sum(all_quality_scores) / len(all_quality_scores)
            
            # 2. SkillLevelCalculatorë¡œ ì •í™•í•œ ë ˆë²¨ ê³„ì‚°
            total_experience = SkillLevelCalculator.calculate_total_experience(all_skills)
            logger.info(f"   ëª¨ë“  ìŠ¤í‚¬: {all_skills}")
            level_info = SkillLevelCalculator.calculate_level(total_experience)
            
            logger.info(f"   ì´ ê²½í—˜ì¹˜: {total_experience:,} EXP")
            logger.info(f"   ë ˆë²¨: {level_info['level']} ({level_info['level_name']})")
            
            # 3. ê°œë°œì íƒ€ì…ë³„ ì»¤ë²„ë¦¬ì§€ ë° ë ˆë²¨ ê³„ì‚°
            chromadb_persist_dir = os.getenv(
                "CHROMADB_PERSIST_DIR", str(Path(main_base_path).parent.parent / "chroma_db_skill_charts")
            )
            developer_type_coverage = await SkillLevelCalculator.calculate_developer_type_coverage(
                all_skills, chromadb_persist_dir
            )
            
            # developer_type_coverageê°€ Noneì´ê±°ë‚˜ ë¹„ì–´ìˆì„ ê²½ìš° ì²˜ë¦¬
            if developer_type_coverage is None:
                developer_type_coverage = {}
                logger.warning("âš ï¸ ê°œë°œì íƒ€ì…ë³„ ì»¤ë²„ë¦¬ì§€ ê³„ì‚° ì‹¤íŒ¨, ë¹ˆ dict ì‚¬ìš©")
            
            # 4. role í¼ì„¼íŠ¸ ê³„ì‚°
            role_percentages = {}
            for role, coverage_data in developer_type_coverage.items():
                percentage = coverage_data.get("percentage", 0)
                role_percentages[role] = float(percentage)
            
            logger.info(f"   ì—­í• ë³„ ì»¤ë²„ë¦¬ì§€: {list(role_percentages.keys())}")
            
            # UserAnalysisResult ìƒì„±
            result = UserAnalysisResult(
                python=LanguageInfo(),  # ë¹ˆ ì´ˆê¸°ê°’ (ì–¸ì–´ë³„ ì •ë³´ëŠ” LLMì´ ì±„ì›€)
                clean_code=round(clean_code_score, 2),
                role=role_percentages,
                markdown="",  # ë‚˜ì¤‘ì— ì „ì²´ ë¦¬í¬íŠ¸ë¡œ ì±„ì›€
                level=level_info,  # ì •í™•í•œ ë ˆë²¨ ì •ë³´
                tech_stack=sorted(list(all_tech_stack)) if all_tech_stack else [],  # ì „ì²´ ê¸°ìˆ  ìŠ¤íƒ
            )
            
            logger.info(f"âœ… UserAnalysisResult ìƒì„± ì™„ë£Œ (ì •í™•í•œ ë ˆë²¨ ê³„ì‚°)")
            return result
            
        except Exception as e:
            logger.error(f"âŒ UserAnalysisResult ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
            return None


    def _generate_synthesis_report(
        self,
        repo_summaries: List[Dict[str, Any]],
        total_commits: int,
        total_files: int,
        successful: int,
        failed: int,
        target_user: str | None,
        user_analysis_result: Optional[UserAnalysisResult] = None,
        llm_analysis: Optional[LLMAnalysisResult] = None,
    ) -> str:
        """ì¢…í•© ë¦¬í¬íŠ¸ ë§ˆí¬ë‹¤ìš´ ìƒì„±"""
        
        is_single = len(repo_summaries) == 1
        title = "Repository Analysis - Synthesis Report" if is_single else "Multi-Repository Analysis - Synthesis Report"
        
        report = f"""# {title}

**ìƒì„± ì‹œê°„**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
**ë¶„ì„ ëŒ€ìƒ ìœ ì €**: {target_user if target_user else "ì „ì²´ ìœ ì €"}

---

## ğŸ“Š Executive Summary

- **ì´ ë ˆí¬ì§€í† ë¦¬ ìˆ˜**: {len(repo_summaries)}ê°œ
- **ì„±ê³µ**: {successful}ê°œ
- **ì‹¤íŒ¨**: {failed}ê°œ
- **ì´ ë¶„ì„ ì»¤ë°‹ ìˆ˜**: {total_commits:,}ê°œ
- **ì´ ë¶„ì„ íŒŒì¼ ìˆ˜**: {total_files:,}ê°œ

---

"""

        # target_userê°€ ìˆê³  user_analysis_resultê°€ ìˆìœ¼ë©´ ì¶”ê°€
        if user_analysis_result:
            # ë ˆë²¨ ì •ë³´ ë¨¼ì € í‘œì‹œ (UserAnalysisResultì—ì„œ ê°€ì ¸ì˜´)
            if user_analysis_result.level:
                level_info = user_analysis_result.level
                report += "## ğŸ¯ ê°œë°œì ë ˆë²¨\n\n"
                report += f"**ë ˆë²¨**: {level_info.get('level', 0)}\n"
                report += (
                    f"**ì´ ê²½í—˜ì¹˜**: "
                    f"{level_info.get('experience', 0):,}\n"
                )
                report += (
                    f"**í˜„ì¬ ë ˆë²¨ ê²½í—˜ì¹˜**: "
                    f"{level_info.get('current_level_exp', 0):,} / "
                    f"{level_info.get('next_level_exp', 0):,}\n"
                )
                report += (
                    f"**ì§„í–‰ë¥ **: "
                    f"{level_info.get('progress_percentage', 0):.1f}%\n\n"
                )
            
            # ê¸°ìˆ  ìŠ¤íƒ í‘œì‹œ (UserAnalysisResultì—ì„œ ê°€ì ¸ì˜´)
            if user_analysis_result.tech_stack and len(user_analysis_result.tech_stack) > 0:
                report += "ê¸°ìˆ  ìŠ¤íƒ\n\n"
                # 5ê°œì”© ì¤„ë°”ê¾¸ì–´ í‘œì‹œ
                for i in range(0, len(user_analysis_result.tech_stack), 5):
                    chunk = user_analysis_result.tech_stack[i:i+5]
                    report += f"`{'` Â· `'.join(chunk)}`\n"
                report += "\n"
            
            report += user_analysis_result.markdown
            report += "\n---\n\n"

        # LLM ë¶„ì„ ê²°ê³¼ ì¶”ê°€
        if llm_analysis:
            report += "## ğŸ¤– LLM ì¢…í•© ë¶„ì„ ë° ê°œì„  ë°©í–¥\n\n"
            
            report += f"### ì¢…í•© í‰ê°€\n\n{llm_analysis.overall_assessment}\n\n"
            
            if llm_analysis.strengths:
                report += "### ê°•ì  ë¶„ì„\n\n"
                for strength in llm_analysis.strengths:
                    report += f"- {strength}\n"
                report += "\n"
            
            if llm_analysis.improvement_recommendations:
                report += "### ê°œì„  ë°©í–¥\n\n"
                for rec in llm_analysis.improvement_recommendations:
                    report += f"#### {rec.priority} - {rec.title}\n\n"
                    report += f"**ì¹´í…Œê³ ë¦¬**: {rec.category}\n\n"
                    report += f"{rec.description}\n\n"
                    if rec.action_items:
                        report += "**ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜**:\n"
                        for action in rec.action_items:
                            report += f"- {action}\n"
                    report += "\n"
            
            if llm_analysis.role_suitability:
                report += "### ì—­í•  ì í•©ì„± í‰ê°€\n\n"
                for role, assessment in llm_analysis.role_suitability.items():
                    report += f"- **{role}**: {assessment}\n"
                report += "\n"
            
            # hiring_decision ì„¹ì…˜ ì¶”ê°€ (í”„ë¡¬í”„íŠ¸ì—ì„œ ê°€ì¥ ì¤‘ìš”í•˜ë‹¤ê³  ê°•ì¡°)
            if llm_analysis.hiring_decision:
                report += "### ğŸ’¼ ì±„ìš© ì˜ê²¬ ë° íˆ¬ì… ê°€ëŠ¥ì„± í‰ê°€\n\n"
                hiring = llm_analysis.hiring_decision
                
                report += f"**ì¦‰ì‹œ íˆ¬ì… ê°€ëŠ¥ì„±**: {hiring.immediate_readiness}\n"
                report += f"**ì˜ˆìƒ ì˜¨ë³´ë”© ê¸°ê°„**: {hiring.onboarding_period}\n"
                report += f"**ì±„ìš© ì¶”ì²œ ì˜ê²¬**: {hiring.hiring_recommendation}\n\n"
                
                report += f"**ì±„ìš© ì˜ê²¬ ê·¼ê±°**:\n{hiring.hiring_decision_reason}\n\n"
                
                if hiring.technical_risks:
                    report += "**ì˜ˆìƒ ê¸°ìˆ ì  ë¦¬ìŠ¤í¬**:\n"
                    for risk in hiring.technical_risks:
                        report += f"- {risk}\n"
                    report += "\n"
                
                if hiring.expected_contributions:
                    report += "**ê¸°ëŒ€ ê¸°ì—¬**:\n"
                    for contribution in hiring.expected_contributions:
                        report += f"- {contribution}\n"
                    report += "\n"
                
                report += f"**ê¸‰ì—¬ ë ˆë²¨ ì¶”ì²œ**: {hiring.salary_recommendation}\n"
                report += f"**ì˜ˆìƒ ì ì • ì—°ë´‰**: {hiring.estimated_salary_range}\n\n"
            
            # ì–¸ì–´ë³„ ìƒì„¸ ì •ë³´ ì¶”ê°€ (ë™ì  í•„ë“œ)
            language_fields = {}
            if llm_analysis:
                # LLMAnalysisResultì˜ ë™ì  í•„ë“œì—ì„œ ì–¸ì–´ë³„ ì •ë³´ ì¶”ì¶œ
                for field_name in llm_analysis.model_fields_set:
                    if field_name not in [
                        'overall_assessment', 'strengths', 'improvement_recommendations',
                        'role_suitability', 'hiring_decision'
                    ]:
                        field_value = getattr(llm_analysis, field_name, None)
                        if isinstance(field_value, dict) and all(
                            k in field_value for k in ['stack', 'level', 'exp', 'usage_frequency']
                        ):
                            language_fields[field_name] = field_value
            
            # UserAnalysisResultì—ì„œë„ ì–¸ì–´ë³„ ì •ë³´ í™•ì¸
            if user_analysis_result:
                for field_name in dir(user_analysis_result):
                    if not field_name.startswith('_') and field_name not in [
                        'python', 'clean_code', 'role', 'markdown', 'level', 'tech_stack',
                        'model_config', 'model_fields', 'model_computed_fields',
                        'model_dump', 'model_dump_json', 'model_validate', 'model_validate_json',
                        'model_copy', 'model_post_init', 'model_json_schema',
                        'model_parametrized_name', 'model_rebuild', 'model_fields_set'
                    ]:
                        field_value = getattr(user_analysis_result, field_name, None)
                        if isinstance(field_value, LanguageInfo):
                            language_fields[field_name] = {
                                'stack': field_value.stack,
                                'level': field_value.level,
                                'exp': field_value.exp,
                                'usage_frequency': field_value.usage_frequency
                            }
                # python í•„ë“œë„ í™•ì¸
                if user_analysis_result.python and user_analysis_result.python.level > 0:
                    language_fields['python'] = {
                        'stack': user_analysis_result.python.stack,
                        'level': user_analysis_result.python.level,
                        'exp': user_analysis_result.python.exp,
                        'usage_frequency': user_analysis_result.python.usage_frequency
                    }
            
            # ì–¸ì–´ë³„ ìƒì„¸ ì •ë³´ í‘œì‹œ
            if language_fields:
                report += "### ğŸ“Š ì–¸ì–´ë³„ ìƒì„¸ ì •ë³´\n\n"
                report += "| ì–¸ì–´ | ìˆ™ë ¨ë„ | ê²½í—˜ì¹˜ | ì‚¬ìš© ë¹ˆë„ | ê¸°ìˆ  ìŠ¤íƒ |\n"
                report += "|------|--------|--------|-----------|----------|\n"
                for lang, info in language_fields.items():
                    level_stars = "â­" * min(5, (info.get('level', 0) // 20))
                    stack_str = ", ".join(info.get('stack', [])[:3])  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                    if len(info.get('stack', [])) > 3:
                        stack_str += f" ì™¸ {len(info.get('stack', [])) - 3}ê°œ"
                    report += f"| {lang.capitalize()} | {level_stars} ({info.get('level', 0)}/100) | {info.get('exp', 0):,} | {info.get('usage_frequency', 0)}% | {stack_str} |\n"
                report += "\n"
            
            # ì‹œê°í™” ìš”ì†Œ ì¶”ê°€ (í”„ë¡¬í”„íŠ¸ì—ì„œ ìš”êµ¬)
            if user_analysis_result and user_analysis_result.role:
                report += "### ğŸ“ˆ ë¶„ì•¼ë³„ ì—­ëŸ‰ ì°¨íŠ¸\n\n"
                # ì—­í• ë³„ ë³´ìœ ìœ¨ì„ ì°¨íŠ¸ë¡œ í‘œì‹œ
                for role, percentage in sorted(user_analysis_result.role.items(), key=lambda x: x[1], reverse=True):
                    if percentage > 0:
                        bar_length = int(percentage / 5)  # 5%ë‹¹ 1ì¹¸
                        filled = "â–ˆ" * bar_length
                        empty = "â–‘" * (20 - bar_length)
                        report += f"{role:<15} {filled}{empty} {percentage:.1f}%\n"
                report += "\n"

        # LLM ë¶„ì„ì´ ì—†ëŠ” ê²½ìš° ì•ˆë‚´ ë©”ì‹œì§€
        if not llm_analysis:
            report += "## ğŸ“ Notes\n\n"
            report += "LLM ë¶„ì„ì´ ì‹¤íŒ¨í•˜ì—¬ ìƒì„¸ í‰ê°€ì™€ ê°œì„  ë°©í–¥ì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"

        return report

