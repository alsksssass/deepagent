"""ReporterAgent - ìµœì¢… ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì—ì´ì „íŠ¸"""

import logging
import asyncio
from pathlib import Path
from typing import Any, Dict, Optional
from datetime import datetime

from langchain_aws import ChatBedrockConverse
from langchain_core.messages import SystemMessage, HumanMessage

from agents.security_agent import SecurityAgent, SecurityAgentContext
from agents.performance_agent import PerformanceAgent, PerformanceAgentContext
from agents.quality_agent import QualityAgent, QualityAgentContext
from agents.architect_agent import ArchitectAgent, ArchitectAgentContext
from agents.static_analyzer.schemas import StaticAnalyzerResponse
from agents.user_aggregator.schemas import UserAggregatorResponse
from agents.user_skill_profiler.schemas import UserSkillProfilerResponse
from shared.storage import ResultStore
from shared.utils.prompt_loader import PromptLoader
from shared.utils.token_tracker import TokenTracker
from shared.utils.agent_debug_logger import AgentDebugLogger

from .schemas import ReporterContext, ReporterResponse

logger = logging.getLogger(__name__)


class ReporterAgent:
    """
    ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì—ì´ì „íŠ¸

    ë³‘ë ¬ ì²˜ë¦¬:
    - 4ê°œ ë„ë©”ì¸ ì—ì´ì „íŠ¸ ë³‘ë ¬ ì‹¤í–‰
    - 6ê°œ ë¦¬í¬íŠ¸ ì„¹ì…˜ ë³‘ë ¬ ìƒì„± (LLM í˜¸ì¶œ)
    """

    def __init__(self, llm: Optional[ChatBedrockConverse] = None):
        # í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹: YAML ëª¨ë¸ ìš°ì„ , ì™¸ë¶€ LLM ì „ë‹¬ ì‹œ ì˜¤ë²„ë¼ì´ë“œ
        if llm is None:
            # YAML ì„¤ì • ê¸°ë°˜ìœ¼ë¡œ LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            self.llm = PromptLoader.get_llm("reporter")
            model_id = PromptLoader.get_model("reporter")
            logger.info(f"âœ… ReporterAgent: YAML ëª¨ë¸ ì‚¬ìš© - {model_id}")
        else:
            # ì™¸ë¶€ ì „ë‹¬ëœ LLM ì‚¬ìš© (ì˜¤ë²„ë¼ì´ë“œ)
            self.llm = llm
            logger.info(f"âœ… ReporterAgent: ì™¸ë¶€ LLM ì‚¬ìš©")
        
        # í”„ë¡¬í”„íŠ¸ ì»´í¬ì§€ì…˜ íŒ¨í„´: YAMLì—ì„œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
        self.prompts = PromptLoader.load("reporter")

    async def run(self, context: ReporterContext) -> ReporterResponse:
        """
        ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±

        Args:
            context: ReporterContext

        Returns:
            ReporterResponse
        """
        logger.info(f"ğŸ“ Reporter: ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘")
        
        # ë””ë²„ê¹… ë¡œê±° ì´ˆê¸°í™”
        base_path = Path(context.base_path)
        debug_logger = AgentDebugLogger.get_logger(context.task_uuid, base_path, "reporter")
        
        with TokenTracker.track("reporter"), debug_logger.track_execution():
            # ìš”ì²­ ë¡œê¹…
            debug_logger.log_request(context)
            
            try:
                # ResultStoreì—ì„œ ê²°ê³¼ ë¡œë“œ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ)
                static_analysis_dict = context.static_analysis
                user_aggregate_dict = context.user_aggregate
                skill_profile_dict = {}

                if context.result_store_path:
                    try:
                        store = ResultStore(context.task_uuid, base_path)
                        
                        # StaticAnalyzer ê²°ê³¼ ë¡œë“œ
                        # S3 ì‚¬ìš© ì‹œ get_result_path()ëŠ” ë¬¸ìì—´ì„ ë°˜í™˜í•˜ë¯€ë¡œ list_available_results()ë¡œ í™•ì¸
                        available_results = store.list_available_results()
                        if "static_analyzer" in available_results:
                            static_response = store.load_result("static_analyzer", StaticAnalyzerResponse)
                            static_analysis_dict = static_response.model_dump()
                            debug_logger.log_loaded_data("static_analyzer", static_analysis_dict)
                            logger.info("âœ… ResultStoreì—ì„œ StaticAnalyzer ê²°ê³¼ ë¡œë“œ")
                        else:
                            debug_logger.log_loaded_data("static_analyzer", None, error=f"File not found: static_analyzer")
                        
                        # UserAggregator ê²°ê³¼ ë¡œë“œ
                        if "user_aggregator" in available_results:
                            user_agg_response = store.load_result("user_aggregator", UserAggregatorResponse)
                            user_aggregate_dict = user_agg_response.model_dump()
                            debug_logger.log_loaded_data("user_aggregator", user_aggregate_dict)
                            logger.info("âœ… ResultStoreì—ì„œ UserAggregator ê²°ê³¼ ë¡œë“œ")
                        else:
                            debug_logger.log_loaded_data("user_aggregator", None, error=f"File not found: user_aggregator")
                        
                        # UserSkillProfiler ê²°ê³¼ ë¡œë“œ
                        if "user_skill_profiler" in available_results:
                            skill_profile_response = store.load_result("user_skill_profiler", UserSkillProfilerResponse)
                            skill_profile_dict = skill_profile_response.model_dump()
                            debug_logger.log_loaded_data("user_skill_profiler", skill_profile_dict)
                            
                            # ìŠ¤í‚¬ í”„ë¡œíŒŒì¼ ìƒíƒœ í™•ì¸ ë¡œê¹…
                            debug_logger.log_intermediate("skill_profile_check", {
                                "exists": True,
                                "status": skill_profile_dict.get("status"),
                                "has_data": bool(skill_profile_dict.get("skill_profile")),
                                "total_skills": skill_profile_dict.get("skill_profile", {}).get("total_skills", 0),
                                "user": skill_profile_dict.get("user"),
                            })
                            
                            logger.info("âœ… ResultStoreì—ì„œ UserSkillProfiler ê²°ê³¼ ë¡œë“œ")
                        else:
                            debug_logger.log_loaded_data("user_skill_profiler", None, error=f"File not found: user_skill_profiler")
                            debug_logger.log_intermediate("skill_profile_check", {
                                "exists": False,
                                "error": "File not found",
                            })
                            logger.warning(f"âš ï¸ UserSkillProfiler ê²°ê³¼ íŒŒì¼ ì—†ìŒ: user_skill_profiler")
                    except Exception as e:
                        logger.warning(f"âš ï¸ ResultStoreì—ì„œ ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨, Context ë°ì´í„° ì‚¬ìš©: {e}")
                        debug_logger.log_loaded_data("static_analyzer", None, error=str(e))
                        debug_logger.log_loaded_data("user_aggregator", None, error=str(e))
                        debug_logger.log_loaded_data("user_skill_profiler", None, error=str(e))

                # Step 1: ë„ë©”ì¸ ì „ë¬¸ ì—ì´ì „íŠ¸ ë³‘ë ¬ ì‹¤í–‰
                logger.info("ğŸ”¬ ë„ë©”ì¸ ì „ë¬¸ ì—ì´ì „íŠ¸ ë¶„ì„ ì‹œì‘")

                # ë„ë©”ì¸ ì—ì´ì „íŠ¸ëŠ” ê°ìì˜ YAML ëª¨ë¸ ì‚¬ìš© (llm=None)
                security_agent = SecurityAgent(llm=None)
                performance_agent = PerformanceAgent(llm=None)
                quality_agent = QualityAgent(llm=None)
                architect_agent = ArchitectAgent(llm=None)

                # ê° ì—ì´ì „íŠ¸ì— ë§ëŠ” Context ìƒì„± (ResultStoreì—ì„œ ë¡œë“œí•œ ë°ì´í„° ì‚¬ìš©)
                security_ctx = SecurityAgentContext(
                    task_uuid=context.task_uuid,  # âœ… í•„ìˆ˜ í•„ë“œ ì¶”ê°€
                    static_analysis=static_analysis_dict,
                    user_aggregate=user_aggregate_dict,
                )
                performance_ctx = PerformanceAgentContext(
                    task_uuid=context.task_uuid,  # âœ… í•„ìˆ˜ í•„ë“œ ì¶”ê°€
                    static_analysis=static_analysis_dict,
                    user_aggregate=user_aggregate_dict,
                )
                quality_ctx = QualityAgentContext(
                    task_uuid=context.task_uuid,  # âœ… í•„ìˆ˜ í•„ë“œ ì¶”ê°€
                    static_analysis=static_analysis_dict,
                    user_aggregate=user_aggregate_dict,
                )
                architect_ctx = ArchitectAgentContext(
                    task_uuid=context.task_uuid,  # âœ… í•„ìˆ˜ í•„ë“œ ì¶”ê°€
                    static_analysis=static_analysis_dict,
                    user_aggregate=user_aggregate_dict,
                    repo_path=context.base_path,
                )

                (
                    security_result,
                    performance_result,
                    quality_result,
                    architecture_result,
                ) = await asyncio.gather(
                    security_agent.run(security_ctx),
                    performance_agent.run(performance_ctx),
                    quality_agent.run(quality_ctx),
                    architect_agent.run(architect_ctx),
                )

                # ë„ë©”ì¸ ë¶„ì„ ê²°ê³¼ ì €ì¥
                domain_analysis = {
                    "security": security_result.model_dump() if hasattr(security_result, "model_dump") else security_result,
                    "performance": performance_result.model_dump() if hasattr(performance_result, "model_dump") else performance_result,
                    "quality": quality_result.model_dump() if hasattr(quality_result, "model_dump") else quality_result,
                    "architecture": architecture_result.model_dump() if hasattr(architecture_result, "model_dump") else architecture_result,
                }

                # Step 2: ë³‘ë ¬ ë¦¬í¬íŠ¸ ì„¹ì…˜ ìƒì„±
                (
                    executive_summary,
                    static_analysis_section,
                    user_analysis_section,
                    skill_profile_section,
                    domain_analysis_section,
                    recommendations_section,
                ) = await asyncio.gather(
                    self._generate_executive_summary(context, static_analysis_dict, user_aggregate_dict),
                    self._generate_static_analysis_section(static_analysis_dict),
                    self._generate_user_analysis_section(user_aggregate_dict),
                    self._generate_skill_profile_section(skill_profile_dict),
                    self._generate_domain_analysis_section(domain_analysis),
                    self._generate_recommendations(static_analysis_dict, user_aggregate_dict, domain_analysis, skill_profile_dict),
                )

                # ë¦¬í¬íŠ¸ ì¡°í•©
                report_content = self._compose_report(
                    git_url=context.git_url,
                    executive_summary=executive_summary,
                    static_analysis_section=static_analysis_section,
                    user_analysis_section=user_analysis_section,
                    skill_profile_section=skill_profile_section,
                    domain_analysis_section=domain_analysis_section,
                    recommendations_section=recommendations_section,
                )

                # ë¦¬í¬íŠ¸ íŒŒì¼ëª… ìƒì„±
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                report_name = f"report_{timestamp}.md"

                # ResultStoreë¥¼ í†µí•´ ë¦¬í¬íŠ¸ ì €ì¥ (S3 ë˜ëŠ” ë¡œì»¬)
                if context.result_store_path:
                    try:
                        store = ResultStore(context.task_uuid, base_path)
                        saved_path = store.save_report(report_name, report_content)
                        logger.info(f"âœ… Reporter: ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ - {saved_path}")
                        report_path = saved_path
                    except Exception as e:
                        logger.warning(f"âš ï¸ ResultStore ì €ì¥ ì‹¤íŒ¨, ë¡œì»¬ì— ì €ì¥: {e}")
                        # Fallback: ë¡œì»¬ì— ì €ì¥
                        report_dir = base_path / "reports"
                        report_dir.mkdir(parents=True, exist_ok=True)
                        report_path = report_dir / report_name
                        report_path.write_text(report_content, encoding="utf-8")
                        logger.info(f"âœ… Reporter: ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ (ë¡œì»¬) - {report_path}")
                else:
                    # Fallback: ë¡œì»¬ì— ì €ì¥
                    report_dir = base_path / "reports"
                    report_dir.mkdir(parents=True, exist_ok=True)
                    report_path = report_dir / report_name
                    report_path.write_text(report_content, encoding="utf-8")
                    logger.info(f"âœ… Reporter: ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ (ë¡œì»¬) - {report_path}")

                response = ReporterResponse(
                    status="success",
                    report_path=str(report_path),
                )
                
                # ìµœì¢… ì‘ë‹µ ë¡œê¹…
                debug_logger.log_response(response)
                return response

            except Exception as e:
                logger.error(f"âŒ Reporter: {e}", exc_info=True)
                error_response = ReporterResponse(
                    status="failed",
                    report_path="",
                    error=str(e),
                )
                debug_logger.log_response(error_response)
                return error_response

    async def _generate_executive_summary(
        self, 
        context: ReporterContext,
        static_analysis: Dict[str, Any],
        user_aggregate: Dict[str, Any]
    ) -> str:
        """Executive Summary ìƒì„± (LLM) - í”„ë¡¬í”„íŠ¸ ì»´í¬ì§€ì…˜ íŒ¨í„´"""
        # System í”„ë¡¬í”„íŠ¸ëŠ” YAMLì—ì„œ ë¡œë“œ
        system_prompt = self.prompts["executive_summary_system"]
        
        # User í”„ë¡¬í”„íŠ¸ëŠ” ì„¹ì…˜ í…œí”Œë¦¿ì„ ì¡°í•©í•˜ì—¬ ìƒì„±
        section_templates = self.prompts.get("section_templates", {})
        
        sections = [
            PromptLoader.format(
                section_templates.get("git_repo", "**Git Repository**: {git_url}\n"),
                git_url=context.git_url or 'N/A'
            ),
            PromptLoader.format(
                section_templates.get("static_analysis_section", "**ì •ì  ë¶„ì„ ê²°ê³¼**:\n{content}\n"),
                content=self._format_static_analysis(static_analysis)
            ),
            PromptLoader.format(
                section_templates.get("user_aggregate_section", "**ìœ ì € ì§‘ê³„ ê²°ê³¼**:\n{content}\n"),
                content=self._format_user_aggregate(user_aggregate)
            ),
        ]
        
        user_prompt = "ë‹¤ìŒ ë¶„ì„ ê²°ê³¼ë¥¼ ìš”ì•½í•˜ì„¸ìš”:\n\n" + "\n".join(sections)

        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_prompt),
        ]

        # í† í° ì¶”ì 
        response = await self.llm.ainvoke(messages)
        TokenTracker.record_usage("reporter", response, model_id=PromptLoader.get_model("reporter"))
        return response.content

    async def _generate_static_analysis_section(self, static: Dict[str, Any]) -> str:
        """ì •ì  ë¶„ì„ ì„¹ì…˜ ìƒì„±"""

        if not static:
            return "ì •ì  ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

        content = "## ğŸ“Š ì •ì  ë¶„ì„ ê²°ê³¼\n\n"

        # ë³µì¡ë„
        if "complexity" in static:
            complexity = static["complexity"]
            content += "### ì½”ë“œ ë³µì¡ë„\n\n"
            content += f"- **í‰ê·  ë³µì¡ë„**: {complexity.get('average_complexity', 'N/A')}\n"
            content += f"- **ì´ í•¨ìˆ˜ ìˆ˜**: {complexity.get('total_functions', 'N/A')}\n\n"

            summary = complexity.get("summary", {})
            if summary:
                content += "**ë³µì¡ë„ ë“±ê¸‰ ë¶„í¬**:\n"
                for rank, count in summary.items():
                    content += f"- {rank}: {count}ê°œ\n"
                content += "\n"

        # íƒ€ì… ì²´í¬
        if "type_check" in static:
            type_check = static["type_check"]
            content += "### íƒ€ì… ì²´í¬\n\n"
            content += f"- **ì—ëŸ¬**: {type_check.get('total_errors', 'N/A')}\n"
            content += f"- **ê²½ê³ **: {type_check.get('total_warnings', 'N/A')}\n"
            content += f"- **ë¶„ì„ íŒŒì¼ ìˆ˜**: {type_check.get('files_analyzed', 'N/A')}\n\n"

        # LOC
        if "loc_stats" in static:
            loc = static["loc_stats"]
            content += "### ì½”ë“œ ë¼ì¸ ìˆ˜\n\n"
            content += f"- **ì´ ë¼ì¸**: {loc.get('total_lines', 'N/A'):,}\n"
            content += f"- **ì½”ë“œ ë¼ì¸**: {loc.get('code_lines', 'N/A'):,}\n"
            content += f"- **ì£¼ì„ ë¼ì¸**: {loc.get('comment_lines', 'N/A'):,}\n\n"

        return content

    async def _generate_user_analysis_section(self, user_agg: Dict[str, Any]) -> str:
        """ìœ ì € ë¶„ì„ ì„¹ì…˜ ìƒì„±"""

        if not user_agg:
            return "ìœ ì € ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

        content = "## ğŸ‘¤ ìœ ì € ë¶„ì„ ê²°ê³¼\n\n"

        aggregate = user_agg.get("aggregate_stats", {})

        content += f"### ì»¤ë°‹ í†µê³„\n\n"
        content += f"- **ì´ ì»¤ë°‹ ìˆ˜**: {aggregate.get('total_commits', 'N/A')}\n"
        content += f"- **ì„±ê³µ í‰ê°€**: {aggregate.get('successful_evaluations', 'N/A')}\n"
        content += f"- **ì‹¤íŒ¨ í‰ê°€**: {aggregate.get('failed_evaluations', 'N/A')}\n\n"

        # í’ˆì§ˆ ì ìˆ˜
        quality = aggregate.get("quality_stats", {})
        if quality:
            content += "### ì½”ë“œ í’ˆì§ˆ ì ìˆ˜\n\n"
            content += f"- **í‰ê·  ì ìˆ˜**: {quality.get('average_score', 'N/A')}/10\n"
            content += f"- **ì¤‘ì•™ê°’**: {quality.get('median_score', 'N/A')}/10\n"
            content += f"- **ìµœì†Œ/ìµœëŒ€**: {quality.get('min_score', 'N/A')} / {quality.get('max_score', 'N/A')}\n\n"

        # ê¸°ìˆ  ìŠ¤íƒ
        tech = aggregate.get("tech_stats", {})
        if tech:
            top_techs = tech.get("top_technologies", [])
            content += "### ì£¼ìš” ê¸°ìˆ  ìŠ¤íƒ\n\n"
            for tech_name, count in top_techs[:5]:
                content += f"- **{tech_name}**: {count}íšŒ\n"
            content += "\n"

        # ë³µì¡ë„ ë¶„í¬
        complexity = aggregate.get("complexity_stats", {})
        if complexity:
            content += "### ë³µì¡ë„ ë¶„í¬\n\n"
            content += f"- **Low**: {complexity.get('low_count', 0)}\n"
            content += f"- **Medium**: {complexity.get('medium_count', 0)}\n"
            content += f"- **High**: {complexity.get('high_count', 0)}\n\n"

        return content

    async def _generate_skill_profile_section(self, skill_profile: Dict[str, Any]) -> str:
        """ìŠ¤í‚¬ í”„ë¡œíŒŒì¼ ì„¹ì…˜ ìƒì„±"""
        
        if not skill_profile or skill_profile.get("status") != "success":
            return "ìŠ¤í‚¬ í”„ë¡œíŒŒì¼ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        profile_data = skill_profile.get("skill_profile", {})
        if not profile_data or profile_data.get("total_skills", 0) == 0:
            return "ìŠ¤í‚¬ í”„ë¡œíŒŒì¼ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        content = "## ğŸ¯ ê°œë°œì ìŠ¤í‚¬ í”„ë¡œíŒŒì¼\n\n"
        
        user = skill_profile.get("user", "N/A")
        content += f"**ë¶„ì„ ëŒ€ìƒ**: {user}\n\n"
        
        # ì „ì²´ ìŠ¤í‚¬ í†µê³„
        total_skills = profile_data.get("total_skills", 0)
        total_coverage = profile_data.get("total_coverage", 0)
        skills_by_level = profile_data.get("skills_by_level", {})
        
        # ë ˆë²¨ë§ ì‹œìŠ¤í…œ ì •ë³´
        total_experience = profile_data.get("total_experience", 0)
        level_info = profile_data.get("level", {})
        level = level_info.get("level", 1)
        level_name = level_info.get("level_name", "ì´ˆë³´")
        progress = level_info.get("progress_percentage", 0.0)
        next_level_exp = level_info.get("next_level_exp", 0)
        current_level_exp = level_info.get("current_level_exp", 0)

        content += "### ì „ì²´ ìŠ¤í‚¬ í†µê³„\n\n"
        content += f"- **ì´ ë³´ìœ  ìŠ¤í‚¬**: {total_skills}ê°œ\n"
        content += f"- **ì „ì²´ ì»¤ë²„ë¦¬ì§€**: {total_coverage}%\n"
        content += f"- **ë ˆë²¨ ë¶„í¬**: "
        level_parts = []
        if skills_by_level.get("Basic", 0) > 0:
            level_parts.append(f"Basic({skills_by_level['Basic']})")
        if skills_by_level.get("Intermediate", 0) > 0:
            level_parts.append(f"Intermediate({skills_by_level['Intermediate']})")
        if skills_by_level.get("Advanced", 0) > 0:
            level_parts.append(f"Advanced({skills_by_level['Advanced']})")
        content += ", ".join(level_parts) if level_parts else "N/A"
        content += "\n\n"

        # ë ˆë²¨ë§ ì‹œìŠ¤í…œ ì„¹ì…˜ ì¶”ê°€
        if total_experience > 0:
            content += "### ğŸ® ê¸°ìˆ ë ¥ ë ˆë²¨\n\n"
            content += f"- **í˜„ì¬ ë ˆë²¨**: {level_name} (Lv.{level})\n"
            content += f"- **ì´ ê²½í—˜ì¹˜**: {total_experience:,} EXP\n"
            content += f"- **ë ˆë²¨ ì§„í–‰ë¥ **: {progress:.1f}%\n"
            if next_level_exp > current_level_exp:
                exp_needed = next_level_exp - total_experience
                content += f"- **ë‹¤ìŒ ë ˆë²¨ê¹Œì§€**: {exp_needed:,} EXP í•„ìš”\n"
            content += "\n"
        
        # ì¹´í…Œê³ ë¦¬ë³„ ìŠ¤í‚¬ ë¶„í¬
        skills_by_category = profile_data.get("skills_by_category", {})
        category_coverage = profile_data.get("category_coverage", {})
        
        if skills_by_category:
            content += "### ì¹´í…Œê³ ë¦¬ë³„ ìŠ¤í‚¬ ë¶„í¬\n\n"
            # ìŠ¤í‚¬ ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            sorted_categories = sorted(
                skills_by_category.items(),
                key=lambda x: x[1].get("count", 0),
                reverse=True
            )
            
            for cat, stats in sorted_categories[:10]:  # Top 10 ì¹´í…Œê³ ë¦¬ë§Œ í‘œì‹œ
                count = stats.get("count", 0)
                coverage_info = category_coverage.get(cat, {})
                coverage_pct = coverage_info.get("percentage", 0)
                total_in_cat = coverage_info.get("total", 0)
                
                content += f"- **{cat}**: {count}ê°œ ìŠ¤í‚¬ (ì»¤ë²„ë¦¬ì§€: {coverage_pct:.1f}%, ì „ì²´: {total_in_cat}ê°œ)\n"
                # ë ˆë²¨ ë¶„í¬
                levels = stats.get("levels", {})
                level_info = []
                if levels.get("Basic", 0) > 0:
                    level_info.append(f"Basic:{levels['Basic']}")
                if levels.get("Intermediate", 0) > 0:
                    level_info.append(f"Intermediate:{levels['Intermediate']}")
                if levels.get("Advanced", 0) > 0:
                    level_info.append(f"Advanced:{levels['Advanced']}")
                if level_info:
                    content += f"  - ë ˆë²¨ ë¶„í¬: {', '.join(level_info)}\n"
            content += "\n"
        
        # ê°œë°œì íƒ€ì…ë³„ ê¸°ìˆ  ë³´ìœ ìœ¨ ì„¹ì…˜ ì¶”ê°€
        developer_type_coverage = profile_data.get("developer_type_coverage", {})
        if developer_type_coverage:
            content += "### ğŸ‘¨â€ğŸ’» ê°œë°œì íƒ€ì…ë³„ ê¸°ìˆ  ë³´ìœ ìœ¨\n\n"
            for dev_type, coverage_data in list(developer_type_coverage.items())[:10]:  # Top 10
                percentage = coverage_data.get("percentage", 0.0)
                owned_count = coverage_data.get("owned_count", 0)
                total_count = coverage_data.get("total_count", 0)
                type_exp = coverage_data.get("experience", 0)
                type_level_info = coverage_data.get("level", {})
                type_level = type_level_info.get("level", 1)
                type_level_name = type_level_info.get("level_name", "ì´ˆë³´")
                
                content += f"- **{dev_type}**: {percentage:.1f}% ({owned_count}/{total_count} ìŠ¤í‚¬) - {type_level_name} (Lv.{type_level}, {type_exp:,} EXP)\n"
            content += "\n"

        # ìƒìœ„ ìŠ¤í‚¬ (Top 10)
        top_skills = profile_data.get("top_skills", [])
        if top_skills:
            content += "### ìƒìœ„ ìŠ¤í‚¬ (Top 10)\n\n"
            for idx, skill in enumerate(top_skills[:10], 1):
                skill_name = skill.get("skill_name", "N/A")
                level = skill.get("level", "N/A")
                category = skill.get("category", "N/A")
                relevance = skill.get("relevance_score", 0)
                occurrence = skill.get("occurrence_count", 1)
                
                content += f"{idx}. **{skill_name}** ({level})\n"
                content += f"   - ì¹´í…Œê³ ë¦¬: {category}\n"
                content += f"   - ì‹ ë¢°ë„: {relevance:.2f}\n"
                content += f"   - ë°œê²¬ íšŸìˆ˜: {occurrence}íšŒ\n"
            content += "\n"
        
        return content

    async def _generate_domain_analysis_section(self, domain_analysis: Dict[str, Any]) -> str:
        """ë„ë©”ì¸ ì „ë¬¸ ì—ì´ì „íŠ¸ ë¶„ì„ ì„¹ì…˜ ìƒì„±"""
        if not domain_analysis:
            return "## ğŸ”¬ ë„ë©”ì¸ ì „ë¬¸ ë¶„ì„\n\në„ë©”ì¸ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\n"

        content = "## ğŸ”¬ ë„ë©”ì¸ ì „ë¬¸ ë¶„ì„\n\n"

        # Security Agent ê²°ê³¼
        security = domain_analysis.get("security", {})
        if security.get("status") == "success":
            sec_analysis = security.get("security_analysis", {})
            content += "### ğŸ›¡ï¸ ë³´ì•ˆ ë¶„ì„ (Security Agent)\n\n"
            content += f"**ë³´ì•ˆ ì ìˆ˜**: {sec_analysis.get('security_score', 'N/A')}/10\n\n"

            # íƒ€ì… ì•ˆì •ì„± ì´ìŠˆ
            type_issues = sec_analysis.get("type_safety_issues", [])
            if type_issues:
                content += "**íƒ€ì… ì•ˆì •ì„± ì´ìŠˆ**:\n"
                for issue in type_issues[:5]:
                    content += f"- {issue}\n"
                content += "\n"

            # ì·¨ì•½ì  ìœ„í—˜
            vuln_risks = sec_analysis.get("vulnerability_risks", [])
            if vuln_risks:
                content += "**ì·¨ì•½ì  ìœ„í—˜**:\n"
                for risk in vuln_risks[:5]:
                    severity = risk.get("severity", "Medium")
                    category = risk.get("category", "Unknown")
                    desc = risk.get("description", "")
                    content += f"- [{severity}] {category}: {desc}\n"
                content += "\n"

            # ê¶Œì¥ì‚¬í•­
            recommendations = sec_analysis.get("recommendations", [])
            if recommendations:
                content += "**ê¶Œì¥ì‚¬í•­**:\n"
                for rec in recommendations[:3]:
                    content += f"- {rec}\n"
                content += "\n"

        # Performance Agent ê²°ê³¼
        performance = domain_analysis.get("performance", {})
        if performance.get("status") == "success":
            perf_analysis = performance.get("performance_analysis", {})
            content += "### âš¡ ì„±ëŠ¥ ë¶„ì„ (Performance Agent)\n\n"
            content += f"**ì„±ëŠ¥ ì ìˆ˜**: {perf_analysis.get('performance_score', 'N/A')}/10\n\n"

            # ê³ ë³µì¡ë„ í•¨ìˆ˜
            high_comp = perf_analysis.get("high_complexity_functions", [])
            if high_comp:
                content += "**ê³ ë³µì¡ë„ í•¨ìˆ˜**:\n"
                for func in high_comp[:5]:
                    grade = func.get("grade", "N/A")
                    count = func.get("count", 0)
                    impact = func.get("impact", "")
                    content += f"- ë“±ê¸‰ {grade}: {count}ê°œ - {impact}\n"
                content += "\n"

            # ìµœì í™” ê¸°íšŒ
            opt_ops = perf_analysis.get("optimization_opportunities", [])
            if opt_ops:
                content += "**ìµœì í™” ê¸°íšŒ**:\n"
                for opp in opt_ops[:3]:
                    category = opp.get("category", "Unknown")
                    desc = opp.get("description", "")
                    content += f"- {category}: {desc}\n"
                content += "\n"

        # Quality Agent ê²°ê³¼
        quality = domain_analysis.get("quality", {})
        if quality.get("status") == "success":
            qual_analysis = quality.get("quality_analysis", {})
            content += "### ğŸ“Š í’ˆì§ˆ ë¶„ì„ (Quality Agent)\n\n"
            content += f"**í’ˆì§ˆ ì ìˆ˜**: {qual_analysis.get('quality_score', 'N/A')}/10\n\n"

            # ìœ ì§€ë³´ìˆ˜ì„± ì§€ìˆ˜
            maintainability = qual_analysis.get("maintainability_index", 0)
            content += f"**ìœ ì§€ë³´ìˆ˜ì„± ì§€ìˆ˜**: {maintainability:.1f}/100\n\n"

            # ë¬¸ì„œí™” ìˆ˜ì¤€
            doc_coverage = qual_analysis.get("documentation_coverage", 0)
            content += f"**ë¬¸ì„œí™” ì»¤ë²„ë¦¬ì§€**: {doc_coverage:.1f}%\n\n"

            # íƒ€ì… ì•ˆì •ì„± ìˆ˜ì¤€
            type_safety = qual_analysis.get("type_safety_level", "N/A")
            content += f"**íƒ€ì… ì•ˆì •ì„± ìˆ˜ì¤€**: {type_safety}\n\n"

            # ì½”ë“œ ìŠ¤ë©œ
            code_smells = qual_analysis.get("code_smells", [])
            if code_smells:
                content += "**ì½”ë“œ ìŠ¤ë©œ**:\n"
                for smell in code_smells[:5]:
                    severity = smell.get("severity", "Medium")
                    category = smell.get("category", "Unknown")
                    desc = smell.get("description", "")
                    instances = smell.get("instances", 0)
                    content += f"- [{severity}] {category}: {desc} ({instances}ê°œ)\n"
                content += "\n"

        # Architecture Agent ê²°ê³¼
        architecture = domain_analysis.get("architecture", {})
        if architecture.get("status") == "success":
            arch_analysis = architecture.get("architecture_analysis", {})
            content += "### ğŸ—ï¸ ì•„í‚¤í…ì²˜ ë¶„ì„ (Architecture Agent)\n\n"
            content += f"**ì•„í‚¤í…ì²˜ ì ìˆ˜**: {arch_analysis.get('architecture_score', 'N/A')}/10\n\n"

            # ëª¨ë“ˆí™” ì ìˆ˜
            modularity = arch_analysis.get("modularity_score", 0)
            content += f"**ëª¨ë“ˆí™” ì ìˆ˜**: {modularity:.1f}/10\n\n"

            # êµ¬ì¡° íŒ¨í„´
            patterns = arch_analysis.get("structure_patterns", [])
            if patterns:
                content += "**ì‹ë³„ëœ ì•„í‚¤í…ì²˜ íŒ¨í„´**:\n"
                for pattern in patterns[:3]:
                    pattern_name = pattern.get("pattern", "Unknown")
                    desc = pattern.get("description", "")
                    content += f"- **{pattern_name}**: {desc}\n"
                content += "\n"

            # í™•ì¥ì„± í‰ê°€
            scalability = arch_analysis.get("scalability_assessment", "")
            if scalability:
                content += f"**í™•ì¥ì„± í‰ê°€**: {scalability}\n\n"

        # ë©”ì¸ LLM ì¢…í•© ë¶„ì„
        content += "### ğŸ§  ì¢…í•© ë¶„ì„ (Main LLM)\n\n"
        content += await self._generate_domain_synthesis(domain_analysis)

        return content

    async def _generate_domain_synthesis(self, domain_analysis: Dict[str, Any]) -> str:
        """ë©”ì¸ LLMì˜ ë„ë©”ì¸ ë¶„ì„ ê²°ê³¼ ì¢…í•© - í”„ë¡¬í”„íŠ¸ ì»´í¬ì§€ì…˜ íŒ¨í„´"""
        # System í”„ë¡¬í”„íŠ¸ëŠ” YAMLì—ì„œ ë¡œë“œ
        system_prompt = self.prompts["domain_synthesis_system"]
        
        # ê° ë„ë©”ì¸ ë°ì´í„° ì¶”ì¶œ
        security_data = domain_analysis.get("security", {}).get("security_analysis", {})
        performance_data = domain_analysis.get("performance", {}).get("performance_analysis", {})
        quality_data = domain_analysis.get("quality", {}).get("quality_analysis", {})
        architecture_data = domain_analysis.get("architecture", {}).get("architecture_analysis", {})
        
        # ì„¹ì…˜ í…œí”Œë¦¿ ì¡°í•©
        section_templates = self.prompts.get("section_templates", {})
        
        sections = [
            section_templates.get("domain_analysis_intro", "ë‹¤ìŒ 4ê°œ ë„ë©”ì¸ ì „ë¬¸ ì—ì´ì „íŠ¸ì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì„¸ìš”:\n\n"),
            PromptLoader.format(
                section_templates.get("security_domain", "**ë³´ì•ˆ (Security Agent)**: ì ìˆ˜ {score}/10\n- íƒ€ì… ì•ˆì •ì„± ì´ìŠˆ: {type_safety_issues}ê°œ\n- ì·¨ì•½ì  ìœ„í—˜: {vulnerability_risks}ê°œ"),
                score=security_data.get("security_score", "N/A"),
                type_safety_issues=len(security_data.get("type_safety_issues", [])),
                vulnerability_risks=len(security_data.get("vulnerability_risks", []))
            ),
            PromptLoader.format(
                section_templates.get("performance_domain", "**ì„±ëŠ¥ (Performance Agent)**: ì ìˆ˜ {score}/10\n- ê³ ë³µì¡ë„ í•¨ìˆ˜: {high_complexity_functions}ê°œ ì¹´í…Œê³ ë¦¬\n- ìµœì í™” ê¸°íšŒ: {optimization_opportunities}ê°œ"),
                score=performance_data.get("performance_score", "N/A"),
                high_complexity_functions=len(performance_data.get("high_complexity_functions", [])),
                optimization_opportunities=len(performance_data.get("optimization_opportunities", []))
            ),
            PromptLoader.format(
                section_templates.get("quality_domain", "**í’ˆì§ˆ (Quality Agent)**: ì ìˆ˜ {score}/10\n- ìœ ì§€ë³´ìˆ˜ì„±: {maintainability_index}/100\n- íƒ€ì… ì•ˆì •ì„±: {type_safety_level}"),
                score=quality_data.get("quality_score", "N/A"),
                maintainability_index=quality_data.get("maintainability_index", "N/A"),
                type_safety_level=quality_data.get("type_safety_level", "N/A")
            ),
            PromptLoader.format(
                section_templates.get("architecture_domain", "**ì•„í‚¤í…ì²˜ (Architecture Agent)**: ì ìˆ˜ {score}/10\n- ëª¨ë“ˆí™”: {modularity_score}/10\n- ì‹ë³„ëœ íŒ¨í„´: {structure_patterns}ê°œ"),
                score=architecture_data.get("architecture_score", "N/A"),
                modularity_score=architecture_data.get("modularity_score", "N/A"),
                structure_patterns=len(architecture_data.get("structure_patterns", []))
            ),
            section_templates.get("domain_synthesis_outro", "\nì¢…í•© ë¶„ì„ì„ ì œê³µí•˜ì„¸ìš”."),
        ]
        
        user_prompt = "\n\n".join(sections)

        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_prompt),
        ]

        # í† í° ì¶”ì 
        response = await self.llm.ainvoke(messages)
        TokenTracker.record_usage("reporter", response, model_id=PromptLoader.get_model("reporter"))
        return response.content

    async def _generate_recommendations(
        self,
        static_analysis: Dict[str, Any],
        user_aggregate: Dict[str, Any],
        domain_analysis: Dict[str, Any],
        skill_profile: Dict[str, Any] = None
    ) -> str:
        """ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„± (LLM) - í”„ë¡¬í”„íŠ¸ ì»´í¬ì§€ì…˜ íŒ¨í„´"""
        # System í”„ë¡¬í”„íŠ¸ëŠ” YAMLì—ì„œ ë¡œë“œ
        system_prompt = self.prompts["recommendations_system"]
        
        # ë„ë©”ì¸ ì ìˆ˜ ì¶”ì¶œ ë° í¬ë§·íŒ…
        domain_scores = [
            PromptLoader.format(
                self.prompts.get("section_templates", {}).get("domain_score_item", "- {domain}: {score}/10\n"),
                domain="ë³´ì•ˆ",
                score=domain_analysis.get('security', {}).get('security_analysis', {}).get('security_score', 'N/A')
            ),
            PromptLoader.format(
                self.prompts.get("section_templates", {}).get("domain_score_item", "- {domain}: {score}/10\n"),
                domain="ì„±ëŠ¥",
                score=domain_analysis.get('performance', {}).get('performance_analysis', {}).get('performance_score', 'N/A')
            ),
            PromptLoader.format(
                self.prompts.get("section_templates", {}).get("domain_score_item", "- {domain}: {score}/10\n"),
                domain="í’ˆì§ˆ",
                score=domain_analysis.get('quality', {}).get('quality_analysis', {}).get('quality_score', 'N/A')
            ),
            PromptLoader.format(
                self.prompts.get("section_templates", {}).get("domain_score_item", "- {domain}: {score}/10\n"),
                domain="ì•„í‚¤í…ì²˜",
                score=domain_analysis.get('architecture', {}).get('architecture_analysis', {}).get('architecture_score', 'N/A')
            ),
        ]
        
        # ì„¹ì…˜ í…œí”Œë¦¿ ì¡°í•©
        section_templates = self.prompts.get("section_templates", {})
        
        sections = [
            section_templates.get("recommendations_intro", "ë‹¤ìŒ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°œì„  ê¶Œì¥ì‚¬í•­ì„ ì œì‹œí•˜ì„¸ìš”:\n\n"),
            PromptLoader.format(
                section_templates.get("static_analysis_label", "**ì •ì  ë¶„ì„**:\n{content}\n"),
                content=self._format_static_analysis(static_analysis)
            ),
            PromptLoader.format(
                section_templates.get("user_aggregate_label", "**ìœ ì € ì§‘ê³„**:\n{content}\n"),
                content=self._format_user_aggregate(user_aggregate)
            ),
            PromptLoader.format(
                section_templates.get("domain_scores_label", "**ë„ë©”ì¸ ë¶„ì„ ì ìˆ˜**:\n{content}\n"),
                content="".join(domain_scores)
            ),
            PromptLoader.format(
                section_templates.get("skill_profile_label", "**ìŠ¤í‚¬ í”„ë¡œíŒŒì¼ ì •ë³´**:\n{content}\n"),
                content=self._format_skill_profile_for_recommendations(skill_profile)
            ),
        ]
        
        user_prompt = "".join(sections)

        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_prompt),
        ]

        # í† í° ì¶”ì 
        response = await self.llm.ainvoke(messages)
        TokenTracker.record_usage("reporter", response, model_id=PromptLoader.get_model("reporter"))
        return response.content

    def _compose_report(
        self,
        git_url: str,
        executive_summary: str,
        static_analysis_section: str,
        user_analysis_section: str,
        skill_profile_section: str,
        domain_analysis_section: str,
        recommendations_section: str,
    ) -> str:
        """ìµœì¢… ë¦¬í¬íŠ¸ ì¡°í•©"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        report = f"""# ğŸ“Š Deep Agents Code Analysis Report

**Generated**: {timestamp}
**Repository**: {git_url}

---

## ğŸ“‹ Executive Summary

{executive_summary}

---

{static_analysis_section}

---

{user_analysis_section}

---

{skill_profile_section}

---

{domain_analysis_section}

---

## ğŸ’¡ ê°œì„  ê¶Œì¥ì‚¬í•­

{recommendations_section}

---

**End of Report**
"""
        return report

    def _format_static_analysis(self, static: Dict[str, Any]) -> str:
        """ì •ì  ë¶„ì„ ê²°ê³¼ í¬ë§·íŒ…"""
        if not static:
            return "ì •ì  ë¶„ì„ ê²°ê³¼ ì—†ìŒ"

        lines = []
        if "complexity" in static:
            lines.append(
                f"- í‰ê·  ë³µì¡ë„: {static['complexity'].get('average_complexity', 'N/A')}"
            )
        if "type_check" in static:
            lines.append(
                f"- íƒ€ì… ì—ëŸ¬: {static['type_check'].get('total_errors', 'N/A')}"
            )
        if "loc_stats" in static:
            lines.append(
                f"- ì½”ë“œ ë¼ì¸ ìˆ˜: {static['loc_stats'].get('code_lines', 'N/A'):,}"
            )

        return "\n".join(lines) if lines else "ì •ì  ë¶„ì„ ê²°ê³¼ ì—†ìŒ"

    def _format_user_aggregate(self, user_agg: Dict[str, Any]) -> str:
        """ìœ ì € ì§‘ê³„ ê²°ê³¼ í¬ë§·íŒ…"""
        if not user_agg:
            return "ìœ ì € ì§‘ê³„ ê²°ê³¼ ì—†ìŒ"

        aggregate = user_agg.get("aggregate_stats", {})
        lines = [
            f"- ì´ ì»¤ë°‹: {aggregate.get('total_commits', 'N/A')}",
            f"- í‰ê·  í’ˆì§ˆ ì ìˆ˜: {aggregate.get('quality_stats', {}).get('average_score', 'N/A')}/10",
        ]

        return "\n".join(lines)

    def _format_skill_profile_for_recommendations(self, skill_profile: Dict[str, Any]) -> str:
        """ê¶Œì¥ì‚¬í•­ ìƒì„±ì„ ìœ„í•œ ìŠ¤í‚¬ í”„ë¡œíŒŒì¼ í¬ë§·íŒ…"""
        if not skill_profile or skill_profile.get("status") != "success":
            return "ìŠ¤í‚¬ í”„ë¡œíŒŒì¼ ì •ë³´ ì—†ìŒ"
        
        profile_data = skill_profile.get("skill_profile", {})
        if not profile_data:
            return "ìŠ¤í‚¬ í”„ë¡œíŒŒì¼ ì •ë³´ ì—†ìŒ"
        
        lines = []
        total_skills = profile_data.get("total_skills", 0)
        total_coverage = profile_data.get("total_coverage", 0)
        category_coverage = profile_data.get("category_coverage", {})
        
        lines.append(f"- ì´ ë³´ìœ  ìŠ¤í‚¬: {total_skills}ê°œ")
        lines.append(f"- ì „ì²´ ì»¤ë²„ë¦¬ì§€: {total_coverage}%")
        
        # ì»¤ë²„ë¦¬ì§€ê°€ ë‚®ì€ ì¹´í…Œê³ ë¦¬ (20% ë¯¸ë§Œ)
        low_coverage_categories = []
        for cat, coverage_info in category_coverage.items():
            pct = coverage_info.get("percentage", 0)
            if pct < 20:
                low_coverage_categories.append(f"{cat} ({pct:.1f}%)")
        
        if low_coverage_categories:
            lines.append(f"- ë¶€ì¡±í•œ ìŠ¤í‚¬ ì˜ì—­: {', '.join(low_coverage_categories[:5])}")
        
        return "\n".join(lines) if lines else "ìŠ¤í‚¬ í”„ë¡œíŒŒì¼ ì •ë³´ ì—†ìŒ"
