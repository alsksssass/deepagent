"""
AgentDebugLogger - ì—ì´ì „íŠ¸ ë””ë²„ê¹… ë¡œê·¸ë¥¼ êµ¬ì¡°í™”í•˜ì—¬ ì €ì¥í•˜ëŠ” í´ë˜ìŠ¤

ì—ì´ì „íŠ¸ë³„/ì„œë¸Œì—ì´ì „íŠ¸ë³„ë¡œ ìš”ì²­, ì‘ë‹µ, LLM í˜¸ì¶œ ë“±ì„ íŒŒì¼ë¡œ ì €ì¥í•˜ì—¬
ë””ë²„ê¹… ì‹œ ì‰½ê²Œ í™•ì¸í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤.

êµ¬ì¡°:
    data/analyze/{task_uuid}/
    â”œâ”€â”€ results/              # ê¸°ì¡´ ResultStore
    â””â”€â”€ debug/                # ë””ë²„ê¹… ë¡œê·¸
        â”œâ”€â”€ agents/
        â”‚   â”œâ”€â”€ {agent_name}/
        â”‚   â”‚   â”œâ”€â”€ request.json
        â”‚   â”‚   â”œâ”€â”€ response.json
        â”‚   â”‚   â”œâ”€â”€ llm_calls/
        â”‚   â”‚   â”‚   â”œâ”€â”€ call_001_request.json
        â”‚   â”‚   â”‚   â”œâ”€â”€ call_001_response.json
        â”‚   â”‚   â”‚   â””â”€â”€ call_001_metadata.json
        â”‚   â”‚   â”œâ”€â”€ intermediate/
        â”‚   â”‚   â”‚   â””â”€â”€ {step_name}.json
        â”‚   â”‚   â”œâ”€â”€ subagents/
        â”‚   â”‚   â”‚   â””â”€â”€ {subagent_name}/
        â”‚   â”‚   â””â”€â”€ loaded_data/  # Reporterìš©
        â”‚   â”‚       â””â”€â”€ {agent_name}.json
        â””â”€â”€ metadata.json

Usage:
    # ì—ì´ì „íŠ¸ run() ë©”ì„œë“œì—ì„œ
    debug_logger = AgentDebugLogger.get_logger(task_uuid, base_path, "agent_name")
    
    # ì‹¤í–‰ ì¶”ì  (ì˜ˆì™¸ ìë™ ë¡œê¹…)
    with debug_logger.track_execution():
        # ìš”ì²­ ë¡œê¹…
        debug_logger.log_request(context)
        
        try:
            # LLM í˜¸ì¶œ ë¡œê¹… (Context Manager)
            with debug_logger.track_llm_call() as llm_tracker:
                response = await self.llm.ainvoke(messages)
                llm_tracker.set_messages(messages)
                llm_tracker.set_response(response)
            
            # ì¤‘ê°„ ë‹¨ê³„ ë¡œê¹…
            debug_logger.log_intermediate("step_name", data)
            
            # ì„œë¸Œì—ì´ì „íŠ¸ ë¡œê¹…
            subagent_logger = debug_logger.get_subagent_logger("subagent_name")
            subagent_logger.log_request(sub_request)
            subagent_logger.log_response(sub_response)
            
            # ìµœì¢… ì‘ë‹µ ë¡œê¹…
            debug_logger.log_response(response)
            
        except Exception as e:
            # ìˆ˜ë™ ì˜¤ë¥˜ ë¡œê¹… (ì„ íƒì  - track_executionì´ ìë™ìœ¼ë¡œë„ ë¡œê¹…í•¨)
            debug_logger.log_exception(
                e,
                context={"step": "processing", "input": input_data},
                step_name="data_processing"
            )
            raise
"""

import json
import logging
import os
from pathlib import Path
from typing import Any, Dict, Optional, List
from datetime import datetime
from contextlib import contextmanager
from dataclasses import dataclass, field, asdict

logger = logging.getLogger(__name__)


@dataclass
class LLMCallMetadata:
    """LLM í˜¸ì¶œ ë©”íƒ€ë°ì´í„°"""
    call_id: str
    timestamp: str
    agent_name: str
    model_id: Optional[str] = None
    input_tokens: Optional[int] = None
    output_tokens: Optional[int] = None
    execution_time_ms: Optional[float] = None
    error: Optional[str] = None


class LLMCallTracker:
    """LLM í˜¸ì¶œ ì¶”ì  Context Manager (ê°œì„ íŒ)"""
    
    def __init__(self, debug_logger: 'AgentDebugLogger'):
        self.debug_logger = debug_logger
        self.call_id = None
        self.messages = None
        self.response = None
        self.start_time = None
        self.metadata: Optional[LLMCallMetadata] = None
        
        # í”„ë¡¬í”„íŠ¸ ì •ë³´
        self.template_name: Optional[str] = None
        self.variables: Optional[Dict[str, Any]] = None
        self.system_prompt: Optional[str] = None
        self.user_prompt: Optional[str] = None
        
        # ì‘ë‹µ ì²˜ë¦¬ ì •ë³´
        self.raw_response: Optional[str] = None
        self.parsed_json: Optional[Dict[str, Any]] = None
        self.validated_model: Optional[Any] = None
        self.processing_error: Optional[str] = None
        
    def __enter__(self):
        self.call_id = self.debug_logger._get_next_call_id()
        self.start_time = datetime.now()
        return self
        
    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.messages and self.response:
            execution_time_ms = None
            if self.start_time:
                execution_time_ms = (datetime.now() - self.start_time).total_seconds() * 1000
            
            # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
            model_id = None
            input_tokens = None
            output_tokens = None
            
            if hasattr(self.response, 'response_metadata'):
                metadata = self.response.response_metadata
                if isinstance(metadata, dict):
                    usage = metadata.get("usage", {})
                    if isinstance(usage, dict):
                        input_tokens = usage.get("input_tokens")
                        output_tokens = usage.get("output_tokens")
                    model_id = metadata.get("model_id")
            
            self.metadata = LLMCallMetadata(
                call_id=self.call_id,
                timestamp=datetime.now().isoformat(),
                agent_name=self.debug_logger.agent_name,
                model_id=model_id,
                input_tokens=input_tokens,
                output_tokens=output_tokens,
                execution_time_ms=execution_time_ms,
                error=str(exc_val) if exc_val else None
            )
            
            self.debug_logger._save_llm_call_enhanced(
                self.call_id,
                self.messages,
                self.response,
                self.metadata,
                template_name=self.template_name,
                variables=self.variables,
                system_prompt=self.system_prompt,
                user_prompt=self.user_prompt,
                raw_response=self.raw_response,
                parsed_json=self.parsed_json,
                validated_model=self.validated_model,
                processing_error=self.processing_error,
            )
        
        return False  # ì˜ˆì™¸ë¥¼ ë‹¤ì‹œ ë°œìƒì‹œí‚´
    
    def log_prompts(
        self,
        template_name: str,
        variables: Dict[str, Any],
        system_prompt: str,
        user_prompt: str,
    ):
        """
        í”„ë¡¬í”„íŠ¸ ìƒì„± ì •ë³´ ë¡œê¹…
        
        Args:
            template_name: í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì´ë¦„ (ì˜ˆ: "security_agent")
            variables: í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜ ë”•ì…”ë„ˆë¦¬
            system_prompt: ìµœì¢… System Prompt
            user_prompt: ìµœì¢… User Prompt
        """
        self.template_name = template_name
        self.variables = variables
        self.system_prompt = system_prompt
        self.user_prompt = user_prompt
    
    def log_response_stages(
        self,
        raw: str,
        parsed: Optional[Dict[str, Any]] = None,
        validated: Optional[Any] = None,
        error: Optional[str] = None,
    ):
        """
        LLM ì‘ë‹µ ì²˜ë¦¬ ë‹¨ê³„ë³„ ë¡œê¹…
        
        Args:
            raw: LLM ì›ë³¸ ì‘ë‹µ
            parsed: JSON íŒŒì‹± ê²°ê³¼
            validated: Pydantic ê²€ì¦ ê²°ê³¼
            error: ì—ëŸ¬ ë©”ì‹œì§€ (ìˆëŠ” ê²½ìš°)
        """
        self.raw_response = raw
        self.parsed_json = parsed
        self.validated_model = validated
        self.processing_error = error
    
    def set_messages(self, messages: List[Any]):
        """LLM í˜¸ì¶œ ë©”ì‹œì§€ ì„¤ì •"""
        self.messages = messages
        
    def set_response(self, response: Any):
        """LLM ì‘ë‹µ ì„¤ì •"""
        self.response = response


class AgentDebugLogger:
    """
    ì—ì´ì „íŠ¸ ë””ë²„ê¹… ë¡œê·¸ë¥¼ êµ¬ì¡°í™”í•˜ì—¬ ì €ì¥í•˜ëŠ” í´ë˜ìŠ¤
    
    TokenTrackerì™€ ìœ ì‚¬í•œ íŒ¨í„´ìœ¼ë¡œ ì‚¬ìš©:
    - ì‹±ê¸€í†¤ íŒ¨í„´ (ì—ì´ì „íŠ¸ë³„ ì¸ìŠ¤í„´ìŠ¤)
    - Context Managerë¡œ ìë™ ë¡œê¹…
    - ìµœì†Œí•œì˜ ì½”ë“œ ë³€ê²½ìœ¼ë¡œ ì ìš©
    - ì„œë¸Œ ì—ì´ì „íŠ¸ ë¡œê¹… ì§€ì› (í™˜ê²½ ë³€ìˆ˜ë¡œ ì œì–´)
    """
    
    _loggers: Dict[str, 'AgentDebugLogger'] = {}
    _enabled: Optional[bool] = None
    _subagent_enabled: Optional[bool] = None
    
    def __init__(self, task_uuid: str, base_path: Path, agent_name: str, is_subagent: bool = False):
        """
        AgentDebugLogger ì´ˆê¸°í™”
        
        Args:
            task_uuid: ì‘ì—… ê³ ìœ  UUID
            base_path: ì‘ì—… ê¸°ë³¸ ê²½ë¡œ (ì˜ˆ: Path("./data/analyze/{task_uuid}"))
            agent_name: ì—ì´ì „íŠ¸ ì´ë¦„ (ì˜ˆ: "user_skill_profiler", "reporter")
            is_subagent: ì„œë¸Œ ì—ì´ì „íŠ¸ ì—¬ë¶€ (ê¸°ë³¸ê°’: False)
        """
        self.task_uuid = task_uuid
        self.base_path = Path(base_path)
        self.agent_name = agent_name
        self.is_subagent = is_subagent
        
        # ë””ë²„ê·¸ ë””ë ‰í† ë¦¬: data/analyze/{task_uuid}/debug/agents/{agent_name}
        self.debug_dir = self.base_path / "debug" / "agents" / agent_name
        self.debug_dir.mkdir(parents=True, exist_ok=True)
        
        # í•˜ìœ„ ë””ë ‰í† ë¦¬ ìƒì„±
        (self.debug_dir / "llm_calls").mkdir(exist_ok=True)
        (self.debug_dir / "intermediate").mkdir(exist_ok=True)
        (self.debug_dir / "subagents").mkdir(exist_ok=True)
        (self.debug_dir / "loaded_data").mkdir(exist_ok=True)
        (self.debug_dir / "errors").mkdir(exist_ok=True)  # âœ… ì˜¤ë¥˜ ë¡œê·¸ ë””ë ‰í† ë¦¬
        
        self.llm_call_counter = 0
        self.error_counter = 0  # âœ… ì˜¤ë¥˜ ì¹´ìš´í„°
        self.start_time = None
        self.errors_summary = []  # âœ… ì˜¤ë¥˜ ìš”ì•½ ë¦¬ìŠ¤íŠ¸
        
        logger.debug(f"ğŸ” AgentDebugLogger ì´ˆê¸°í™”: {self.debug_dir} (ì„œë¸Œì—ì´ì „íŠ¸: {is_subagent})")
    
    @classmethod
    def is_enabled(cls) -> bool:
        """ë””ë²„ê¹… ë¡œê¹… í™œì„±í™” ì—¬ë¶€ í™•ì¸"""
        if cls._enabled is None:
            # í™˜ê²½ ë³€ìˆ˜ í™•ì¸ (ê¸°ë³¸ê°’: True)
            cls._enabled = os.getenv("ENABLE_DEBUG_LOGGING", "true").lower() == "true"
        return cls._enabled
    
    @classmethod
    def is_subagent_enabled(cls) -> bool:
        """ì„œë¸Œ ì—ì´ì „íŠ¸ ë””ë²„ê¹… ë¡œê¹… í™œì„±í™” ì—¬ë¶€ í™•ì¸"""
        if cls._subagent_enabled is None:
            # í™˜ê²½ ë³€ìˆ˜ í™•ì¸ (ê¸°ë³¸ê°’: False - ì„±ëŠ¥ì„ ìœ„í•´)
            cls._subagent_enabled = os.getenv("ENABLE_SUBAGENT_DEBUG_LOGGING", "false").lower() == "true"
        return cls._subagent_enabled
    
    @classmethod
    def get_logger(cls, task_uuid: str, base_path: str | Path, agent_name: str, is_subagent: bool = False) -> 'AgentDebugLogger':
        """
        ì—ì´ì „íŠ¸ë³„ ë¡œê±° ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸° (ì‹±ê¸€í†¤)
        
        Args:
            task_uuid: ì‘ì—… ê³ ìœ  UUID
            base_path: ì‘ì—… ê¸°ë³¸ ê²½ë¡œ
            agent_name: ì—ì´ì „íŠ¸ ì´ë¦„
            is_subagent: ì„œë¸Œ ì—ì´ì „íŠ¸ ì—¬ë¶€ (ê¸°ë³¸ê°’: False)
            
        Returns:
            AgentDebugLogger ì¸ìŠ¤í„´ìŠ¤ (ë¹„í™œì„±í™” ì‹œ DummyDebugLogger)
        """
        # ë©”ì¸ ì—ì´ì „íŠ¸ëŠ” ENABLE_DEBUG_LOGGINGìœ¼ë¡œ ì œì–´
        if not is_subagent and not cls.is_enabled():
            return DummyDebugLogger()
        
        # ì„œë¸Œ ì—ì´ì „íŠ¸ëŠ” ENABLE_SUBAGENT_DEBUG_LOGGINGìœ¼ë¡œ ì œì–´
        if is_subagent and not cls.is_subagent_enabled():
            return DummyDebugLogger()
        
        key = f"{task_uuid}:{agent_name}"
        if key not in cls._loggers:
            cls._loggers[key] = cls(task_uuid, base_path, agent_name, is_subagent)
        return cls._loggers[key]
    
    @contextmanager
    def track_execution(self):
        """ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹œê°„ ì¶”ì  Context Manager (ì˜ˆì™¸ ìë™ ë¡œê¹…)"""
        import traceback
        
        self.start_time = datetime.now()
        error_occurred = False
        error_info = None
        
        try:
            yield
        except Exception as e:
            error_occurred = True
            error_info = e
            # ìë™ìœ¼ë¡œ ì˜¤ë¥˜ ë¡œê¹…
            try:
                traceback_str = traceback.format_exc()
                self.log_exception(e, traceback_str=traceback_str, step_name="agent_execution")
            except Exception as log_error:
                # ë¡œê¹… ì‹¤íŒ¨ ì‹œì—ë„ ì›ë˜ ì˜ˆì™¸ë¥¼ ìœ ì§€
                logger.warning(f"âš ï¸ ì˜¤ë¥˜ ë¡œê¹… ì‹¤íŒ¨ ({self.agent_name}): {log_error}")
            raise  # ì˜ˆì™¸ë¥¼ ë‹¤ì‹œ ë°œìƒì‹œí‚´
        finally:
            execution_time = None
            if self.start_time:
                execution_time = (datetime.now() - self.start_time).total_seconds() * 1000
            
            # ë©”íƒ€ë°ì´í„° ì €ì¥ (ì—ëŸ¬ ì •ë³´ í¬í•¨)
            metadata = {
                "agent_name": self.agent_name,
                "task_uuid": self.task_uuid,
                "start_time": self.start_time.isoformat() if self.start_time else None,
                "end_time": datetime.now().isoformat(),
                "execution_time_ms": execution_time,
                "llm_call_count": self.llm_call_counter,
                "error_count": self.error_counter,  # âœ… ì—ëŸ¬ ì¹´ìš´íŠ¸ ì¶”ê°€
                "has_errors": error_occurred,  # âœ… ì—ëŸ¬ ë°œìƒ ì—¬ë¶€
                "last_error_type": type(error_info).__name__ if error_info else None,  # âœ… ë§ˆì§€ë§‰ ì—ëŸ¬ íƒ€ì…
            }
            
            metadata_path = self.debug_dir / "metadata.json"
            try:
                metadata_path.write_text(
                    json.dumps(metadata, indent=2, ensure_ascii=False),
                    encoding="utf-8"
                )
            except Exception as e:
                logger.warning(f"âš ï¸ ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨ ({self.agent_name}): {e}")
            
            # ì—ëŸ¬ ìš”ì•½ ì €ì¥
            if self.errors_summary:
                try:
                    self._save_errors_summary()
                except Exception as e:
                    logger.warning(f"âš ï¸ ì—ëŸ¬ ìš”ì•½ ì €ì¥ ì‹¤íŒ¨ ({self.agent_name}): {e}")
    
    def track_llm_call(self) -> LLMCallTracker:
        """LLM í˜¸ì¶œ ì¶”ì  Context Manager"""
        return LLMCallTracker(self)
    
    def log_request(self, context: Any):
        """
        ì—ì´ì „íŠ¸ ìš”ì²­(Context) ë¡œê¹…
        
        Args:
            context: ì—ì´ì „íŠ¸ Context ê°ì²´ (Pydantic ëª¨ë¸ ë˜ëŠ” dict)
        """
        try:
            if hasattr(context, 'model_dump'):
                # Pydantic ëª¨ë¸
                data = context.model_dump()
            elif hasattr(context, 'dict'):
                # Pydantic ëª¨ë¸ (êµ¬ë²„ì „)
                data = context.dict()
            elif isinstance(context, dict):
                data = context
            else:
                data = {"raw": str(context)}
            
            request_data = {
                "timestamp": datetime.now().isoformat(),
                "agent_name": self.agent_name,
                "task_uuid": self.task_uuid,
                "context": data,
            }
            
            request_path = self.debug_dir / "request.json"
            request_path.write_text(
                json.dumps(request_data, indent=2, ensure_ascii=False, default=str),
                encoding="utf-8"
            )
            
            logger.debug(f"ğŸ” ë””ë²„ê·¸ ë¡œê·¸ ì €ì¥: {request_path}")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ìš”ì²­ ë¡œê¹… ì‹¤íŒ¨ ({self.agent_name}): {e}")
    
    def log_response(self, response: Any):
        """
        ì—ì´ì „íŠ¸ ì‘ë‹µ(Response) ë¡œê¹…
        
        Args:
            response: ì—ì´ì „íŠ¸ Response ê°ì²´ (Pydantic ëª¨ë¸ ë˜ëŠ” dict)
        """
        try:
            if hasattr(response, 'model_dump'):
                # Pydantic ëª¨ë¸
                data = response.model_dump()
            elif hasattr(response, 'dict'):
                # Pydantic ëª¨ë¸ (êµ¬ë²„ì „)
                data = response.dict()
            elif isinstance(response, dict):
                data = response
            else:
                data = {"raw": str(response)}
            
            response_data = {
                "timestamp": datetime.now().isoformat(),
                "agent_name": self.agent_name,
                "task_uuid": self.task_uuid,
                "response": data,
            }
            
            response_path = self.debug_dir / "response.json"
            response_path.write_text(
                json.dumps(response_data, indent=2, ensure_ascii=False, default=str),
                encoding="utf-8"
            )
            
            logger.debug(f"ğŸ” ë””ë²„ê·¸ ë¡œê·¸ ì €ì¥: {response_path}")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ì‘ë‹µ ë¡œê¹… ì‹¤íŒ¨ ({self.agent_name}): {e}")
    
    def log_intermediate(self, step_name: str, data: Any):
        """
        ì¤‘ê°„ ë‹¨ê³„ ë°ì´í„° ë¡œê¹…
        
        Args:
            step_name: ë‹¨ê³„ ì´ë¦„ (íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©)
            data: ë¡œê¹…í•  ë°ì´í„°
        """
        try:
            if hasattr(data, 'model_dump'):
                data_dict = data.model_dump()
            elif hasattr(data, 'dict'):
                data_dict = data.dict()
            elif isinstance(data, dict):
                data_dict = data
            else:
                data_dict = {"raw": str(data)}
            
            intermediate_data = {
                "timestamp": datetime.now().isoformat(),
                "step_name": step_name,
                "agent_name": self.agent_name,
                "data": data_dict,
            }
            
            # íŒŒì¼ëª…ì—ì„œ íŠ¹ìˆ˜ë¬¸ì ì œê±°
            safe_step_name = "".join(c if c.isalnum() or c in ('-', '_') else '_' for c in step_name)
            intermediate_path = self.debug_dir / "intermediate" / f"{safe_step_name}.json"
            intermediate_path.write_text(
                json.dumps(intermediate_data, indent=2, ensure_ascii=False, default=str),
                encoding="utf-8"
            )
            
            logger.debug(f"ğŸ” ì¤‘ê°„ ë‹¨ê³„ ë¡œê·¸ ì €ì¥: {intermediate_path}")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ì¤‘ê°„ ë‹¨ê³„ ë¡œê¹… ì‹¤íŒ¨ ({self.agent_name}/{step_name}): {e}")
    
    def get_subagent_logger(self, subagent_name: str) -> 'AgentDebugLogger':
        """
        ì„œë¸Œì—ì´ì „íŠ¸ ë¡œê±° ê°€ì ¸ì˜¤ê¸°
        
        ì„œë¸Œ ì—ì´ì „íŠ¸ëŠ” ë¶€ëª¨ ì—ì´ì „íŠ¸ì˜ subagents/ ë””ë ‰í† ë¦¬ ì•„ë˜ì— ìœ„ì¹˜í•©ë‹ˆë‹¤.
        ì˜ˆ: debug/agents/user_skill_profiler/subagents/code_batch_processor_batch_0/
        
        Args:
            subagent_name: ì„œë¸Œì—ì´ì „íŠ¸ ì´ë¦„ (ì˜ˆ: "code_batch_processor_batch_0")
            
        Returns:
            AgentDebugLogger ì¸ìŠ¤í„´ìŠ¤ (ì„œë¸Œì—ì´ì „íŠ¸ìš©)
        """
        # ì„œë¸Œ ì—ì´ì „íŠ¸ ë¡œê¹…ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´ ë”ë¯¸ ë¡œê±° ë°˜í™˜
        if not AgentDebugLogger.is_subagent_enabled():
            return DummyDebugLogger()
        
        # ì„œë¸Œì—ì´ì „íŠ¸ ê²½ë¡œ: {parent_debug_dir}/subagents/{subagent_name}
        subagent_path = self.debug_dir / "subagents" / subagent_name
        subagent_logger = AgentDebugLogger(
            self.task_uuid,
            self.base_path,
            f"{self.agent_name}/subagents/{subagent_name}",
            is_subagent=True
        )
        # ì„œë¸Œì—ì´ì „íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ë³€ê²½
        subagent_logger.debug_dir = subagent_path
        subagent_logger.debug_dir.mkdir(parents=True, exist_ok=True)
        (subagent_logger.debug_dir / "llm_calls").mkdir(exist_ok=True)
        (subagent_logger.debug_dir / "intermediate").mkdir(exist_ok=True)
        (subagent_logger.debug_dir / "errors").mkdir(exist_ok=True)  # âœ… ì„œë¸Œì—ì´ì „íŠ¸ë„ errors ë””ë ‰í† ë¦¬ ìƒì„±
        
        return subagent_logger
    
    def log_loaded_data(self, agent_name: str, data: Any, error: Optional[str] = None):
        """
        ResultStoreì—ì„œ ë¡œë“œí•œ ë°ì´í„° ë¡œê¹… (Reporterìš©)
        
        Args:
            agent_name: ë¡œë“œí•œ ì—ì´ì „íŠ¸ ì´ë¦„
            data: ë¡œë“œí•œ ë°ì´í„° (Noneì´ë©´ ë¡œë“œ ì‹¤íŒ¨)
            error: ì—ëŸ¬ ë©”ì‹œì§€ (ìˆëŠ” ê²½ìš°)
        """
        try:
            loaded_data = {
                "timestamp": datetime.now().isoformat(),
                "loaded_by": self.agent_name,
                "source_agent": agent_name,
                "load_success": data is not None,
                "error": error,
            }
            
            if data is not None:
                if hasattr(data, 'model_dump'):
                    loaded_data["data"] = data.model_dump()
                elif hasattr(data, 'dict'):
                    loaded_data["data"] = data.dict()
                elif isinstance(data, dict):
                    loaded_data["data"] = data
                else:
                    loaded_data["data"] = {"raw": str(data)}
            
            loaded_path = self.debug_dir / "loaded_data" / f"{agent_name}.json"
            loaded_path.write_text(
                json.dumps(loaded_data, indent=2, ensure_ascii=False, default=str),
                encoding="utf-8"
            )
            
            logger.debug(f"ğŸ” ë¡œë“œ ë°ì´í„° ë¡œê·¸ ì €ì¥: {loaded_path}")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ë¡œë“œ ë°ì´í„° ë¡œê¹… ì‹¤íŒ¨ ({self.agent_name}/{agent_name}): {e}")
    
    def log_error(
        self,
        error: Exception | str,
        context: Optional[Dict[str, Any]] = None,
        traceback_str: Optional[str] = None,
        step_name: Optional[str] = None,
    ):
        """
        ì—ëŸ¬ ë¡œê¹… (ì¼ë°˜)
        
        Args:
            error: Exception ê°ì²´ ë˜ëŠ” ì—ëŸ¬ ë©”ì‹œì§€ ë¬¸ìì—´
            context: ì—ëŸ¬ ë°œìƒ ì‹œì ì˜ ì»¨í…ìŠ¤íŠ¸ ì •ë³´
            traceback_str: íŠ¸ë ˆì´ìŠ¤ë°± ë¬¸ìì—´
            step_name: ì—ëŸ¬ê°€ ë°œìƒí•œ ë‹¨ê³„ ì´ë¦„
        """
        import traceback
        
        try:
            # ì—ëŸ¬ ì •ë³´ ì¶”ì¶œ
            if isinstance(error, Exception):
                error_type = type(error).__name__
                error_message = str(error)
                if traceback_str is None:
                    traceback_str = traceback.format_exc()
            else:
                error_type = "Error"
                error_message = str(error)
                if traceback_str is None:
                    traceback_str = None
            
            self._save_error_log(
                error_type=error_type,
                error_message=error_message,
                traceback_str=traceback_str,
                context=context,
                step_name=step_name,
            )
            
        except Exception as e:
            logger.warning(f"âš ï¸ ì—ëŸ¬ ë¡œê¹… ì‹¤íŒ¨ ({self.agent_name}): {e}")
    
    def log_exception(
        self,
        exception: Exception,
        context: Optional[Dict[str, Any]] = None,
        traceback_str: Optional[str] = None,
        step_name: Optional[str] = None,
    ):
        """
        ì˜ˆì™¸ ë¡œê¹… (Exception ê°ì²´ ì „ìš©, íŠ¸ë ˆì´ìŠ¤ë°± í¬í•¨)
        
        Args:
            exception: Exception ê°ì²´
            context: ì˜ˆì™¸ ë°œìƒ ì‹œì ì˜ ì»¨í…ìŠ¤íŠ¸ ì •ë³´
            traceback_str: íŠ¸ë ˆì´ìŠ¤ë°± ë¬¸ìì—´ (ì—†ìœ¼ë©´ ìë™ ìƒì„±)
            step_name: ì˜ˆì™¸ê°€ ë°œìƒí•œ ë‹¨ê³„ ì´ë¦„
        """
        import traceback
        
        try:
            error_type = type(exception).__name__
            error_message = str(exception)
            
            if traceback_str is None:
                traceback_str = traceback.format_exc()
            
            self._save_error_log(
                error_type=error_type,
                error_message=error_message,
                traceback_str=traceback_str,
                context=context,
                step_name=step_name,
            )
            
        except Exception as e:
            logger.warning(f"âš ï¸ ì˜ˆì™¸ ë¡œê¹… ì‹¤íŒ¨ ({self.agent_name}): {e}")
    
    def _save_error_log(
        self,
        error_type: str,
        error_message: str,
        traceback_str: Optional[str],
        context: Optional[Dict[str, Any]],
        step_name: Optional[str],
    ):
        """ì—ëŸ¬ ë¡œê·¸ íŒŒì¼ ì €ì¥ (ë‚´ë¶€ ë©”ì„œë“œ)"""
        try:
            self.error_counter += 1
            error_id = f"error_{self.error_counter:03d}"
            timestamp = datetime.now().isoformat()
            
            # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
            execution_time_ms = None
            if self.start_time:
                execution_time_ms = (datetime.now() - self.start_time).total_seconds() * 1000
            
            # ì—ëŸ¬ ë¡œê·¸ ë°ì´í„°
            error_data = {
                "error_id": error_id,
                "timestamp": timestamp,
                "agent_name": self.agent_name,
                "task_uuid": self.task_uuid,
                "error_type": error_type,
                "error_message": error_message,
                "step_name": step_name,
                "context": context or {},
                "traceback": traceback_str,
                "execution_time_ms": execution_time_ms,
                "llm_call_count": self.llm_call_counter,
            }
            
            # ì—ëŸ¬ ë¡œê·¸ íŒŒì¼ ì €ì¥
            error_path = self.debug_dir / "errors" / f"{error_id}.json"
            error_path.write_text(
                json.dumps(error_data, indent=2, ensure_ascii=False, default=str),
                encoding="utf-8"
            )
            
            # ì—ëŸ¬ ìš”ì•½ì— ì¶”ê°€
            self.errors_summary.append({
                "error_id": error_id,
                "timestamp": timestamp,
                "error_type": error_type,
                "error_message": error_message[:200],  # ë©”ì‹œì§€ ê¸¸ì´ ì œí•œ
                "step_name": step_name,
            })
            
            logger.error(f"âŒ ì—ëŸ¬ ë¡œê·¸ ì €ì¥: {error_path} ({error_type}: {error_message[:100]})")
            
        except Exception as e:
            # ì—ëŸ¬ ë¡œê¹… ì‹¤íŒ¨ ì‹œì—ë„ ì›ë˜ ì—ëŸ¬ ì •ë³´ë¥¼ ë¡œê±°ì— ê¸°ë¡
            logger.error(f"âŒ ì—ëŸ¬ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨ ({self.agent_name}): {e}")
    
    def _save_errors_summary(self):
        """ì—ëŸ¬ ìš”ì•½ íŒŒì¼ ì €ì¥"""
        try:
            if not self.errors_summary:
                return
            
            # ì—ëŸ¬ íƒ€ì…ë³„ í†µê³„
            errors_by_type = {}
            errors_by_step = {}
            
            for error in self.errors_summary:
                error_type = error["error_type"]
                step_name = error.get("step_name", "unknown")
                
                errors_by_type[error_type] = errors_by_type.get(error_type, 0) + 1
                errors_by_step[step_name] = errors_by_step.get(step_name, 0) + 1
            
            summary_data = {
                "total_errors": len(self.errors_summary),
                "errors_by_type": errors_by_type,
                "errors_by_step": errors_by_step,
                "first_error": self.errors_summary[0]["timestamp"] if self.errors_summary else None,
                "last_error": self.errors_summary[-1]["timestamp"] if self.errors_summary else None,
                "errors": self.errors_summary,  # ëª¨ë“  ì—ëŸ¬ ìš”ì•½
            }
            
            summary_path = self.debug_dir / "errors" / "errors_summary.json"
            summary_path.write_text(
                json.dumps(summary_data, indent=2, ensure_ascii=False, default=str),
                encoding="utf-8"
            )
            
            logger.debug(f"ğŸ” ì—ëŸ¬ ìš”ì•½ ì €ì¥: {summary_path}")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ì—ëŸ¬ ìš”ì•½ ì €ì¥ ì‹¤íŒ¨ ({self.agent_name}): {e}")
    
    def _get_next_call_id(self) -> str:
        """ë‹¤ìŒ LLM í˜¸ì¶œ ID ìƒì„±"""
        self.llm_call_counter += 1
        return f"call_{self.llm_call_counter:03d}"
    
    def _save_llm_call_enhanced(
        self,
        call_id: str,
        messages: List[Any],
        response: Any,
        metadata: LLMCallMetadata,
        template_name: Optional[str] = None,
        variables: Optional[Dict[str, Any]] = None,
        system_prompt: Optional[str] = None,
        user_prompt: Optional[str] = None,
        raw_response: Optional[str] = None,
        parsed_json: Optional[Dict[str, Any]] = None,
        validated_model: Optional[Any] = None,
        processing_error: Optional[str] = None,
    ):
        """
        LLM í˜¸ì¶œ ìƒì„¸ ì •ë³´ ì €ì¥ (ê°œì„ íŒ)
        
        ë””ë ‰í† ë¦¬ êµ¬ì¡°:
            llm_calls/call_001/
                â”œâ”€â”€ 01_prompt_template_info.json
                â”œâ”€â”€ 02_prompt_variables.json
                â”œâ”€â”€ 03_system_prompt.txt
                â”œâ”€â”€ 04_user_prompt.txt
                â”œâ”€â”€ 05_llm_request.json
                â”œâ”€â”€ 06_llm_response_raw.txt
                â”œâ”€â”€ 07_llm_response_parsed.json
                â”œâ”€â”€ 08_pydantic_validated.json
                â”œâ”€â”€ 09_metadata.json
                â””â”€â”€ summary.md
        
        Args:
            call_id: í˜¸ì¶œ ID
            messages: LLM ì…ë ¥ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
            response: LLM ì‘ë‹µ ê°ì²´
            metadata: ë©”íƒ€ë°ì´í„°
            template_name: í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì´ë¦„
            variables: í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜
            system_prompt: ìµœì¢… System Prompt
            user_prompt: ìµœì¢… User Prompt
            raw_response: LLM ì›ë³¸ ì‘ë‹µ
            parsed_json: JSON íŒŒì‹± ê²°ê³¼
            validated_model: Pydantic ê²€ì¦ ê²°ê³¼
            processing_error: ì²˜ë¦¬ ì—ëŸ¬
        """
        try:
            # call_id ë””ë ‰í† ë¦¬ ìƒì„±
            call_dir = self.debug_dir / "llm_calls" / call_id
            call_dir.mkdir(parents=True, exist_ok=True)
            
            # 01. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ë³´
            if template_name:
                template_info = {
                    "template_name": template_name,
                    "agent_name": self.agent_name,
                    "call_id": call_id,
                }
                self._write_json(
                    call_dir / "01_prompt_template_info.json",
                    template_info
                )
            
            # 02. í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜
            if variables:
                self._write_json(
                    call_dir / "02_prompt_variables.json",
                    variables
                )
            
            # 03. System Prompt (TXT)
            if system_prompt:
                self._write_text(
                    call_dir / "03_system_prompt.txt",
                    system_prompt
                )
            
            # 04. User Prompt (TXT)
            if user_prompt:
                self._write_text(
                    call_dir / "04_user_prompt.txt",
                    user_prompt
                )
            
            # 05. LLM Request (JSON)
            request_data = {
                "call_id": call_id,
                "timestamp": metadata.timestamp,
                "agent_name": self.agent_name,
                "model_id": metadata.model_id,
                "messages": self._serialize_messages(messages),
            }
            self._write_json(
                call_dir / "05_llm_request.json",
                request_data
            )
            
            # 06. LLM Response Raw (TXT)
            response_content = raw_response
            if response_content is None:
                if hasattr(response, 'content'):
                    response_content = response.content
                elif isinstance(response, str):
                    response_content = response
                else:
                    response_content = str(response)
            
            self._write_text(
                call_dir / "06_llm_response_raw.txt",
                response_content
            )
            
            # 07. LLM Response Parsed (JSON)
            if parsed_json is not None:
                self._write_json(
                    call_dir / "07_llm_response_parsed.json",
                    parsed_json
                )
            elif response_content:
                # ìë™ íŒŒì‹± ì‹œë„
                auto_parsed = self._try_parse_json(response_content)
                if auto_parsed:
                    self._write_json(
                        call_dir / "07_llm_response_parsed.json",
                        auto_parsed
                    )
            
            # 08. Pydantic Validated (JSON)
            if validated_model is not None:
                if hasattr(validated_model, 'model_dump'):
                    validated_data = validated_model.model_dump()
                elif hasattr(validated_model, 'dict'):
                    validated_data = validated_model.dict()
                elif isinstance(validated_model, dict):
                    validated_data = validated_model
                else:
                    validated_data = {"raw": str(validated_model)}
                
                self._write_json(
                    call_dir / "08_pydantic_validated.json",
                    validated_data
                )
            
            # 09. Metadata (JSON)
            metadata_dict = asdict(metadata)
            if processing_error:
                metadata_dict["processing_error"] = processing_error
            
            self._write_json(
                call_dir / "09_metadata.json",
                metadata_dict
            )
            
            # 10. Summary (Markdown)
            summary_md = self._generate_summary_md(
                call_id=call_id,
                metadata=metadata,
                template_name=template_name,
                variables=variables,
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                response_content=response_content,
                parsed_json=parsed_json,
                validated_model=validated_model,
                processing_error=processing_error,
            )
            self._write_text(
                call_dir / "summary.md",
                summary_md
            )
            
            logger.debug(f"ğŸ” LLM í˜¸ì¶œ ë¡œê·¸ ì €ì¥ ì™„ë£Œ: {call_id} â†’ {call_dir}")
            
        except Exception as e:
            logger.warning(f"âš ï¸ LLM í˜¸ì¶œ ë¡œê¹… ì‹¤íŒ¨ ({self.agent_name}/{call_id}): {e}")
    
    def _generate_summary_md(
        self,
        call_id: str,
        metadata: LLMCallMetadata,
        template_name: Optional[str],
        variables: Optional[Dict[str, Any]],
        system_prompt: Optional[str],
        user_prompt: Optional[str],
        response_content: Optional[str],
        parsed_json: Optional[Dict[str, Any]],
        validated_model: Optional[Any],
        processing_error: Optional[str],
    ) -> str:
        """ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ ìš”ì•½ Markdown ìƒì„±"""
        
        lines = []
        lines.append(f"# LLM Call: {call_id}")
        lines.append("")
        
        # ê¸°ë³¸ ì •ë³´
        lines.append("## ê¸°ë³¸ ì •ë³´")
        lines.append(f"- **Agent**: `{self.agent_name}`")
        lines.append(f"- **Timestamp**: {metadata.timestamp}")
        lines.append(f"- **Model**: `{metadata.model_id or 'N/A'}`")
        lines.append(f"- **Execution Time**: {metadata.execution_time_ms:.2f}ms" if metadata.execution_time_ms else "- **Execution Time**: N/A")
        lines.append("")
        
        # í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜
        if variables:
            lines.append("## í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜")
            lines.append("```yaml")
            for key, value in variables.items():
                # ê¸´ ê°’ì€ ì˜ë¼ì„œ í‘œì‹œ
                if isinstance(value, str) and len(value) > 100:
                    value_str = value[:100] + "..."
                else:
                    value_str = str(value)
                lines.append(f"{key}: {value_str}")
            lines.append("```")
            lines.append("")
        
        # System Prompt
        if system_prompt:
            lines.append("## System Prompt")
            lines.append("```")
            # ì²« 200ìë§Œ í‘œì‹œ
            preview = system_prompt[:200] + "..." if len(system_prompt) > 200 else system_prompt
            lines.append(preview)
            lines.append("```")
            lines.append("*(ì „ì²´: 03_system_prompt.txt ì°¸ì¡°)*")
            lines.append("")
        
        # User Prompt
        if user_prompt:
            lines.append("## User Prompt")
            lines.append("```")
            # ì²« 300ìë§Œ í‘œì‹œ
            preview = user_prompt[:300] + "..." if len(user_prompt) > 300 else user_prompt
            lines.append(preview)
            lines.append("```")
            lines.append("*(ì „ì²´: 04_user_prompt.txt ì°¸ì¡°)*")
            lines.append("")
        
        # LLM ì‘ë‹µ
        if parsed_json:
            lines.append("## LLM ì‘ë‹µ (íŒŒì‹±ë¨)")
            lines.append("```json")
            json_str = json.dumps(parsed_json, indent=2, ensure_ascii=False)
            # ì²« 500ìë§Œ í‘œì‹œ
            preview = json_str[:500] + "\n..." if len(json_str) > 500 else json_str
            lines.append(preview)
            lines.append("```")
            lines.append("*(ì „ì²´: 07_llm_response_parsed.json ì°¸ì¡°)*")
            lines.append("")
        elif response_content:
            lines.append("## LLM ì‘ë‹µ (ì›ë³¸)")
            lines.append("```")
            # ì²« 300ìë§Œ í‘œì‹œ
            preview = response_content[:300] + "..." if len(response_content) > 300 else response_content
            lines.append(preview)
            lines.append("```")
            lines.append("*(ì „ì²´: 06_llm_response_raw.txt ì°¸ì¡°)*")
            lines.append("")
        
        # í† í° ì‚¬ìš©ëŸ‰
        lines.append("## í† í° ì‚¬ìš©ëŸ‰")
        if metadata.input_tokens and metadata.output_tokens:
            total_tokens = metadata.input_tokens + metadata.output_tokens
            # ê°€ê²© ê³„ì‚° (ì˜ˆì‹œ: Sonnet ê¸°ì¤€)
            input_cost = (metadata.input_tokens / 1_000_000) * 3.0
            output_cost = (metadata.output_tokens / 1_000_000) * 15.0
            total_cost = input_cost + output_cost
            
            lines.append(f"- **Input**: {metadata.input_tokens:,} tokens")
            lines.append(f"- **Output**: {metadata.output_tokens:,} tokens")
            lines.append(f"- **Total**: {total_tokens:,} tokens")
            lines.append(f"- **Est. Cost**: ${total_cost:.4f}")
        else:
            lines.append("- *í† í° ì •ë³´ ì—†ìŒ*")
        lines.append("")
        
        # ìƒíƒœ
        lines.append("## ìƒíƒœ")
        if metadata.error:
            lines.append(f"âŒ **ì—ëŸ¬ ë°œìƒ**: {metadata.error}")
        elif processing_error:
            lines.append(f"âš ï¸ **ì²˜ë¦¬ ì—ëŸ¬**: {processing_error}")
        elif validated_model:
            lines.append("âœ… **ì„±ê³µ**")
            lines.append("- JSON íŒŒì‹±: ì„±ê³µ")
            lines.append("- Pydantic ê²€ì¦: ì„±ê³µ")
        elif parsed_json:
            lines.append("âš ï¸ **ë¶€ë¶„ ì„±ê³µ**")
            lines.append("- JSON íŒŒì‹±: ì„±ê³µ")
            lines.append("- Pydantic ê²€ì¦: ë¯¸ìˆ˜í–‰ ë˜ëŠ” ì‹¤íŒ¨")
        else:
            lines.append("âš ï¸ **íŒŒì‹± í•„ìš”**")
            lines.append("- JSON íŒŒì‹±ì´ ìˆ˜í–‰ë˜ì§€ ì•ŠìŒ")
        lines.append("")
        
        # íŒŒì¼ ì°¸ì¡°
        lines.append("## ìƒì„¸ íŒŒì¼")
        lines.append("- `01_prompt_template_info.json` - í…œí”Œë¦¿ ì •ë³´")
        lines.append("- `02_prompt_variables.json` - ë³€ìˆ˜ ë§¤í•‘")
        lines.append("- `03_system_prompt.txt` - System Prompt ì „ì²´")
        lines.append("- `04_user_prompt.txt` - User Prompt ì „ì²´")
        lines.append("- `05_llm_request.json` - LangChain ìš”ì²­ êµ¬ì¡°")
        lines.append("- `06_llm_response_raw.txt` - LLM ì›ë³¸ ì‘ë‹µ")
        lines.append("- `07_llm_response_parsed.json` - JSON íŒŒì‹± ê²°ê³¼")
        lines.append("- `08_pydantic_validated.json` - Pydantic ê²€ì¦ ê²°ê³¼")
        lines.append("- `09_metadata.json` - ë©”íƒ€ë°ì´í„° (í† í°, ì‹œê°„ ë“±)")
        lines.append("")
        
        return "\n".join(lines)
    
    def _write_text(self, path: Path, content: str):
        """í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥"""
        path.write_text(content, encoding="utf-8")
    
    def _write_json(self, path: Path, data: Any):
        """JSON íŒŒì¼ ì €ì¥"""
        path.write_text(
            json.dumps(data, indent=2, ensure_ascii=False, default=str),
            encoding="utf-8"
        )
    
    def _serialize_messages(self, messages: List[Any]) -> List[Dict[str, Any]]:
        """LangChain ë©”ì‹œì§€ë¥¼ ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜"""
        result = []
        for msg in messages:
            if hasattr(msg, 'content'):
                result.append({
                    "type": type(msg).__name__,
                    "content": msg.content,
                })
            elif isinstance(msg, dict):
                result.append(msg)
            else:
                result.append({"raw": str(msg)})
        return result
    
    def _try_parse_json(self, text: str) -> Optional[Dict[str, Any]]:
        """í…ìŠ¤íŠ¸ì—ì„œ JSON íŒŒì‹± ì‹œë„"""
        import re
        
        # JSON ì½”ë“œ ë¸”ë¡ ì°¾ê¸°
        json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', text, re.DOTALL)
        if json_match:
            try:
                return json.loads(json_match.group(1))
            except:
                pass
        
        # ì§ì ‘ JSON íŒŒì‹± ì‹œë„
        try:
            return json.loads(text)
        except:
            pass
        
        return None


class DummyDebugLogger:
    """ë””ë²„ê¹… ë¹„í™œì„±í™” ì‹œ ì‚¬ìš©í•˜ëŠ” ë”ë¯¸ ë¡œê±°"""
    
    def log_request(self, *args, **kwargs):
        pass
    
    def log_response(self, *args, **kwargs):
        pass
    
    def log_intermediate(self, *args, **kwargs):
        pass
    
    def get_subagent_logger(self, *args, **kwargs):
        return self
    
    def log_loaded_data(self, *args, **kwargs):
        pass
    
    def log_error(self, *args, **kwargs):
        """ì—ëŸ¬ ë¡œê¹… (ë”ë¯¸ - ì•„ë¬´ê²ƒë„ í•˜ì§€ ì•ŠìŒ)"""
        pass
    
    def log_exception(self, *args, **kwargs):
        """ì˜ˆì™¸ ë¡œê¹… (ë”ë¯¸ - ì•„ë¬´ê²ƒë„ í•˜ì§€ ì•ŠìŒ)"""
        pass
    
    def track_llm_call(self):
        return self
    
    def track_execution(self):
        return self
    
    def __enter__(self):
        return self
    
    def __exit__(self, *args):
        pass
    
    def set_messages(self, *args):
        pass
    
    def set_response(self, *args):
        pass
    
    def log_prompts(self, *args, **kwargs):
        pass
    
    def log_response_stages(self, *args, **kwargs):
        pass

