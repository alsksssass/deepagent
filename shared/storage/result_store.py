"""
ResultStore - ì—ì´ì „íŠ¸ ê²°ê³¼ ì €ì¥ ë° ê´€ë¦¬

ì—ì´ì „íŠ¸ ì‹¤í–‰ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•˜ê³  íƒ€ì… ì•ˆì „í•˜ê²Œ ë¡œë“œí•˜ëŠ” ìŠ¤í† ë¦¬ì§€ ë§¤ë‹ˆì €

êµ¬ì¡°:
    data/analyze/{task_uuid}/
    â”œâ”€â”€ results/
    â”‚   â”œâ”€â”€ repo_cloner.json
    â”‚   â”œâ”€â”€ static_analyzer.json
    â”‚   â”œâ”€â”€ commit_analyzer.json
    â”‚   â”œâ”€â”€ commit_evaluator/
    â”‚   â”‚   â”œâ”€â”€ batch_0001.json
    â”‚   â”‚   â”œâ”€â”€ batch_0002.json
    â”‚   â”‚   â””â”€â”€ summary.json
    â”‚   â””â”€â”€ reporter.json
    â””â”€â”€ metadata.json
"""

import json
import logging
from pathlib import Path
from typing import Type, TypeVar, Optional, List, Any
from datetime import datetime

from shared.schemas.common import BaseResponse

logger = logging.getLogger(__name__)

T = TypeVar("T", bound=BaseResponse)


class ResultStore:
    """
    ì—ì´ì „íŠ¸ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥/ë¡œë“œí•˜ëŠ” ìŠ¤í† ë¦¬ì§€ ë§¤ë‹ˆì €

    íŠ¹ì§•:
    - íƒ€ì… ì•ˆì „í•œ ê²°ê³¼ ì €ì¥/ë¡œë“œ (Pydantic ê¸°ë°˜)
    - ëŒ€ìš©ëŸ‰ ê²°ê³¼ ë°°ì¹˜ ë¶„í•  ì €ì¥ ì§€ì›
    - ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ê²°ê³¼ ê´€ë¦¬
    - ì—ì´ì „íŠ¸ë³„ ìë™ ê²½ë¡œ ê´€ë¦¬
    """

    def __init__(self, task_uuid: str, base_path: Path):
        """
        ResultStore ì´ˆê¸°í™”

        Args:
            task_uuid: ì‘ì—… ê³ ìœ  UUID
            base_path: ì‘ì—… ê¸°ë³¸ ê²½ë¡œ (ì˜ˆ: Path("./data/analyze/{task_uuid}"))
        """
        self.task_uuid = task_uuid
        self.base_path = Path(base_path)
        self.results_dir = self.base_path / "results"
        self.results_dir.mkdir(parents=True, exist_ok=True)

        logger.debug(f"ğŸ“¦ ResultStore ì´ˆê¸°í™”: {self.results_dir}")

    def save_result(
        self,
        agent_name: str,
        result: BaseResponse,
    ) -> Path:
        """
        ì—ì´ì „íŠ¸ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥

        Args:
            agent_name: ì—ì´ì „íŠ¸ ì´ë¦„ (ì˜ˆ: "repo_cloner", "static_analyzer")
            result: Pydantic BaseResponse ì¸ìŠ¤í„´ìŠ¤

        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ

        Example:
            >>> store = ResultStore("task-123", Path("./data/analyze/task-123"))
            >>> response = RepoClonerResponse(status="success", repo_path="/path/to/repo")
            >>> file_path = store.save_result("repo_cloner", response)
            >>> print(file_path)
            Path("./data/analyze/task-123/results/repo_cloner.json")
        """
        file_path = self.results_dir / f"{agent_name}.json"

        try:
            # Pydantic ëª¨ë¸ì„ JSONìœ¼ë¡œ ì§ë ¬í™”
            json_content = result.model_dump_json(indent=2, ensure_ascii=False)
            file_path.write_text(json_content, encoding="utf-8")

            logger.info(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {agent_name} â†’ {file_path}")
            return file_path

        except Exception as e:
            logger.error(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨ ({agent_name}): {e}")
            raise

    def load_result(
        self,
        agent_name: str,
        result_class: Type[T],
    ) -> T:
        """
        ì €ì¥ëœ ì—ì´ì „íŠ¸ ê²°ê³¼ë¥¼ íƒ€ì… ì•ˆì „í•˜ê²Œ ë¡œë“œ

        Args:
            agent_name: ì—ì´ì „íŠ¸ ì´ë¦„
            result_class: Pydantic Response í´ë˜ìŠ¤ (ì˜ˆ: RepoClonerResponse)

        Returns:
            ë¡œë“œëœ Pydantic Response ì¸ìŠ¤í„´ìŠ¤

        Raises:
            FileNotFoundError: ê²°ê³¼ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šì„ ë•Œ
            ValueError: JSON íŒŒì‹± ë˜ëŠ” Pydantic ê²€ì¦ ì‹¤íŒ¨ ì‹œ

        Example:
            >>> from agents.repo_cloner import RepoClonerResponse
            >>> store = ResultStore("task-123", Path("./data/analyze/task-123"))
            >>> result = store.load_result("repo_cloner", RepoClonerResponse)
            >>> print(result.repo_path)
            "/path/to/repo"
        """
        file_path = self.results_dir / f"{agent_name}.json"

        if not file_path.exists():
            raise FileNotFoundError(
                f"ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {agent_name} ({file_path})"
            )

        try:
            # JSON íŒŒì¼ ì½ê¸°
            json_content = file_path.read_text(encoding="utf-8")
            data = json.loads(json_content)

            # Pydantic ëª¨ë¸ë¡œ ì—­ì§ë ¬í™”
            result = result_class(**data)

            logger.debug(f"ğŸ“‚ ê²°ê³¼ ë¡œë“œ: {agent_name} â† {file_path}")
            return result

        except json.JSONDecodeError as e:
            logger.error(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨ ({agent_name}): {e}")
            raise ValueError(f"ì˜ëª»ëœ JSON í˜•ì‹: {agent_name}") from e
        except Exception as e:
            logger.error(f"âŒ ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨ ({agent_name}): {e}")
            raise

    def save_batched_result(
        self,
        agent_name: str,
        batch_id: int,
        result: BaseResponse | List[BaseResponse] | dict[str, Any],
    ) -> Path:
        """
        ëŒ€ìš©ëŸ‰ ê²°ê³¼ë¥¼ ë°°ì¹˜ë³„ë¡œ ì €ì¥ (CommitEvaluator ë“±)

        Args:
            agent_name: ì—ì´ì „íŠ¸ ì´ë¦„ (ì˜ˆ: "commit_evaluator")
            batch_id: ë°°ì¹˜ ë²ˆí˜¸ (0ë¶€í„° ì‹œì‘)
            result: ì €ì¥í•  ê²°ê³¼ (Pydantic Response, Response ë¦¬ìŠ¤íŠ¸, ë˜ëŠ” dict)

        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ

        Example:
            >>> store = ResultStore("task-123", Path("./data/analyze/task-123"))
            >>> batch_results = [CommitEvaluatorResponse(...) for _ in range(100)]
            >>> file_path = store.save_batched_result("commit_evaluator", 0, batch_results)
            >>> print(file_path)
            Path("./data/analyze/task-123/results/commit_evaluator/batch_0000.json")
        """
        batch_dir = self.results_dir / agent_name
        batch_dir.mkdir(parents=True, exist_ok=True)

        file_path = batch_dir / f"batch_{batch_id:04d}.json"

        try:
            # ê²°ê³¼ íƒ€ì…ì— ë”°ë¼ ì§ë ¬í™”
            if isinstance(result, BaseResponse):
                json_content = result.model_dump_json(indent=2, ensure_ascii=False)
            elif isinstance(result, list) and result and isinstance(result[0], BaseResponse):
                # Pydantic Response ë¦¬ìŠ¤íŠ¸
                json_content = json.dumps(
                    [r.model_dump() for r in result],
                    indent=2,
                    ensure_ascii=False,
                )
            elif isinstance(result, dict):
                # dict ì§ì ‘ ì €ì¥
                json_content = json.dumps(result, indent=2, ensure_ascii=False)
            else:
                # ê¸°íƒ€ íƒ€ì…ì€ JSON ì§ë ¬í™” ì‹œë„
                json_content = json.dumps(result, indent=2, ensure_ascii=False, default=str)

            file_path.write_text(json_content, encoding="utf-8")

            logger.info(f"ğŸ’¾ ë°°ì¹˜ ê²°ê³¼ ì €ì¥: {agent_name}/batch_{batch_id:04d} â†’ {file_path}")
            return file_path

        except Exception as e:
            logger.error(f"âŒ ë°°ì¹˜ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨ ({agent_name}/batch_{batch_id}): {e}")
            raise

    def load_batched_results(
        self,
        agent_name: str,
        result_class: Optional[Type[T]] = None,
    ) -> List[dict[str, Any]] | List[T]:
        """
        ë°°ì¹˜ ê²°ê³¼ ì „ì²´ë¥¼ ë¡œë“œ

        Args:
            agent_name: ì—ì´ì „íŠ¸ ì´ë¦„
            result_class: Pydantic Response í´ë˜ìŠ¤ (ì§€ì • ì‹œ íƒ€ì… ì•ˆì „ ë¡œë“œ)

        Returns:
            ë°°ì¹˜ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (result_class ì§€ì • ì‹œ Pydantic ì¸ìŠ¤í„´ìŠ¤ ë¦¬ìŠ¤íŠ¸, ì•„ë‹ˆë©´ dict ë¦¬ìŠ¤íŠ¸)

        Example:
            >>> from agents.commit_evaluator import CommitEvaluatorResponse
            >>> store = ResultStore("task-123", Path("./data/analyze/task-123"))
            >>> batches = store.load_batched_results("commit_evaluator", CommitEvaluatorResponse)
            >>> print(len(batches))
            10
        """
        batch_dir = self.results_dir / agent_name

        if not batch_dir.exists():
            raise FileNotFoundError(
                f"ë°°ì¹˜ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {agent_name} ({batch_dir})"
            )

        # ë°°ì¹˜ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ì •ë ¬)
        batch_files = sorted(batch_dir.glob("batch_*.json"))

        if not batch_files:
            logger.warning(f"âš ï¸  ë°°ì¹˜ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {agent_name}")
            return []

        results = []

        for batch_file in batch_files:
            try:
                json_content = batch_file.read_text(encoding="utf-8")
                data = json.loads(json_content)

                # result_classê°€ ì§€ì •ëœ ê²½ìš° Pydanticìœ¼ë¡œ ë³€í™˜
                if result_class:
                    if isinstance(data, list):
                        # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ê° í•­ëª©ì„ Pydanticìœ¼ë¡œ ë³€í™˜
                        results.extend([result_class(**item) for item in data])
                    else:
                        # ë‹¨ì¼ ê°ì²´ì¸ ê²½ìš°
                        results.append(result_class(**data))
                else:
                    # dict ê·¸ëŒ€ë¡œ ë°˜í™˜
                    if isinstance(data, list):
                        results.extend(data)
                    else:
                        results.append(data)

            except Exception as e:
                logger.error(f"âŒ ë°°ì¹˜ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ({batch_file}): {e}")
                continue

        logger.debug(f"ğŸ“‚ ë°°ì¹˜ ê²°ê³¼ ë¡œë“œ: {agent_name} - {len(results)}ê°œ í•­ëª©")
        return results

    def get_result_path(self, agent_name: str) -> Path:
        """
        ì—ì´ì „íŠ¸ ê²°ê³¼ íŒŒì¼ ê²½ë¡œ ë°˜í™˜ (ì—ì´ì „íŠ¸ê°€ ì§ì ‘ íŒŒì¼ ì½ê¸° ê°€ëŠ¥)

        Args:
            agent_name: ì—ì´ì „íŠ¸ ì´ë¦„

        Returns:
            ê²°ê³¼ íŒŒì¼ ê²½ë¡œ (ì¡´ì¬í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ)

        Example:
            >>> store = ResultStore("task-123", Path("./data/analyze/task-123"))
            >>> path = store.get_result_path("static_analyzer")
            >>> if path.exists():
            ...     data = json.loads(path.read_text())
        """
        return self.results_dir / f"{agent_name}.json"

    def get_batch_dir(self, agent_name: str) -> Path:
        """
        ë°°ì¹˜ ê²°ê³¼ ë””ë ‰í† ë¦¬ ê²½ë¡œ ë°˜í™˜

        Args:
            agent_name: ì—ì´ì „íŠ¸ ì´ë¦„

        Returns:
            ë°°ì¹˜ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        """
        return self.results_dir / agent_name

    def list_available_results(self) -> List[str]:
        """
        ì €ì¥ëœ ì—ì´ì „íŠ¸ ê²°ê³¼ ëª©ë¡ ì¡°íšŒ

        Returns:
            ì—ì´ì „íŠ¸ ì´ë¦„ ë¦¬ìŠ¤íŠ¸

        Example:
            >>> store = ResultStore("task-123", Path("./data/analyze/task-123"))
            >>> results = store.list_available_results()
            >>> print(results)
            ["repo_cloner", "static_analyzer", "commit_analyzer"]
        """
        if not self.results_dir.exists():
            return []

        # JSON íŒŒì¼ë§Œ í•„í„°ë§ (ë””ë ‰í† ë¦¬ ì œì™¸)
        result_files = [
            f.stem
            for f in self.results_dir.iterdir()
            if f.is_file() and f.suffix == ".json"
        ]

        return sorted(result_files)

    def list_batched_agents(self) -> List[str]:
        """
        ë°°ì¹˜ ì €ì¥ëœ ì—ì´ì „íŠ¸ ëª©ë¡ ì¡°íšŒ

        Returns:
            ë°°ì¹˜ ì €ì¥ëœ ì—ì´ì „íŠ¸ ì´ë¦„ ë¦¬ìŠ¤íŠ¸

        Example:
            >>> store = ResultStore("task-123", Path("./data/analyze/task-123"))
            >>> batched = store.list_batched_agents()
            >>> print(batched)
            ["commit_evaluator"]
        """
        if not self.results_dir.exists():
            return []

        # ë°°ì¹˜ ë””ë ‰í† ë¦¬ë§Œ í•„í„°ë§
        batched_agents = [
            d.name
            for d in self.results_dir.iterdir()
            if d.is_dir() and any(d.glob("batch_*.json"))
        ]

        return sorted(batched_agents)

    def save_metadata(self, metadata: dict[str, Any]) -> Path:
        """
        ì‘ì—… ë©”íƒ€ë°ì´í„° ì €ì¥

        Args:
            metadata: ë©”íƒ€ë°ì´í„° dict

        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        metadata_path = self.base_path / "metadata.json"

        # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
        metadata["updated_at"] = datetime.now().isoformat()

        try:
            json_content = json.dumps(metadata, indent=2, ensure_ascii=False, default=str)
            metadata_path.write_text(json_content, encoding="utf-8")

            logger.debug(f"ğŸ’¾ ë©”íƒ€ë°ì´í„° ì €ì¥: {metadata_path}")
            return metadata_path

        except Exception as e:
            logger.error(f"âŒ ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            raise

    def load_metadata(self) -> dict[str, Any]:
        """
        ì‘ì—… ë©”íƒ€ë°ì´í„° ë¡œë“œ

        Returns:
            ë©”íƒ€ë°ì´í„° dict (íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¹ˆ dict)
        """
        metadata_path = self.base_path / "metadata.json"

        if not metadata_path.exists():
            return {}

        try:
            json_content = metadata_path.read_text(encoding="utf-8")
            return json.loads(json_content)

        except Exception as e:
            logger.error(f"âŒ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}

