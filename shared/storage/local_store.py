"""
LocalStorageBackend - ë¡œì»¬ íŒŒì¼ì‹œìŠ¤í…œ ê¸°ë°˜ ìŠ¤í† ë¦¬ì§€

ë¡œì»¬ í™˜ê²½ì—ì„œ JSON íŒŒì¼ë¡œ ê²°ê³¼ë¥¼ ì €ì¥/ë¡œë“œ
"""

import json
import logging
from pathlib import Path
from typing import Type, TypeVar, Optional, List, Any

from shared.storage.base import StorageBackend
from shared.schemas.common import BaseResponse

logger = logging.getLogger(__name__)

T = TypeVar("T", bound=BaseResponse)


class LocalStorageBackend(StorageBackend):
    """
    ë¡œì»¬ íŒŒì¼ì‹œìŠ¤í…œ ê¸°ë°˜ ìŠ¤í† ë¦¬ì§€ ë°±ì—”ë“œ

    êµ¬ì¡°:
        data/analyze/{task_uuid}/
        â”œâ”€â”€ results/
        â”‚   â”œâ”€â”€ repo_cloner.json
        â”‚   â”œâ”€â”€ static_analyzer.json
        â”‚   â”œâ”€â”€ commit_evaluator/
        â”‚   â”‚   â”œâ”€â”€ batch_0000.json
        â”‚   â”‚   â””â”€â”€ batch_0001.json
        â”‚   â””â”€â”€ reporter.json
        â””â”€â”€ metadata.json
    """

    def __init__(self, task_uuid: str, base_path: str | Path):
        """
        LocalStorageBackend ì´ˆê¸°í™”

        Args:
            task_uuid: ì‘ì—… ê³ ìœ  UUID
            base_path: ê¸°ë³¸ ê²½ë¡œ (ì˜ˆ: "./data/analyze/{task_uuid}")
        """
        super().__init__(task_uuid, base_path)
        self.base_path_obj = Path(base_path)
        self.results_dir = self.base_path_obj / "results"
        self.results_dir.mkdir(parents=True, exist_ok=True)

        logger.debug(f"ğŸ“¦ LocalStorageBackend ì´ˆê¸°í™”: {self.results_dir}")

    def save_result(self, agent_name: str, result: BaseResponse) -> str:
        """ì—ì´ì „íŠ¸ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        file_path = self.results_dir / f"{agent_name}.json"

        try:
            json_content = result.model_dump_json(indent=2, ensure_ascii=False)
            file_path.write_text(json_content, encoding="utf-8")

            logger.info(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ (Local): {agent_name} â†’ {file_path}")
            return str(file_path)

        except Exception as e:
            logger.error(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨ ({agent_name}): {e}")
            raise

    def load_result(self, agent_name: str, result_class: Type[T]) -> T:
        """ì €ì¥ëœ ì—ì´ì „íŠ¸ ê²°ê³¼ë¥¼ íƒ€ì… ì•ˆì „í•˜ê²Œ ë¡œë“œ"""
        file_path = self.results_dir / f"{agent_name}.json"

        if not file_path.exists():
            raise FileNotFoundError(
                f"ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {agent_name} ({file_path})"
            )

        try:
            json_content = file_path.read_text(encoding="utf-8")
            data = json.loads(json_content)
            result = result_class(**data)

            logger.debug(f"ğŸ“‚ ê²°ê³¼ ë¡œë“œ (Local): {agent_name} â† {file_path}")
            return result

        except json.JSONDecodeError as e:
            logger.error(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨ ({agent_name}): {e}")
            raise ValueError(f"ì˜ëª»ëœ JSON í˜•ì‹: {agent_name}") from e
        except Exception as e:
            logger.error(f"âŒ ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨ ({agent_name}): {e}")
            raise

    def save_batched_result(
        self,
        agent_name: str,
        batch_id: int,
        result: BaseResponse | List[BaseResponse] | dict[str, Any],
    ) -> str:
        """ëŒ€ìš©ëŸ‰ ê²°ê³¼ë¥¼ ë°°ì¹˜ë³„ë¡œ ì €ì¥"""
        batch_dir = self.results_dir / agent_name
        batch_dir.mkdir(parents=True, exist_ok=True)

        file_path = batch_dir / f"batch_{batch_id:04d}.json"

        try:
            # ê²°ê³¼ íƒ€ì…ì— ë”°ë¼ ì§ë ¬í™”
            if isinstance(result, BaseResponse):
                json_content = result.model_dump_json(indent=2, ensure_ascii=False)
            elif isinstance(result, list) and result and isinstance(result[0], BaseResponse):
                json_content = json.dumps(
                    [r.model_dump() for r in result],
                    indent=2,
                    ensure_ascii=False,
                )
            elif isinstance(result, dict):
                json_content = json.dumps(result, indent=2, ensure_ascii=False)
            else:
                json_content = json.dumps(result, indent=2, ensure_ascii=False, default=str)

            file_path.write_text(json_content, encoding="utf-8")

            logger.info(f"ğŸ’¾ ë°°ì¹˜ ê²°ê³¼ ì €ì¥ (Local): {agent_name}/batch_{batch_id:04d} â†’ {file_path}")
            return str(file_path)

        except Exception as e:
            logger.error(f"âŒ ë°°ì¹˜ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨ ({agent_name}/batch_{batch_id}): {e}")
            raise

    def load_batched_results(
        self,
        agent_name: str,
        result_class: Optional[Type[T]] = None,
    ) -> List[dict[str, Any]] | List[T]:
        """ë°°ì¹˜ ê²°ê³¼ ì „ì²´ë¥¼ ë¡œë“œ"""
        batch_dir = self.results_dir / agent_name

        if not batch_dir.exists():
            raise FileNotFoundError(
                f"ë°°ì¹˜ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {agent_name} ({batch_dir})"
            )

        batch_files = sorted(batch_dir.glob("batch_*.json"))

        if not batch_files:
            logger.warning(f"âš ï¸  ë°°ì¹˜ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {agent_name}")
            return []

        results = []

        for batch_file in batch_files:
            try:
                json_content = batch_file.read_text(encoding="utf-8")
                data = json.loads(json_content)

                if result_class:
                    if isinstance(data, list):
                        results.extend([result_class(**item) for item in data])
                    else:
                        results.append(result_class(**data))
                else:
                    if isinstance(data, list):
                        results.extend(data)
                    else:
                        results.append(data)

            except Exception as e:
                logger.error(f"âŒ ë°°ì¹˜ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ({batch_file}): {e}")
                continue

        logger.debug(f"ğŸ“‚ ë°°ì¹˜ ê²°ê³¼ ë¡œë“œ (Local): {agent_name} - {len(results)}ê°œ í•­ëª©")
        return results

    def save_metadata(self, metadata: dict[str, Any]) -> str:
        """ì‘ì—… ë©”íƒ€ë°ì´í„° ì €ì¥"""
        from datetime import datetime

        metadata_path = self.base_path_obj / "metadata.json"

        # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
        metadata["updated_at"] = datetime.now().isoformat()

        try:
            json_content = json.dumps(metadata, indent=2, ensure_ascii=False, default=str)
            metadata_path.write_text(json_content, encoding="utf-8")

            logger.debug(f"ğŸ’¾ ë©”íƒ€ë°ì´í„° ì €ì¥ (Local): {metadata_path}")
            return str(metadata_path)

        except Exception as e:
            logger.error(f"âŒ ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            raise

    def load_metadata(self) -> dict[str, Any]:
        """ì‘ì—… ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
        metadata_path = self.base_path_obj / "metadata.json"

        if not metadata_path.exists():
            return {}

        try:
            json_content = metadata_path.read_text(encoding="utf-8")
            return json.loads(json_content)

        except Exception as e:
            logger.error(f"âŒ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}

    def list_available_results(self) -> List[str]:
        """ì €ì¥ëœ ì—ì´ì „íŠ¸ ê²°ê³¼ ëª©ë¡ ì¡°íšŒ"""
        if not self.results_dir.exists():
            return []

        result_files = [
            f.stem
            for f in self.results_dir.iterdir()
            if f.is_file() and f.suffix == ".json"
        ]

        return sorted(result_files)

    def list_batched_agents(self) -> List[str]:
        """ë°°ì¹˜ ì €ì¥ëœ ì—ì´ì „íŠ¸ ëª©ë¡ ì¡°íšŒ"""
        if not self.results_dir.exists():
            return []

        batched_agents = [
            d.name
            for d in self.results_dir.iterdir()
            if d.is_dir() and any(d.glob("batch_*.json"))
        ]

        return sorted(batched_agents)

    def get_result_path(self, agent_name: str) -> str:
        """ì—ì´ì „íŠ¸ ê²°ê³¼ íŒŒì¼ ê²½ë¡œ ë°˜í™˜"""
        return str(self.results_dir / f"{agent_name}.json")

    def get_batch_dir(self, agent_name: str) -> str:
        """ë°°ì¹˜ ê²°ê³¼ ë””ë ‰í† ë¦¬ ê²½ë¡œ ë°˜í™˜"""
        return str(self.results_dir / agent_name)

    def save_report(self, report_name: str, content: str) -> str:
        """ë¦¬í¬íŠ¸ íŒŒì¼ ì €ì¥"""
        reports_dir = self.base_path_obj / "reports"
        reports_dir.mkdir(parents=True, exist_ok=True)
        
        report_path = reports_dir / report_name
        report_path.write_text(content, encoding="utf-8")
        
        logger.info(f"ğŸ’¾ ë¦¬í¬íŠ¸ ì €ì¥ (Local): {report_path}")
        return str(report_path)

    def load_report(self, report_name: str) -> str:
        """ë¦¬í¬íŠ¸ íŒŒì¼ ë¡œë“œ"""
        report_path = self.base_path_obj / "reports" / report_name
        
        if not report_path.exists():
            raise FileNotFoundError(f"ë¦¬í¬íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {report_name}")
        
        return report_path.read_text(encoding="utf-8")

    def save_log(self, log_name: str, content: str) -> str:
        """ë¡œê·¸ íŒŒì¼ ì €ì¥"""
        logs_dir = self.base_path_obj / "logs"
        logs_dir.mkdir(parents=True, exist_ok=True)
        
        log_path = logs_dir / log_name
        log_path.write_text(content, encoding="utf-8")
        
        logger.info(f"ğŸ’¾ ë¡œê·¸ ì €ì¥ (Local): {log_path}")
        return str(log_path)

    def upload_log_directory(self, local_log_dir: Path, remote_subdir: str = None) -> List[str]:
        """ë¡œì»¬ì—ì„œëŠ” ë‹¨ìˆœíˆ ê²½ë¡œ ë°˜í™˜ (ì—…ë¡œë“œ ë¶ˆí•„ìš”)"""
        if not local_log_dir.exists():
            return []
        
        uploaded_paths = []
        for log_file in local_log_dir.rglob("*"):
            if log_file.is_file():
                uploaded_paths.append(str(log_file))
        
        return uploaded_paths

    def save_debug_file(self, relative_path: str, content: str | bytes) -> str:
        """ë””ë²„ê·¸ íŒŒì¼ ì €ì¥ (ë¡œì»¬)"""
        file_path = self.base_path_obj / relative_path
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        if isinstance(content, bytes):
            file_path.write_bytes(content)
        else:
            file_path.write_text(content, encoding="utf-8")
        
        return str(file_path)
